{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in census data for 2012, 2016, and 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race_2012 = pd.read_csv('data/election/census/census_race_2012.csv')\n",
    "df_race_2016 = pd.read_csv('data/election/census/census_race_2016.csv')\n",
    "df_race_2020 = pd.read_csv('data/election/census/census_race_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_sex_2012 = pd.read_csv('data/election/census/census_age_sex_2012.csv')\n",
    "df_age_sex_2016 = pd.read_csv('data/election/census/census_age_sex_2016.csv')\n",
    "df_age_sex_2020 = pd.read_csv('data/election/census/census_age_sex_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_employment_2012 = pd.read_csv('data/election/census/census_employment_2012.csv')\n",
    "df_age_employment_2016 = pd.read_csv('data/election/census/census_employment_2016.csv')\n",
    "df_age_employment_2020 = pd.read_csv('data/election/census/census_employment_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industry_2012 = pd.read_csv('../../data/election/census/census_industry_2012.csv')\n",
    "df_industry_2016 = pd.read_csv('../../data/election/census/census_industry_2016.csv')\n",
    "df_industry_2020 = pd.read_csv('../../data/election/census/census_industry_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_financial_2012 = pd.read_csv('data/election/census/census_housing_finanical_2012.csv')\n",
    "df_housing_financial_2016 = pd.read_csv('data/election/census/census_housing_finanical_2016.csv')\n",
    "df_housing_financial_2020 = pd.read_csv('data/election/census/census_housing_finanical_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veteran_status_2012 = pd.read_csv('data/election/census/census_veteran_status_2012.csv')\n",
    "df_veteran_status_2016 = pd.read_csv('data/election/census/census_veteran_status_2016.csv')\n",
    "df_veteran_status_2020 = pd.read_csv('data/election/census/census_veteran_status_2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape race data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reshape_demographics_race_data(df):\n",
    "    \"\"\"\n",
    "    Reshape demographic data from wide format to long format with separate county and state columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe with demographic data\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped dataframe with county and state as rows and demographic categories as columns\n",
    "    \"\"\"\n",
    "    # Reset index to get the Label column as a regular column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Melt the dataframe to convert counties from columns to rows\n",
    "    melted = pd.melt(\n",
    "        df,\n",
    "        id_vars=['Label (Grouping)'],\n",
    "        var_name='location',\n",
    "        value_name='value'\n",
    "    )\n",
    "    \n",
    "    # Split the location column into county and state\n",
    "    # Remove the '!!Estimate' suffix and split on the last comma\n",
    "    melted['location'] = melted['location'].str.replace('!!Estimate', '')\n",
    "    melted[['county_name', 'state_name']] = melted['location'].str.rsplit(',', n=1, expand=True)\n",
    "    \n",
    "    # Strip whitespace from county and state names\n",
    "    melted['county_name'] = melted['county_name'].str.strip()\n",
    "    melted['state_name'] = melted['state_name'].str.strip()\n",
    "    \n",
    "    # Pivot the data to get demographic categories as columns\n",
    "    reshaped = melted.pivot(\n",
    "        index=['county_name', 'state_name'],\n",
    "        columns='Label (Grouping)',\n",
    "        values='value'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Clean up column names by removing any extra levels\n",
    "    reshaped.columns.name = None\n",
    "    \n",
    "    # Reorder columns to have county_name and state_name first\n",
    "    demographic_cols = [col for col in reshaped.columns if col not in ['county_name', 'state_name']]\n",
    "    column_order = ['county_name', 'state_name'] + demographic_cols\n",
    "    \n",
    "    return reshaped[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race_2012_reshaped = reshape_demographics_race_data(df_race_2012)\n",
    "df_race_2012_reshaped = df_race_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_race_2016_reshaped = reshape_demographics_race_data(df_race_2016)\n",
    "df_race_2016_reshaped = df_race_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_race_2020_reshaped = reshape_demographics_race_data(df_race_2020)\n",
    "df_race_2020_reshaped = df_race_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_race_2012_reshaped.to_csv('data/election/census/census_race_2012_reshaped.csv', index=False)\n",
    "df_race_2016_reshaped.to_csv('data/election/census/census_race_2016_reshaped.csv', index=False)\n",
    "df_race_2020_reshaped.to_csv('data/election/census/census_race_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_demographics_age_data(df):\n",
    "    # First, let's get the column names and split them into components\n",
    "    columns = df.columns[1:]  # Skip the 'Label (Grouping)' column\n",
    "    \n",
    "    # Create a list to store the transformed data\n",
    "    transformed_data = []\n",
    "    \n",
    "    # Track unique counties and states\n",
    "    processed_locations = set()\n",
    "    \n",
    "    # Iterate through each location column\n",
    "    for col in columns:\n",
    "        # Split the column name\n",
    "        parts = col.split('!!')\n",
    "        \n",
    "        # Extract location and demographic type\n",
    "        location = parts[0]\n",
    "        demo_type = parts[1]  # Male, Female, or Total\n",
    "        estimate = parts[2] if len(parts) > 2 else None\n",
    "        \n",
    "        # Skip if not an Estimate\n",
    "        if estimate != 'Estimate':\n",
    "            continue\n",
    "            \n",
    "        # Split location into county and state\n",
    "        county_state = location.split(', ')\n",
    "        county = county_state[0]\n",
    "        state = county_state[1]\n",
    "        \n",
    "        # Create unique key for this county\n",
    "        location_key = (county, state)\n",
    "        \n",
    "        # If we haven't processed this county yet, create a new row\n",
    "        if location_key not in processed_locations:\n",
    "            row_data = {\n",
    "                'county_name': county,\n",
    "                'state_name': state\n",
    "            }\n",
    "            \n",
    "            # Add data for each demographic label\n",
    "            for idx, label in enumerate(df['Label (Grouping)']):\n",
    "                if pd.notna(df.iloc[idx][col]) and str(df.iloc[idx][col]) != '(X)':\n",
    "                    value = df.iloc[idx][col]\n",
    "                    # Convert percentages to floats\n",
    "                    if isinstance(value, str) and '%' in value:\n",
    "                        value = float(value.strip('%'))/100\n",
    "                    \n",
    "                    # Create column name combining label and demographic type\n",
    "                    column_name = f\"{label}_{demo_type.lower()}\"\n",
    "                    row_data[column_name] = value\n",
    "            \n",
    "            transformed_data.append(row_data)\n",
    "            processed_locations.add(location_key)\n",
    "        else:\n",
    "            # Update existing row with additional demographic type data\n",
    "            row_idx = next(i for i, row in enumerate(transformed_data) \n",
    "                          if row['county_name'] == county and row['state_name'] == state)\n",
    "            \n",
    "            for idx, label in enumerate(df['Label (Grouping)']):\n",
    "                if pd.notna(df.iloc[idx][col]) and str(df.iloc[idx][col]) != '(X)':\n",
    "                    value = df.iloc[idx][col]\n",
    "                    # Convert percentages to floats\n",
    "                    if isinstance(value, str) and '%' in value:\n",
    "                        value = float(value.strip('%'))/100\n",
    "                    \n",
    "                    # Create column name combining label and demographic type\n",
    "                    column_name = f\"{label}_{demo_type.lower()}\"\n",
    "                    transformed_data[row_idx][column_name] = value\n",
    "    \n",
    "    # Create new dataframe\n",
    "    new_df = pd.DataFrame(transformed_data)\n",
    "    \n",
    "    # Sort columns alphabetically after county_name and state_name\n",
    "    cols = ['county_name', 'state_name'] + sorted([col for col in new_df.columns \n",
    "                                                 if col not in ['county_name', 'state_name']])\n",
    "    new_df = new_df[cols]\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "# Example usage:\n",
    "# reshaped_df = reshape_demographics_data(your_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_sex_2012_reshaped = reshape_demographics_age_data(df_age_sex_2012)\n",
    "df_age_sex_2012_reshaped = df_age_sex_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_age_sex_2016_reshaped = reshape_demographics_age_data(df_age_sex_2016)\n",
    "df_age_sex_2016_reshaped = df_age_sex_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_age_sex_2020_reshaped = reshape_demographics_age_data(df_age_sex_2020)\n",
    "df_age_sex_2020_reshaped = df_age_sex_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_age_sex_2012_reshaped.to_csv('data/election/census/census_age_sex_2012_reshaped.csv', index=False)\n",
    "df_age_sex_2016_reshaped.to_csv('data/election/census/census_age_sex_2016_reshaped.csv', index=False)\n",
    "df_age_sex_2020_reshaped.to_csv('data/election/census/census_age_sex_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape Employment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_employment_data(df, year):\n",
    "    \"\"\"\n",
    "    Reshape county-level census data from wide format to long format with counties as rows,\n",
    "    creating separate columns for Total, Labor Force, Employed, and Unemployment rate for each category.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with county data in wide format\n",
    "    year (int): Census year (2012 or 2016/2020) to determine column naming format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped DataFrame with counties as rows\n",
    "    \"\"\"\n",
    "    # Define metric mappings based on year\n",
    "    if year == 2012:\n",
    "        metric_mappings = {\n",
    "            'Total': 'Total',\n",
    "            'In labor force': 'labor_force',\n",
    "            'Employed': 'employed',\n",
    "            'Unemployment rate': 'unemployment_rate'\n",
    "        }\n",
    "    else:  # 2016 or 2020\n",
    "        metric_mappings = {\n",
    "            'Total': 'Total',\n",
    "            'Labor Force Participation Rate': 'labor_force',\n",
    "            'Employment/Population Ratio': 'employed',\n",
    "            'Unemployment rate': 'unemployment_rate'\n",
    "        }\n",
    "    \n",
    "    # Get the Label column values as our new column names, filtering out header rows\n",
    "    row_categories = []\n",
    "    for idx, label in enumerate(df['Label (Grouping)']):\n",
    "        if pd.notna(label):\n",
    "            # Skip if row is all caps and contains no data (header row)\n",
    "            if not (str(label).isupper() and df.iloc[idx, 1:].isna().all()):\n",
    "                row_categories.append((idx, label))\n",
    "    \n",
    "    # Process each unique county\n",
    "    counties_data = []\n",
    "    \n",
    "    # Get unique county-state combinations\n",
    "    county_columns = [col for col in df.columns if '!!' in col]\n",
    "    unique_counties = set()\n",
    "    for col in county_columns:\n",
    "        county_state = col.split('!!')[0]\n",
    "        if ',' in county_state:\n",
    "            unique_counties.add(county_state)\n",
    "            \n",
    "    # Process each county\n",
    "    for county_state in unique_counties:\n",
    "        county_name, state_name = county_state.split(',', 1)\n",
    "        state_name = state_name.strip()\n",
    "        \n",
    "        # Create a dictionary for this county's data\n",
    "        county_data = {\n",
    "            'county_name': county_name,\n",
    "            'state_name': state_name\n",
    "        }\n",
    "        print('processing', county_name, state_name)\n",
    "        \n",
    "        # For each demographic category\n",
    "        for idx, category in row_categories:\n",
    "            category_clean = (category.replace(' ', '_')\n",
    "                            .replace('(', '')\n",
    "                            .replace(')', '')\n",
    "                            .replace(',', '')\n",
    "                            .replace('/', '_')\n",
    "                            .replace('-', '_')\n",
    "                            .replace('...', ''))\n",
    "            \n",
    "            # Get the four metrics for this category using the appropriate mapping\n",
    "            for original_metric, clean_metric in metric_mappings.items():\n",
    "                col_name = f\"{county_state}!!{original_metric}!!Estimate\"\n",
    "                if col_name in df.columns:\n",
    "                    value = df.iloc[idx][col_name]\n",
    "                    \n",
    "                    # Convert percentage strings to floats if possible\n",
    "                    if isinstance(value, str):\n",
    "                        if value in ['-', '(X)']:\n",
    "                            value = None\n",
    "                        elif '%' in value:\n",
    "                            try:\n",
    "                                value = float(value.strip('%')) / 100\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                    \n",
    "                    # Create clean column name\n",
    "                    final_col_name = f\"{category_clean}_{clean_metric}\"\n",
    "                    county_data[final_col_name] = value\n",
    "        \n",
    "        counties_data.append(county_data)\n",
    "    \n",
    "    # Create the final DataFrame\n",
    "    result_df = pd.DataFrame(counties_data)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_employment_2012_reshaped = reshape_employment_data(df_age_employment_2012, 2012)\n",
    "df_age_employment_2012_reshaped = df_age_employment_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_employment_2016_reshaped = reshape_employment_data(df_age_employment_2016, 2016)\n",
    "df_age_employment_2016_reshaped = df_age_employment_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_employment_2020_reshaped = reshape_employment_data(df_age_employment_2020, 2020)\n",
    "df_age_employment_2020_reshaped = df_age_employment_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_age_employment_2012_reshaped.to_csv('data/election/census/census_age_employment_2012_reshaped.csv', index=False)\n",
    "df_age_employment_2016_reshaped.to_csv('data/election/census/census_age_employment_2016_reshaped.csv', index=False)\n",
    "df_age_employment_2020_reshaped.to_csv('data/election/census/census_age_employment_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape Industry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_industry_data(df):\n",
    "    \"\"\"\n",
    "    Reshape county-level occupation data from wide format to long format with counties as rows,\n",
    "    creating separate columns for total workers and percentage in each occupation category.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with county occupation data in wide format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped DataFrame with counties as rows\n",
    "    \"\"\"\n",
    "    # Get the Label column values as our new column names, filtering out header rows\n",
    "    row_categories = []\n",
    "    for idx, label in enumerate(df['Label (Grouping)']):\n",
    "        if pd.notna(label):\n",
    "            # Skip if row is all caps or percent imputed rows\n",
    "            if not (str(label).isupper() or 'PERCENT' in str(label)):\n",
    "                row_categories.append((idx, label))\n",
    "    \n",
    "    # Define occupation categories in order\n",
    "    occupation_categories = [\n",
    "        'Total',\n",
    "        'Management, business, science, and arts occupations',\n",
    "        'Service occupations',\n",
    "        'Sales and office occupations',\n",
    "        'Natural resources, construction, and maintenance occupations',\n",
    "        'Production, transportation, and material moving occupations'\n",
    "    ]\n",
    "    \n",
    "    # Process each unique county\n",
    "    counties_data = []\n",
    "    \n",
    "    # Get unique county-state combinations\n",
    "    county_columns = [col for col in df.columns if '!!' in col]\n",
    "    unique_counties = set()\n",
    "    for col in county_columns:\n",
    "        county_state = col.split('!!')[0]\n",
    "        if ',' in county_state:\n",
    "            unique_counties.add(county_state)\n",
    "    \n",
    "    # Process each county\n",
    "    for county_state in unique_counties:\n",
    "        county_name, state_name = county_state.split(',', 1)\n",
    "        state_name = state_name.strip()\n",
    "        \n",
    "        # Create a dictionary for this county's data\n",
    "        county_data = {\n",
    "            'county_name': county_name,\n",
    "            'state_name': state_name\n",
    "        }\n",
    "        \n",
    "        # For each industry category\n",
    "        for idx, category in row_categories:\n",
    "            category_clean = (category.replace(' ', '_')\n",
    "                            .replace('(', '')\n",
    "                            .replace(')', '')\n",
    "                            .replace(',', '')\n",
    "                            .replace('/', '_')\n",
    "                            .replace('-', '_')\n",
    "                            .replace('.', '')\n",
    "                            .replace('...', ''))\n",
    "            \n",
    "            # Get values for total and each occupation percentage\n",
    "            for occupation in occupation_categories:\n",
    "                col_name = f\"{county_state}!!{occupation}!!Estimate\"\n",
    "                if col_name in df.columns:\n",
    "                    value = df.iloc[idx][col_name]\n",
    "                    \n",
    "                    # Convert percentage strings to floats if possible\n",
    "                    if isinstance(value, str):\n",
    "                        if value == '-' or value == '(X)':\n",
    "                            value = None\n",
    "                        elif '%' in value:\n",
    "                            try:\n",
    "                                value = float(value.strip('%')) / 100\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                    \n",
    "                    # Create clean column name\n",
    "                    if occupation == 'Total':\n",
    "                        suffix = 'total_workers'\n",
    "                    else:\n",
    "                        occupation_clean = (occupation.replace(' ', '_')\n",
    "                                         .replace(',', '')\n",
    "                                         .replace('_and_', '_')\n",
    "                                         .lower())\n",
    "                        suffix = f'pct_{occupation_clean}'\n",
    "                    \n",
    "                    final_col_name = f\"{category_clean}_{suffix}\"\n",
    "                    county_data[final_col_name] = value\n",
    "        \n",
    "        counties_data.append(county_data)\n",
    "    \n",
    "    # Create the final DataFrame\n",
    "    result_df = pd.DataFrame(counties_data)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_common_columns(df_2012, df_2016, df_2020):\n",
    "    \"\"\"\n",
    "    Find common columns across three dataframes and sort them by geography \n",
    "    (State, then County within State).\n",
    "    \n",
    "    Parameters:\n",
    "    df_2012, df_2016, df_2020 (pandas.DataFrame): Industry dataframes for different years\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (df_2012_sorted, df_2016_sorted, df_2020_sorted)\n",
    "    \"\"\"\n",
    "\n",
    "    # df_2012_sorted.columns = [col.replace('!!Estimate', '') for col in df_2012_sorted.columns]\n",
    "    df_2012.columns = [col.replace('!!Estimate', '') for col in df_2012.columns]\n",
    "    df_2016.columns = [col.replace('!!Estimate', '') for col in df_2016.columns]\n",
    "    df_2020.columns = [col.replace('!!Estimate', '') for col in df_2020.columns]\n",
    "\n",
    "    # Find common columns\n",
    "    common_columns = list(set(df_2012.columns) & set(df_2016.columns) & set(df_2020.columns))\n",
    "\n",
    "    # # show columns that are not in common_columns\n",
    "    # print('uncommon 2012:')\n",
    "    # for col in df_2012.columns:\n",
    "    #     if col not in common_columns:\n",
    "    #         print(col)\n",
    "\n",
    "    # print('uncommon 2016:')\n",
    "    # for col in df_2016.columns:\n",
    "    #     if col not in common_columns:\n",
    "    #         print(col)\n",
    "\n",
    "    # print('uncommon 2020:')\n",
    "    # for col in df_2020.columns:\n",
    "    #     if col not in common_columns:\n",
    "    #         print(col)\n",
    "    \n",
    "    \n",
    "    # Keep 'Label (Grouping)' as first column if it exists\n",
    "    if 'Label (Grouping)' in common_columns:\n",
    "        common_columns.remove('Label (Grouping)')\n",
    "        sorted_columns = ['Label (Grouping)']\n",
    "    else:\n",
    "        sorted_columns = []\n",
    "    \n",
    "    # Function to extract state and county from column name\n",
    "    def get_location_key(col_name):\n",
    "        if '!!' not in col_name:\n",
    "            return ('', '', col_name)\n",
    "        \n",
    "        location = col_name.split('!!')[0]\n",
    "        category = col_name.split('!!')[1]\n",
    "        \n",
    "        # Handle different location formats\n",
    "        if ',' in location:\n",
    "            county, state = location.split(',', 1)\n",
    "            return (state.strip(), county.strip(), category)\n",
    "        return (location, '', category)\n",
    "    \n",
    "    # Sort the geographical columns\n",
    "    geo_columns = [col for col in common_columns if '!!' in col]\n",
    "    sorted_geo_columns = sorted(geo_columns, key=get_location_key)\n",
    "    \n",
    "    # Add any remaining non-geographic columns at the end\n",
    "    remaining_columns = [col for col in common_columns if '!!' not in col and col != 'Label (Grouping)']\n",
    "    sorted_columns.extend(sorted_geo_columns + remaining_columns)\n",
    "    \n",
    "    # Create new dataframes with sorted columns\n",
    "    df_2012_sorted = df_2012[sorted_columns]\n",
    "    df_2016_sorted = df_2016[sorted_columns]\n",
    "    df_2020_sorted = df_2020[sorted_columns]\n",
    "    \n",
    "    return df_2012_sorted, df_2016_sorted, df_2020_sorted\n",
    "\n",
    "# Example usage:\n",
    "df_2012_sorted, df_2016_sorted, df_2020_sorted = get_sorted_common_columns(\n",
    "    df_industry_2012,\n",
    "    df_industry_2016,\n",
    "    df_industry_2020\n",
    ")\n",
    "\n",
    "# Verify the sorting\n",
    "def verify_sorting(df):\n",
    "    \"\"\"Print first few column names to verify sorting\"\"\"\n",
    "    print(\"First few columns:\")\n",
    "    for col in list(df.columns)[:5]:\n",
    "        print(f\"  {col}\")\n",
    "    print(\"...\")\n",
    "\n",
    "verify_sorting(df_2012_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_industry_dataframes(df_2012, df_2016, df_2020):\n",
    "    \"\"\"\n",
    "    Standardize Label (Grouping) values across three industry dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "    df_2012, df_2016, df_2020 (pandas.DataFrame): Industry dataframes for different years\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (df_2012_clean, df_2016_clean, df_2020_clean)\n",
    "    \"\"\"\n",
    "    def standardize_label(label):\n",
    "        # Remove non-breaking space characters and regular spaces\n",
    "        clean_label = label.replace('\\xa0', '').strip()\n",
    "        \n",
    "        # Map the percent imputed/allocated variations to a standard form\n",
    "        if clean_label in ['PERCENT IMPUTED', 'PERCENT ALLOCATED']:\n",
    "            clean_label = 'PERCENT ALLOCATED'\n",
    "            \n",
    "        return clean_label\n",
    "    \n",
    "    # Create copies of the original dataframes to avoid modifying them\n",
    "    df_2012_clean = df_2012.copy()\n",
    "    df_2016_clean = df_2016.copy()\n",
    "    df_2020_clean = df_2020.copy()\n",
    "    \n",
    "    # Apply standardization to each dataframe\n",
    "    df_2012_clean['Label (Grouping)'] = df_2012_clean['Label (Grouping)'].apply(standardize_label)\n",
    "    df_2016_clean['Label (Grouping)'] = df_2016_clean['Label (Grouping)'].apply(standardize_label)\n",
    "    df_2020_clean['Label (Grouping)'] = df_2020_clean['Label (Grouping)'].apply(standardize_label)\n",
    "    \n",
    "    return df_2012_clean, df_2016_clean, df_2020_clean\n",
    "\n",
    "# Example usage:\n",
    "df_industry_2012_clean, df_industry_2016_clean, df_industry_2020_clean = standardize_industry_dataframes(\n",
    "    df_2012_sorted,\n",
    "    df_2016_sorted,\n",
    "    df_2020_sorted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists of all Label (Grouping) values\n",
    "label_grouping_2012 = df_industry_2012_clean['Label (Grouping)'].tolist()\n",
    "label_grouping_2016 = df_industry_2016_clean['Label (Grouping)'].tolist()\n",
    "label_grouping_2020 = df_industry_2020_clean['Label (Grouping)'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_occupation_categories(df):\n",
    "    \"\"\"\n",
    "    Extract unique occupation subcategories from column names and\n",
    "    verify consistency across all locations.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Dataframe with occupation data\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (list of unique categories, dict of inconsistencies if any)\n",
    "    \"\"\"\n",
    "    # Get columns that contain occupation data (have '!!' delimiter)\n",
    "    occupation_columns = [col for col in df.columns if '!!' in col]\n",
    "    \n",
    "    # Extract categories and group by location\n",
    "    location_categories = {}\n",
    "    all_categories = set()\n",
    "    \n",
    "    for col in occupation_columns:\n",
    "        location, category = col.split('!!', 1)\n",
    "        all_categories.add(category)\n",
    "        \n",
    "        if location not in location_categories:\n",
    "            location_categories[location] = set()\n",
    "        location_categories[location].add(category)\n",
    "    \n",
    "    # Sort categories for consistent output\n",
    "    sorted_categories = sorted(list(all_categories))\n",
    "    \n",
    "    # Check for inconsistencies\n",
    "    inconsistencies = {}\n",
    "    for location, categories in location_categories.items():\n",
    "        missing = all_categories - categories\n",
    "        extra = categories - all_categories\n",
    "        if missing or extra:\n",
    "            inconsistencies[location] = {\n",
    "                'missing': sorted(list(missing)),\n",
    "                'extra': sorted(list(extra))\n",
    "            }\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Found {len(sorted_categories)} unique occupation categories:\")\n",
    "    for i, category in enumerate(sorted_categories, 1):\n",
    "        print(f\"{i}. {category}\")\n",
    "    \n",
    "    print(f\"\\nChecked {len(location_categories)} locations\")\n",
    "    if inconsistencies:\n",
    "        print(f\"Found inconsistencies in {len(inconsistencies)} locations:\")\n",
    "        for location, issues in inconsistencies.items():\n",
    "            print(f\"\\n{location}:\")\n",
    "            if issues['missing']:\n",
    "                print(\"  Missing categories:\")\n",
    "                for cat in issues['missing']:\n",
    "                    print(f\"    - {cat}\")\n",
    "            if issues['extra']:\n",
    "                print(\"  Extra categories:\")\n",
    "                for cat in issues['extra']:\n",
    "                    print(f\"    - {cat}\")\n",
    "    else:\n",
    "        print(\"\\nAll locations have consistent categories!\")\n",
    "    \n",
    "    return sorted_categories, inconsistencies\n",
    "\n",
    "# Example usage:\n",
    "categories, inconsistencies = analyze_occupation_categories(df_industry_2012_clean)\n",
    "\n",
    "# If you just want the list of categories:\n",
    "occupation_categories = categories\n",
    "\n",
    "print(\"\\nOccupation categories list:\")\n",
    "print(occupation_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industry_2016_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the row with 'Label (Grouping)' == 'PERCENT ALLOCATED'\n",
    "df_industry_2012_clean = df_industry_2012_clean[df_industry_2012_clean['Label (Grouping)'] != 'PERCENT ALLOCATED']\n",
    "df_industry_2016_clean = df_industry_2016_clean[df_industry_2016_clean['Label (Grouping)'] != 'PERCENT ALLOCATED']\n",
    "df_industry_2020_clean = df_industry_2020_clean[df_industry_2020_clean['Label (Grouping)'] != 'PERCENT ALLOCATED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reshaped dataframe has 3216 rows (counties) and 102 columns\n",
      "\n",
      "Example column names:\n",
      "\n",
      "Location columns:\n",
      "['county', 'state']\n",
      "\n",
      "Industry total columns:\n",
      "['INDUSTRY_agriculture_forestry_fishing_and_hunting_and_mining_total', 'INDUSTRY_arts_entertainment_and_recreation_and_accommodation_and_food_services_total', 'INDUSTRY_civilian_employed_population_16_years_and_over_total', 'INDUSTRY_construction_total', 'INDUSTRY_educational_services_and_health_care_and_social_assistance_total']\n",
      "\n",
      "Occupation percentage columns:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def reshape_county_data(df):\n",
    "    \"\"\"\n",
    "    Reshape data to have one row per county with:\n",
    "    1. OCCUPATION_category_INDUSTRY_label columns for occupation percentages\n",
    "    2. INDUSTRY_label_total columns for raw counts\n",
    "    3. INDUSTRY_label_percent columns for industry percentages of total employment\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped dataframe with one row per county\n",
    "    \"\"\"\n",
    "    # Get unique counties\n",
    "    counties = set()\n",
    "    for col in df.columns:\n",
    "        if '!!' in col:\n",
    "            county = col.split('!!')[0]\n",
    "            counties.add(county)\n",
    "    \n",
    "    # Define occupation categories\n",
    "    occupations = [\n",
    "        'Management, business, science, and arts occupations',\n",
    "        'Natural resources, construction, and maintenance occupations',\n",
    "        'Production, transportation, and material moving occupations',\n",
    "        'Sales and office occupations',\n",
    "        'Service occupations',\n",
    "        'Total'\n",
    "    ]\n",
    "    \n",
    "    county_data = []\n",
    "    \n",
    "    for county in counties:\n",
    "        row_data = {}\n",
    "        \n",
    "        # Add county and state information\n",
    "        if ',' in county:\n",
    "            county_name, state = county.split(',', 1)\n",
    "            row_data['county'] = county_name.strip()\n",
    "            row_data['state'] = state.strip()\n",
    "        else:\n",
    "            row_data['location'] = county\n",
    "            row_data['state'] = ''\n",
    "        \n",
    "        # First pass: Get total employed population for percentage calculations\n",
    "        total_employed = None\n",
    "        for idx, row in df.iterrows():\n",
    "            label = row['Label (Grouping)']\n",
    "            if pd.isna(label) or label.strip() == '':\n",
    "                continue\n",
    "                \n",
    "            if label == 'Civilian employed population 16 years and over':\n",
    "                total_col = f\"{county}!!Total\"\n",
    "                if total_col in df.columns:\n",
    "                    value = row[total_col]\n",
    "                    if value != '(X)':\n",
    "                        try:\n",
    "                            total_employed = float(str(value).replace(',', ''))\n",
    "                            row_data['total_civilian_employed'] = total_employed\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "                break\n",
    "        \n",
    "        # Process each industry label\n",
    "        for idx, row in df.iterrows():\n",
    "            label = row['Label (Grouping)']\n",
    "            if pd.isna(label) or label.strip() == '':\n",
    "                continue\n",
    "            \n",
    "            # Special handling for Industry row\n",
    "            if label == 'Industry':\n",
    "                total_col = f\"{county}!!Total\"\n",
    "                if total_col in df.columns:\n",
    "                    value = row[total_col]\n",
    "                    if value != '(X)':\n",
    "                        row_data['INDUSTRY_industrial_total'] = value\n",
    "                continue\n",
    "            \n",
    "            # Clean industry label\n",
    "            clean_industry = (label.lower()\n",
    "                            .replace(' ', '_')\n",
    "                            .replace(',', '')\n",
    "                            .replace('...', '')\n",
    "                            .replace('(', '')\n",
    "                            .replace(')', '')\n",
    "                            .replace('-', '_')\n",
    "                            .strip('_'))\n",
    "            \n",
    "            # For all other rows, get all occupation categories\n",
    "            for occ in occupations:\n",
    "                col = f\"{county}!!{occ}\"\n",
    "                if col in df.columns:\n",
    "                    value = row[col]\n",
    "                    if value != '(X)' and not pd.isna(value):\n",
    "                        # Clean occupation name\n",
    "                        clean_occ = (occ.lower()\n",
    "                                   .replace(' ', '_')\n",
    "                                   .replace(',', '')\n",
    "                                   .replace('(', '')\n",
    "                                   .replace(')', '')\n",
    "                                   .replace('-', '_'))\n",
    "                        \n",
    "                        if occ == 'Total':\n",
    "                            # For total values, use simpler naming\n",
    "                            col_name = f\"INDUSTRY_{clean_industry}_total\"\n",
    "                            # Add the industry percentage if we have total employed\n",
    "                            if total_employed is not None:\n",
    "                                try:\n",
    "                                    total_value = float(str(value).replace(',', ''))\n",
    "                                    percent_col_name = f\"INDUSTRY_{clean_industry}_percent\"\n",
    "                                    row_data[percent_col_name] = total_value / total_employed\n",
    "                                except (ValueError, ZeroDivisionError):\n",
    "                                    pass\n",
    "                        else:\n",
    "                            # For occupation percentages, use OCCUPATION_category_INDUSTRY_label format\n",
    "                            col_name = f\"INDUSTRY_{clean_industry}_OCCUPATION_{clean_occ}_percent\"\n",
    "                        \n",
    "                        # Convert percentage strings to floats\n",
    "                        if isinstance(value, str):\n",
    "                            if '%' in value:\n",
    "                                value = float(value.strip('%')) / 100\n",
    "                            else:\n",
    "                                try:\n",
    "                                    value = float(value.replace(',', ''))\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "                        \n",
    "                        row_data[col_name] = value\n",
    "        \n",
    "        county_data.append(row_data)\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    result_df = pd.DataFrame(county_data)\n",
    "    \n",
    "    # Sort columns to group related fields together\n",
    "    location_cols = ['county', 'state', 'location', 'total_civilian_employed']\n",
    "    industry_total_cols = [col for col in result_df.columns if col.endswith('_total')]\n",
    "    # industry_percent_cols = [col for col in result_df.columns if col.endswith('_percent')]\n",
    "    industry_percent_cols = [col for col in result_df.columns if 'INDUSTRY_' in col and '_percent' in col]\n",
    "    occupation_cols = [col for col in result_df.columns if col.startswith('OCCUPATION_')]\n",
    "    \n",
    "    sorted_columns = (\n",
    "        [col for col in location_cols if col in result_df.columns] +\n",
    "        sorted(industry_total_cols) +\n",
    "        sorted(industry_percent_cols) +\n",
    "        sorted(occupation_cols)\n",
    "    )\n",
    "    \n",
    "    result_df = result_df[sorted_columns]\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Example usage:\n",
    "reshaped_df = reshape_county_data(df_industry_2012_clean)\n",
    "\n",
    "# Display info about the transformed data\n",
    "print(f\"\\nReshaped dataframe has {len(reshaped_df)} rows (counties) and {len(reshaped_df.columns)} columns\")\n",
    "print(\"\\nExample column names:\")\n",
    "print(\"\\nLocation columns:\")\n",
    "print([col for col in reshaped_df.columns if col in ['county', 'state', 'location']][:5])\n",
    "print(\"\\nIndustry total columns:\")\n",
    "print([col for col in reshaped_df.columns if col.endswith('_total')][:5])\n",
    "print(\"\\nOccupation percentage columns:\")\n",
    "print([col for col in reshaped_df.columns if col.startswith('OCCUPATION_')][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change col name INDUSTRY_industrial_total to INDUSTRY_industrial_percent and convert the value from a string with percnt sign to a float\n",
    "reshaped_df = reshaped_df.rename(columns={'INDUSTRY_industrial_total': 'INDUSTRY_industrial_percent'})\n",
    "reshaped_df['INDUSTRY_industrial_percent'] = reshaped_df['INDUSTRY_industrial_percent'].str.replace('%', '').astype(float)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for columns that contain 'civilian_employed_population_16_years_and_over', change that part to 'employed_total'\n",
    "reshaped_df.columns = [col.replace('civilian_employed_population_16_years_and_over', 'employed') for col in reshaped_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industry_2012_reshaped = reshape_county_data(df_industry_2012_clean)\n",
    "df_industry_2016_reshaped = reshape_county_data(df_industry_2016_clean)\n",
    "df_industry_2020_reshaped = reshape_county_data(df_industry_2020_clean)\n",
    "\n",
    "df_industry_2012_reshaped = df_industry_2012_reshaped.rename(columns={'INDUSTRY_industrial_total': 'INDUSTRY_industrial_percent'})\n",
    "df_industry_2012_reshaped['INDUSTRY_industrial_percent'] = df_industry_2012_reshaped['INDUSTRY_industrial_percent'].str.replace('%', '').astype(float)/100\n",
    "df_industry_2016_reshaped = df_industry_2016_reshaped.rename(columns={'INDUSTRY_industrial_total': 'INDUSTRY_industrial_percent'})\n",
    "df_industry_2016_reshaped['INDUSTRY_industrial_percent'] = df_industry_2016_reshaped['INDUSTRY_industrial_percent'].str.replace('%', '').astype(float)/100\n",
    "df_industry_2020_reshaped = df_industry_2020_reshaped.rename(columns={'INDUSTRY_industrial_total': 'INDUSTRY_industrial_percent'})\n",
    "df_industry_2020_reshaped['INDUSTRY_industrial_percent'] = df_industry_2020_reshaped['INDUSTRY_industrial_percent'].str.replace('%', '').astype(float)/100\n",
    "\n",
    "df_industry_2012_reshaped.columns = [col.replace('civilian_employed_population_16_years_and_over', 'employed') for col in df_industry_2012_reshaped.columns]\n",
    "df_industry_2016_reshaped.columns = [col.replace('civilian_employed_population_16_years_and_over', 'employed') for col in df_industry_2016_reshaped.columns]\n",
    "df_industry_2020_reshaped.columns = [col.replace('civilian_employed_population_16_years_and_over', 'employed') for col in df_industry_2020_reshaped.columns]\n",
    "\n",
    "df_industry_2012_reshaped.columns = [col.replace('civilian', '') for col in df_industry_2012_reshaped.columns]\n",
    "df_industry_2016_reshaped.columns = [col.replace('civilian', '') for col in df_industry_2016_reshaped.columns]\n",
    "df_industry_2020_reshaped.columns = [col.replace('civilian', '') for col in df_industry_2020_reshaped.columns]\n",
    "\n",
    "df_industry_2012_reshaped = df_industry_2012_reshaped.sort_values(by=['state', 'county']).reset_index(drop=True)\n",
    "df_industry_2016_reshaped = df_industry_2016_reshaped.sort_values(by=['state', 'county']).reset_index(drop=True)\n",
    "df_industry_2020_reshaped = df_industry_2020_reshaped.sort_values(by=['state', 'county']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_industry_2012_reshaped.to_csv('../../data/election/census/census_industry_2012_reshaped.csv', index=False)\n",
    "df_industry_2016_reshaped.to_csv('../../data/election/census/census_industry_2016_reshaped.csv', index=False)\n",
    "df_industry_2020_reshaped.to_csv('../../data/election/census/census_industry_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape housing financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_housing_financial_data(df):\n",
    "    \"\"\"\n",
    "    Reshape county-level housing financial data from wide format to long format with counties as rows,\n",
    "    creating separate columns for total, owner-occupied, and renter-occupied housing metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with county housing data in wide format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped DataFrame with counties as rows\n",
    "    \"\"\"\n",
    "    # Get the Label column values as our new column names, filtering out header rows\n",
    "    row_categories = []\n",
    "    for idx, label in enumerate(df['Label (Grouping)']):\n",
    "        if pd.notna(label):\n",
    "            # Skip if row is all caps, header rows, or percent imputed\n",
    "            if not (str(label).isupper() or 'PERCENT' in str(label)):\n",
    "                row_categories.append((idx, label))\n",
    "    \n",
    "    # Define housing categories\n",
    "    housing_categories = [\n",
    "        'Occupied housing units',\n",
    "        'Owner-occupied housing units',\n",
    "        'Renter-occupied housing units'\n",
    "    ]\n",
    "    \n",
    "    # Process each unique county\n",
    "    counties_data = []\n",
    "    \n",
    "    # Get unique county-state combinations\n",
    "    county_columns = [col for col in df.columns if '!!' in col]\n",
    "    unique_counties = set()\n",
    "    for col in county_columns:\n",
    "        county_state = col.split('!!')[0]\n",
    "        if ',' in county_state:\n",
    "            unique_counties.add(county_state)\n",
    "    \n",
    "    # Process each county\n",
    "    for county_state in unique_counties:\n",
    "        county_name, state_name = county_state.split(',', 1)\n",
    "        state_name = state_name.strip()\n",
    "        \n",
    "        # Create a dictionary for this county's data\n",
    "        county_data = {\n",
    "            'county_name': county_name,\n",
    "            'state_name': state_name\n",
    "        }\n",
    "        \n",
    "        # For each financial metric\n",
    "        for idx, category in row_categories:\n",
    "            category_clean = (category.replace(' ', '_')\n",
    "                            .replace('(', '')\n",
    "                            .replace(')', '')\n",
    "                            .replace(',', '')\n",
    "                            .replace('/', '_')\n",
    "                            .replace('-', '_')\n",
    "                            .replace('.', '')\n",
    "                            .replace('...', '')\n",
    "                            .replace('$', '')\n",
    "                            .replace('__', '_')\n",
    "                            .lower())\n",
    "            \n",
    "            # Get values for each housing category\n",
    "            for housing_type in housing_categories:\n",
    "                col_name = f\"{county_state}!!{housing_type}!!Estimate\"\n",
    "                if col_name in df.columns:\n",
    "                    value = df.iloc[idx][col_name]\n",
    "                    \n",
    "                    # Convert percentage strings to floats if possible\n",
    "                    if isinstance(value, str):\n",
    "                        if value == '-' or value == '(X)':\n",
    "                            value = None\n",
    "                        elif '%' in value:\n",
    "                            try:\n",
    "                                value = float(value.strip('%')) / 100\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                        # Handle dollar amounts\n",
    "                        elif '$' in value or ',' in value:\n",
    "                            try:\n",
    "                                value = float(value.replace('$', '').replace(',', ''))\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                    \n",
    "                    # Create clean column name\n",
    "                    housing_type_clean = (housing_type.replace(' ', '_')\n",
    "                                        .replace('-', '_')\n",
    "                                        .lower())\n",
    "                    final_col_name = f\"{category_clean}_{housing_type_clean}\"\n",
    "                    county_data[final_col_name] = value\n",
    "        \n",
    "        counties_data.append(county_data)\n",
    "    \n",
    "    # Create the final DataFrame\n",
    "    result_df = pd.DataFrame(counties_data)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_financial_2012_reshaped = reshape_housing_financial_data(df_housing_financial_2012)\n",
    "df_housing_financial_2012_reshaped = df_housing_financial_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_housing_financial_2016_reshaped = reshape_housing_financial_data(df_housing_financial_2016)\n",
    "df_housing_financial_2016_reshaped = df_housing_financial_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_housing_financial_2020_reshaped = reshape_housing_financial_data(df_housing_financial_2020)\n",
    "df_housing_financial_2020_reshaped = df_housing_financial_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_housing_financial_2012_reshaped.to_csv('data/election/census/census_housing_financial_2012_reshaped.csv', index=False)\n",
    "df_housing_financial_2016_reshaped.to_csv('data/election/census/census_housing_financial_2016_reshaped.csv', index=False)\n",
    "df_housing_financial_2020_reshaped.to_csv('data/election/census/census_housing_financial_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape veteran status data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_veteran_data(df):\n",
    "    \"\"\"\n",
    "    Reshape county-level veteran status data from wide format to long format with counties as rows,\n",
    "    creating separate columns for total population, veterans, and nonveterans metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with county veteran data in wide format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped DataFrame with counties as rows\n",
    "    \"\"\"\n",
    "    # Get the Label column values as our new column names, filtering out header rows\n",
    "    row_categories = []\n",
    "    for idx, label in enumerate(df['Label (Grouping)']):\n",
    "        if pd.notna(label):\n",
    "            # Skip if row is all caps, header rows, or percent imputed\n",
    "            if not (str(label).isupper() or 'PERCENT' in str(label)):\n",
    "                row_categories.append((idx, label))\n",
    "    \n",
    "    # Define status categories\n",
    "    status_categories = [\n",
    "        'Total',\n",
    "        'Veterans',\n",
    "        'Nonveterans'\n",
    "    ]\n",
    "    \n",
    "    # Process each unique county\n",
    "    counties_data = []\n",
    "    \n",
    "    # Get unique county-state combinations\n",
    "    county_columns = [col for col in df.columns if '!!' in col]\n",
    "    unique_counties = set()\n",
    "    for col in county_columns:\n",
    "        county_state = col.split('!!')[0]\n",
    "        if ',' in county_state:\n",
    "            unique_counties.add(county_state)\n",
    "    \n",
    "    # Process each county\n",
    "    for county_state in unique_counties:\n",
    "        county_name, state_name = county_state.split(',', 1)\n",
    "        state_name = state_name.strip()\n",
    "        \n",
    "        # Create a dictionary for this county's data\n",
    "        county_data = {\n",
    "            'county_name': county_name,\n",
    "            'state_name': state_name\n",
    "        }\n",
    "        \n",
    "        # For each demographic/service metric\n",
    "        for idx, category in row_categories:\n",
    "            category_clean = (category.replace(' ', '_')\n",
    "                            .replace('(', '')\n",
    "                            .replace(')', '')\n",
    "                            .replace(',', '')\n",
    "                            .replace('/', '_')\n",
    "                            .replace('-', '_')\n",
    "                            .replace('.', '')\n",
    "                            .replace('...', '')\n",
    "                            .replace('$', '')\n",
    "                            .replace('__', '_')\n",
    "                            .lower())\n",
    "            \n",
    "            # Special handling for period of service categories\n",
    "            is_period_of_service = 'veterans' in category_clean and any(period in category_clean \n",
    "                                                                      for period in ['gulf_war', 'vietnam', 'korean', 'world_war'])\n",
    "            \n",
    "            # Get values for each status category\n",
    "            for status in status_categories:\n",
    "                col_name = f\"{county_state}!!{status}!!Estimate\"\n",
    "                if col_name in df.columns:\n",
    "                    value = df.iloc[idx][col_name]\n",
    "                    \n",
    "                    # Convert percentage strings to floats if possible\n",
    "                    if isinstance(value, str):\n",
    "                        if value == '-' or value == '(X)':\n",
    "                            value = None\n",
    "                        elif '%' in value:\n",
    "                            try:\n",
    "                                value = float(value.strip('%')) / 100\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                        # Handle dollar amounts\n",
    "                        elif '$' in value or ',' in value:\n",
    "                            try:\n",
    "                                value = float(value.replace('$', '').replace(',', ''))\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                    \n",
    "                    # Create clean column name\n",
    "                    if is_period_of_service:\n",
    "                        # For period of service, only store veteran percentage\n",
    "                        if status == 'Veterans':\n",
    "                            final_col_name = f\"pct_{category_clean}\"\n",
    "                            county_data[final_col_name] = value\n",
    "                    else:\n",
    "                        # For other metrics, store all three categories\n",
    "                        status_clean = status.lower()\n",
    "                        final_col_name = f\"{category_clean}_{status_clean}\"\n",
    "                        county_data[final_col_name] = value\n",
    "        \n",
    "        counties_data.append(county_data)\n",
    "    \n",
    "    # Create the final DataFrame\n",
    "    result_df = pd.DataFrame(counties_data)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veteran_status_2012_reshaped = reshape_veteran_data(df_veteran_status_2012)\n",
    "df_veteran_status_2012_reshaped = df_veteran_status_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_veteran_status_2016_reshaped = reshape_veteran_data(df_veteran_status_2016)\n",
    "df_veteran_status_2016_reshaped = df_veteran_status_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_veteran_status_2020_reshaped = reshape_veteran_data(df_veteran_status_2020)\n",
    "df_veteran_status_2020_reshaped = df_veteran_status_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_veteran_status_2012_reshaped.to_csv('data/election/census/census_veteran_status_2012_reshaped.csv', index=False)\n",
    "df_veteran_status_2016_reshaped.to_csv('data/election/census/census_veteran_status_2016_reshaped.csv', index=False)\n",
    "df_veteran_status_2020_reshaped.to_csv('data/election/census/census_veteran_status_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stack dataframes in list for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # race dataframes\n",
    "# df_race_list = [df_race_2012_reshaped, df_race_2016_reshaped, df_race_2020_reshaped]\n",
    "# # age_sex dataframes\n",
    "# df_age_sex_list = [df_age_sex_2012_reshaped, df_age_sex_2016_reshaped, df_age_sex_2020_reshaped]\n",
    "# # age_employment dataframes\n",
    "# df_age_employment_list = [df_age_employment_2012_reshaped, df_age_employment_2016_reshaped, df_age_employment_2020_reshaped]\n",
    "# # industry dataframes\n",
    "df_industry_list = [df_industry_2012_reshaped, df_industry_2016_reshaped, df_industry_2020_reshaped]\n",
    "# # housing_financial dataframes\n",
    "# df_housing_financial_list = [df_housing_financial_2012_reshaped, df_housing_financial_2016_reshaped, df_housing_financial_2020_reshaped]\n",
    "# # veteran_status dataframes\n",
    "# df_veteran_status_list = [df_veteran_status_2012_reshaped, df_veteran_status_2016_reshaped, df_veteran_status_2020_reshaped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the row with county_name 'index' in the df_race_list dataframes\n",
    "for df in df_race_list:\n",
    "    df.drop(df[df['county_name'] == 'index'].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop rows where state_name is 'Puerto Rico' or 'Alaska' or 'Hawaii' or 'District of Columbia' in all dataframe lists\n",
    "# for df in df_race_list:\n",
    "#     df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "#     df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# for df in df_age_sex_list:\n",
    "#     df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "#     df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# for df in df_age_employment_list:\n",
    "#     df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "#     df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for df in df_industry_list:\n",
    "    df.drop(df[df['state'] == 'Puerto Rico'].index, inplace=True)\n",
    "    df.drop(df[df['state'] == 'Alaska'].index, inplace=True)\n",
    "    df.drop(df[df['state'] == 'Hawaii'].index, inplace=True)\n",
    "    df.drop(df[df['state'] == 'District of Columbia'].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# for df in df_housing_financial_list:\n",
    "#     df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "#     df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# for df in df_veteran_status_list:\n",
    "#     df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "#     df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "#     df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show rows where county_name does not contain 'County' or 'Parish' or 'city' or 'Borough\n",
    "df2[~df2['county_name'].str.contains('County|Parish|city|Borough')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_abbr_to_name = {\n",
    "    'AL': 'Alabama',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "state_name_to_abbr = {v: k for k, v in state_abbr_to_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df2['state_abbr'] = df2['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "# # for all dataframes lists, add a column for state_abbr\n",
    "# for df in df_race_list:\n",
    "#     df['state_abbr'] = df['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "# for df in df_age_sex_list:\n",
    "#     df['state_abbr'] = df['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "# for df in df_age_employment_list:\n",
    "#     df['state_abbr'] = df['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "for df in df_industry_list:\n",
    "    df['state_abbr'] = df['state'].map(state_name_to_abbr)\n",
    "\n",
    "# for df in df_housing_financial_list:\n",
    "#     df['state_abbr'] = df['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "# for df in df_veteran_status_list:\n",
    "#     df['state_abbr'] = df['state_name'].map(state_name_to_abbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change state to state_name and county to county_name in df_industry_list dataframes\n",
    "for df in df_industry_list:\n",
    "    df.rename(columns={'state': 'state_name', 'county': 'county_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add FIPS codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "\n",
    "def clean_place_name(name):\n",
    "    \"\"\"Clean place names for consistent matching\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    \n",
    "    # Convert to string and clean accented characters\n",
    "    name = str(name)\n",
    "    name = unidecode.unidecode(name)\n",
    "    \n",
    "    # Standardize spaces and case\n",
    "    name = name.strip()\n",
    "    \n",
    "    # Standardize specific terms\n",
    "    replacements = {\n",
    "        'Municipality': 'Municipio',\n",
    "        'City and Borough': 'Borough',\n",
    "        'Census Area': 'Census Area',\n",
    "        ' city': ' City',\n",
    "        'LaSalle': 'La Salle',\n",
    "        'LaPorte': 'La Porte',\n",
    "        'DeSoto': 'De Soto',\n",
    "        'DeKalb': 'De Kalb',\n",
    "        'St.': 'St',\n",
    "        'Ste.': 'Ste'\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        name = name.replace(old, new)\n",
    "    \n",
    "    return name\n",
    "\n",
    "def add_fips_codes(census_df, fips_csv_path):\n",
    "    \"\"\"\n",
    "    Add FIPS codes to census data by matching county and state.\n",
    "    Handles special cases for Alaska, Puerto Rico, and Virginia.\n",
    "    \n",
    "    Parameters:\n",
    "    census_df (pandas.DataFrame): Census dataframe with county_name and state_abbr columns\n",
    "    fips_csv_path (str): Path to the FIPS CSV file\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Census dataframe with FIPS codes added\n",
    "    \"\"\"\n",
    "    # Read FIPS data\n",
    "    fips_df = pd.read_csv(fips_csv_path)\n",
    "    \n",
    "    # Filter out non-place rows (like \"UNITED STATES\" and state-level entries)\n",
    "    fips_df = fips_df[~fips_df['name'].isna()]\n",
    "    fips_df = fips_df[fips_df['name'].str.contains('County|Borough|Parish|Census Area|city|Municipio', \n",
    "                                                  case=False, na=False)]\n",
    "    \n",
    "    # Clean up names in both dataframes\n",
    "    census_df = census_df.copy()\n",
    "    census_df['clean_name'] = census_df['county_name'].apply(clean_place_name)\n",
    "    fips_df['clean_name'] = fips_df['name'].apply(clean_place_name)\n",
    "    \n",
    "    # # Special handling for DC\n",
    "    # dc_mask = census_df['county_name'] == 'District of Columbia'\n",
    "    # census_df.loc[dc_mask, 'state_abbr'] = 'DC'\n",
    "    \n",
    "    # # Handle cases where state_abbr might be NaN\n",
    "    # state_map = {\n",
    "    #     'Borough': 'AK',\n",
    "    #     'Census Area': 'AK',\n",
    "    #     'Municipio': 'PR'\n",
    "    # }\n",
    "    \n",
    "    # for identifier, state_code in state_map.items():\n",
    "    #     mask = census_df['county_name'].str.contains(identifier, na=False)\n",
    "    #     census_df.loc[mask, 'state_abbr'] = state_code\n",
    "    \n",
    "    # Merge the dataframes\n",
    "    result = pd.merge(\n",
    "        census_df,\n",
    "        fips_df[['fips', 'clean_name', 'state']],\n",
    "        how='left',\n",
    "        left_on=['clean_name', 'state_abbr'],\n",
    "        right_on=['clean_name', 'state']\n",
    "    )\n",
    "    \n",
    "    # Drop the working columns\n",
    "    result = result.drop(['clean_name', 'state'], axis=1)\n",
    "    \n",
    "    # Convert FIPS codes to strings with leading zeros\n",
    "    result['fips'] = result['fips'].astype(str).str.zfill(5)\n",
    "    \n",
    "    # Rename the FIPS column\n",
    "    result = result.rename(columns={'fips': 'fips_code'})\n",
    "    \n",
    "    # Check for unmatched counties\n",
    "    unmatched = result[result['fips_code'].isna()]\n",
    "    if len(unmatched) > 0:\n",
    "        print(f\"\\nWarning: {len(unmatched)} places could not be matched with FIPS codes:\")\n",
    "        for _, row in unmatched.iterrows():\n",
    "            print(f\"- {row['county_name']}, {row['state_abbr']}\")\n",
    "    \n",
    "    # Reorder columns to put fips_code after state_name\n",
    "    cols = list(result.columns)\n",
    "    state_name_idx = cols.index('state_name')\n",
    "    cols.remove('fips_code')\n",
    "    cols.insert(state_name_idx + 1, 'fips_code')\n",
    "    result = result[cols]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/election/fips_state_and_county.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[228], line 29\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # # add fips codes to all dataframes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# # for df in df_race_list:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# #     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# df_age_employment_2016_reshaped = add_fips_codes(df_age_employment_2016_reshaped, 'data/election/fips_state_and_county.csv')\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# df_age_employment_2020_reshaped = add_fips_codes(df_age_employment_2020_reshaped, 'data/election/fips_state_and_county.csv')\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m df_industry_2012_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43madd_fips_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_industry_2012_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/election/fips_state_and_county.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m df_industry_2016_reshaped \u001b[38;5;241m=\u001b[39m add_fips_codes(df_industry_2016_reshaped, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/election/fips_state_and_county.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m df_industry_2020_reshaped \u001b[38;5;241m=\u001b[39m add_fips_codes(df_industry_2020_reshaped, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/election/fips_state_and_county.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[227], line 48\u001b[0m, in \u001b[0;36madd_fips_codes\u001b[1;34m(census_df, fips_csv_path)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03mAdd FIPS codes to census data by matching county and state.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03mHandles special cases for Alaska, Puerto Rico, and Virginia.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03mpandas.DataFrame: Census dataframe with FIPS codes added\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Read FIPS data\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m fips_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfips_csv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Filter out non-place rows (like \"UNITED STATES\" and state-level entries)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m fips_df \u001b[38;5;241m=\u001b[39m fips_df[\u001b[38;5;241m~\u001b[39mfips_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()]\n",
      "File \u001b[1;32mc:\\Users\\bovam\\miniconda3\\envs\\aispace\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bovam\\miniconda3\\envs\\aispace\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bovam\\miniconda3\\envs\\aispace\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bovam\\miniconda3\\envs\\aispace\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\bovam\\miniconda3\\envs\\aispace\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bovam\\miniconda3\\envs\\aispace\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\bovam\\miniconda3\\envs\\aispace\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/election/fips_state_and_county.csv'"
     ]
    }
   ],
   "source": [
    "# # # add fips codes to all dataframes\n",
    "# # for df in df_race_list:\n",
    "# #     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# # for df in df_age_sex_list:\n",
    "# #     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# # for df in df_age_employment_list:\n",
    "# #     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# # for df in df_industry_list:\n",
    "# #     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# # for df in df_housing_financial_list:\n",
    "# #     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# # for df in df_veteran_status_list:\n",
    "# #     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# df_race_2012_reshaped = add_fips_codes(df_race_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_race_2016_reshaped = add_fips_codes(df_race_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_race_2020_reshaped = add_fips_codes(df_race_2020_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_age_sex_2012_reshaped = add_fips_codes(df_age_sex_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_age_sex_2016_reshaped = add_fips_codes(df_age_sex_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_age_sex_2020_reshaped = add_fips_codes(df_age_sex_2020_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_age_employment_2012_reshaped = add_fips_codes(df_age_employment_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_age_employment_2016_reshaped = add_fips_codes(df_age_employment_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_age_employment_2020_reshaped = add_fips_codes(df_age_employment_2020_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_industry_2012_reshaped = add_fips_codes(df_industry_2012_reshaped, '../../data/election/fips_state_and_county.csv')\n",
    "df_industry_2016_reshaped = add_fips_codes(df_industry_2016_reshaped, '../../data/election/fips_state_and_county.csv')\n",
    "df_industry_2020_reshaped = add_fips_codes(df_industry_2020_reshaped, '../../data/election/fips_state_and_county.csv')\n",
    "# df_housing_financial_2012_reshaped = add_fips_codes(df_housing_financial_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_housing_financial_2016_reshaped = add_fips_codes(df_housing_financial_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_housing_financial_2020_reshaped = add_fips_codes(df_housing_financial_2020_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_veteran_status_2012_reshaped = add_fips_codes(df_veteran_status_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_veteran_status_2016_reshaped = add_fips_codes(df_veteran_status_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "# df_veteran_status_2020_reshaped = add_fips_codes(df_veteran_status_2020_reshaped, 'data/election/fips_state_and_county.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns with more than 0 missing values\n",
    "df_age_employment_2012_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_age_employment_2016_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_age_employment_2020_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_industry_2012_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_industry_2016_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_industry_2020_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_housing_financial_2012_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_housing_financial_2016_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_housing_financial_2020_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_veteran_status_2012_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_veteran_status_2016_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_veteran_status_2020_reshaped.dropna(axis=1, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add _2012 to all columns except for county_name, state_name, fips_code, state_abbr\n",
    "df_race_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_race_2012_reshaped.columns]\n",
    "df_age_sex_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_sex_2012_reshaped.columns]\n",
    "df_age_employment_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_employment_2012_reshaped.columns]\n",
    "df_industry_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_industry_2012_reshaped.columns]\n",
    "df_housing_financial_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_housing_financial_2012_reshaped.columns]\n",
    "df_veteran_status_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_veteran_status_2012_reshaped.columns]\n",
    "\n",
    "# add _2016 to all columns except for county_name, state_name, fips_code, state_abbr\n",
    "df_race_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_race_2016_reshaped.columns]\n",
    "df_age_sex_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_sex_2016_reshaped.columns]\n",
    "df_age_employment_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_employment_2016_reshaped.columns]\n",
    "df_industry_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_industry_2016_reshaped.columns]\n",
    "df_housing_financial_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_housing_financial_2016_reshaped.columns]\n",
    "df_veteran_status_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_veteran_status_2016_reshaped.columns]\n",
    "\n",
    "# add _2020 to all columns except for county_name, state_name, fips_code, state_abbr\n",
    "df_race_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_race_2020_reshaped.columns]\n",
    "df_age_sex_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_sex_2020_reshaped.columns]\n",
    "df_age_employment_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_employment_2020_reshaped.columns]\n",
    "df_industry_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_industry_2020_reshaped.columns]\n",
    "df_housing_financial_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_housing_financial_2020_reshaped.columns]\n",
    "df_veteran_status_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_veteran_status_2020_reshaped.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race_2020_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all dataframes on fips_code\n",
    "df_race_merged = df_race_2012_reshaped.merge(df_race_2016_reshaped, on='fips_code')\n",
    "df_race_merged = df_race_merged.merge(df_race_2020_reshaped, on='fips_code')\n",
    "df_age_sex_merged = df_age_sex_2012_reshaped.merge(df_age_sex_2016_reshaped, on='fips_code')\n",
    "df_age_sex_merged = df_age_sex_merged.merge(df_age_sex_2020_reshaped, on='fips_code')\n",
    "df_age_employment_merged = df_age_employment_2012_reshaped.merge(df_age_employment_2016_reshaped, on='fips_code')\n",
    "df_age_employment_merged = df_age_employment_merged.merge(df_age_employment_2020_reshaped, on='fips_code')\n",
    "df_industry_merged = df_industry_2012_reshaped.merge(df_industry_2016_reshaped, on='fips_code')\n",
    "df_industry_merged = df_industry_merged.merge(df_industry_2020_reshaped, on='fips_code')\n",
    "df_housing_financial_merged = df_housing_financial_2012_reshaped.merge(df_housing_financial_2016_reshaped, on='fips_code')\n",
    "df_housing_financial_merged = df_housing_financial_merged.merge(df_housing_financial_2020_reshaped, on='fips_code')\n",
    "df_veteran_status_merged = df_veteran_status_2012_reshaped.merge(df_veteran_status_2016_reshaped, on='fips_code')\n",
    "df_veteran_status_merged = df_veteran_status_merged.merge(df_veteran_status_2020_reshaped, on='fips_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# load the existing counties data county_data_with_elections_2012_2016_2020.geojson\n",
    "counties = gpd.read_file('data/election/final_data/county_data_with_elections_2012_2016_2020.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veteran_status_merged['fips_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties['FIPS Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a .0 to each fips code in the counties dataframe\n",
    "counties['FIPS Code'] = counties['FIPS Code'].astype(str) + '.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all data to the counties dataframe\n",
    "counties_merged = counties.merge(df_race_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_age_sex_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_age_employment_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_industry_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_housing_financial_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_veteran_status_merged, left_on='FIPS Code', right_on='fips_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 to 19 years_male_2012_y\n",
    "counties_merged['FIPS Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show duplicated columns\n",
    "duplicated_cols = counties_merged.columns[counties_merged.columns.duplicated()]\n",
    "duplicated_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated columns\n",
    "counties_merged.drop(columns=duplicated_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save counties_merged to a geojson file\n",
    "counties_merged.to_file('data/election/final_data/county_data_with_elections_2012_2016_2020_census_MAIN.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out the dataframes into separate dataframes for each year (2012, 2016, 2020), also take the state_abbr, county_name, state_name, and fips_code columns\n",
    "counties_merged_2012 = counties_merged[[col for col in counties_merged.columns if '2012' in col] + ['state_abbr', 'county_name', 'state_name', 'FIPS Code', 'geometry']]\n",
    "counties_merged_2016 = counties_merged[[col for col in counties_merged.columns if '2016' in col] + ['state_abbr', 'county_name', 'state_name', 'FIPS Code', 'geometry']]\n",
    "# for 2020, include values that contain 2021 as well\n",
    "counties_merged_2020 = counties_merged[[col for col in counties_merged.columns if '2020' in col or '2021' in col] + ['state_abbr', 'county_name', 'state_name', 'FIPS Code', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all cols in counties_merged that have 2020 in them\n",
    "[col for col in counties_merged.columns if '2016' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_merged[[col for col in counties_merged.columns if '2020' in col] + ['state_abbr', 'county_name', 'state_name', 'FIPS Code', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in counties_merged_2012, fix values in all columns that contain a percentage sign in the value (i.e. some columns have values with percentage signs in them, need to be float)\n",
    "for col in counties_merged_2012.columns:\n",
    "    if '%' in counties_merged_2012[col].values:\n",
    "        counties_merged_2012[col] = counties_merged_2012[col].str.replace('%', '').astype(float)\n",
    "\n",
    "# in counties_merged_2016, fix values in all columns that contain a percentage sign in the value (i.e. some columns have values with percentage signs in them, need to be float)\n",
    "for col in counties_merged_2016.columns:\n",
    "    if '%' in counties_merged_2016[col].values:\n",
    "        counties_merged_2016[col] = counties_merged_2016[col].str.replace('%', '').astype(float)\n",
    "\n",
    "# in counties_merged_2020, fix values in all columns that contain a percentage sign in the value (i.e. some columns have values with percentage signs in them, need to be float)\n",
    "for col in counties_merged_2020.columns:\n",
    "    if '%' in counties_merged_2020[col].values:\n",
    "        counties_merged_2020[col] = counties_merged_2020[col].str.replace('%', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_merged_2020.per_point_diff_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save merged dataframes to geojson files\n",
    "counties_merged_2012.to_file('data/election/final_data/county_data_with_elections_2012_census_MAIN.geojson', driver='GeoJSON')\n",
    "counties_merged_2016.to_file('data/election/final_data/county_data_with_elections_2016_census_MAIN.geojson', driver='GeoJSON')\n",
    "counties_merged_2020.to_file('data/election/final_data/county_data_with_elections_2020_census_MAIN.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_merged_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_race_2012_reshaped.to_csv('data/election/census/census_race_2012_reshaped.csv', index=False)\n",
    "df_race_2016_reshaped.to_csv('data/election/census/census_race_2016_reshaped.csv', index=False)\n",
    "df_race_2020_reshaped.to_csv('data/election/census/census_race_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_age_sex_2012_reshaped.to_csv('data/election/census/census_age_sex_2012_reshaped.csv', index=False)\n",
    "df_age_sex_2016_reshaped.to_csv('data/election/census/census_age_sex_2016_reshaped.csv', index=False)\n",
    "df_age_sex_2020_reshaped.to_csv('data/election/census/census_age_sex_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_age_employment_2012_reshaped.to_csv('data/election/census/census_age_employment_2012_reshaped.csv', index=False)\n",
    "df_age_employment_2016_reshaped.to_csv('data/election/census/census_age_employment_2016_reshaped.csv', index=False)\n",
    "df_age_employment_2020_reshaped.to_csv('data/election/census/census_age_employment_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_industry_2012_reshaped.to_csv('data/election/census/census_industry_2012_reshaped.csv', index=False)\n",
    "df_industry_2016_reshaped.to_csv('data/election/census/census_industry_2016_reshaped.csv', index=False)\n",
    "df_industry_2020_reshaped.to_csv('data/election/census/census_industry_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_housing_financial_2012_reshaped.to_csv('data/election/census/census_housing_financial_2012_reshaped.csv', index=False)\n",
    "df_housing_financial_2016_reshaped.to_csv('data/election/census/census_housing_financial_2016_reshaped.csv', index=False)\n",
    "df_housing_financial_2020_reshaped.to_csv('data/election/census/census_housing_financial_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_veteran_status_2012_reshaped.to_csv('data/election/census/census_veteran_status_2012_reshaped.csv', index=False)\n",
    "df_veteran_status_2016_reshaped.to_csv('data/election/census/census_veteran_status_2016_reshaped.csv', index=False)\n",
    "df_veteran_status_2020_reshaped.to_csv('data/election/census/census_veteran_status_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add _2012 to all column names, remove ':' from column names\n",
    "df2_fips.columns = [col + '_2012' if col != 'state_name' and col != 'county_name' else col for col in df2_fips.columns]\n",
    "df2_fips.columns = [col.replace(':', '') for col in df2_fips.columns]\n",
    "df2_fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove commas from all values\n",
    "df2_fips = df2_fips.replace(',', '', regex=True)\n",
    "df2_fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_demographic_percentages(df):\n",
    "    \"\"\"\n",
    "    Add percentage columns for each demographic category.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with demographic counts\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with additional percentage columns\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Define the demographic columns and their new percentage column names\n",
    "    demographic_cols = {\n",
    "        'American Indian and Alaska Native alone_2012': 'pct_aian_2012',\n",
    "        'Asian alone_2012': 'pct_asian_2012',\n",
    "        'Black or African American alone_2012': 'pct_black_2012',\n",
    "        'Native Hawaiian and Other Pacific Islander alone_2012': 'pct_nhpi_2012',\n",
    "        'Some other race alone_2012': 'pct_other_2012',\n",
    "        'Two or more races_2012': 'pct_two_or_more_2012',\n",
    "        'White alone_2012': 'pct_white_2012',\n",
    "        'Two races excluding Some other race, and three or more races_2012': 'pct_two_races_excl_other_2012',\n",
    "        'Two races including Some other race_2012': 'pct_two_races_incl_other_2012'\n",
    "    }\n",
    "    \n",
    "    # Calculate percentages for each demographic category\n",
    "    for col, new_col in demographic_cols.items():\n",
    "        result[new_col] = (result[col] / result['Total_2012'] * 100).round(2)\n",
    "        \n",
    "    # Validate that percentages sum to approximately 100\n",
    "    # Note: We exclude the detailed two races breakdowns as they're subcategories\n",
    "    main_pct_cols = [\n",
    "        'pct_aian_2012',\n",
    "        'pct_asian_2012',\n",
    "        'pct_black_2012',\n",
    "        'pct_nhpi_2012',\n",
    "        'pct_other_2012',\n",
    "        'pct_two_or_more_2012',\n",
    "        'pct_white_2012'\n",
    "    ]\n",
    "    \n",
    "    # Calculate sum of percentages\n",
    "    result['pct_sum'] = result[main_pct_cols].sum(axis=1)\n",
    "    \n",
    "    # Check for any significant deviations from 100%\n",
    "    tolerance = 0.1  # Allow for small rounding differences\n",
    "    deviations = result[abs(result['pct_sum'] - 100) > tolerance]\n",
    "    if len(deviations) > 0:\n",
    "        print(f\"\\nWarning: {len(deviations)} rows have percentages that don't sum to 100% ({tolerance}%):\")\n",
    "        for _, row in deviations.iterrows():\n",
    "            print(f\"- {row['county_name']}, {row['state_name']}: {row['pct_sum']:.2f}%\")\n",
    "    \n",
    "    # Drop the validation column\n",
    "    result = result.drop('pct_sum', axis=1)\n",
    "    \n",
    "    # Group and order columns\n",
    "    id_cols = ['county_name', 'state_name', 'fips_code_2012', 'state_abbr_2012']\n",
    "    count_cols = ['Total_2012'] + list(demographic_cols.keys())\n",
    "    pct_cols = list(demographic_cols.values())\n",
    "    \n",
    "    # Reorder columns\n",
    "    result = result[id_cols + count_cols + pct_cols]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called df\n",
    "df2_fips = add_demographic_percentages(df2_fips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aispace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
