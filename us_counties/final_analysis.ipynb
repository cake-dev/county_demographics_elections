{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ideas:\n",
    "\n",
    "change in who a county votes for (flips or not) is spatially correlated / informed \n",
    "\n",
    "spatial correlation on residuals from a model that predicts winner in each county\n",
    "\n",
    "most religious groups are spatially correlated\n",
    "\n",
    "todo:\n",
    "\n",
    "- describe dataset and coverage\n",
    "- describe what spatial correlation means for this dataset (or rather, for the specific features we are looking at)\n",
    "    - describe what we are looking for in the spatial correlation\n",
    "- show the main election results (2012-2024)\n",
    "- show the religious groups correlations (multiple maps since lots of groups)\n",
    "- show the spatial correlation of the residuals from a model that predicts the winner in each county (or another predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the full census election data geojson\n",
    "census_election_data = gpd.read_file('../../data/election/final_data/county_demographics_with_elections_2012_2024.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using multi feature choropleth to visualize the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_configs = [\n",
    "    {\n",
    "        'name': 'state_winner_2024',\n",
    "        'scale': 'linear',\n",
    "        'color_scheme': 'political',\n",
    "        'legend_name': 'State Winner 2024'\n",
    "    },\n",
    "    {\n",
    "        'name': 'state_winner_2020',\n",
    "        'scale': 'linear',\n",
    "        'color_scheme': 'political',\n",
    "        'legend_name': 'State Winner 2020'\n",
    "    },\n",
    "    {\n",
    "        'name': 'state_winner_2016',\n",
    "        'scale': 'linear',\n",
    "        'color_scheme': 'political',\n",
    "        'legend_name': 'State Winner 2016'\n",
    "    },\n",
    "    {\n",
    "        'name': 'state_winner_2012',\n",
    "        'scale': 'linear',\n",
    "        'color_scheme': 'political',\n",
    "        'legend_name': 'State Winner 2012'\n",
    "    }\n",
    "]\n",
    "\n",
    "map_obj = create_multi_feature_choropleth(\n",
    "    gdf=census_election_data,\n",
    "    feature_configs=feature_configs,\n",
    "    zoom_start=6\n",
    ")\n",
    "map_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using multi feature spatial correlation mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "feature_configs = [\n",
    "    {\n",
    "        'name': 'flipped_2012_2016',\n",
    "        'scale': 'linear',\n",
    "        'color_scheme': 'politcal',\n",
    "        'legend_name': 'flipped_2012_2016'\n",
    "    },\n",
    "    {\n",
    "        'name': 'flipped_2020_2024',\n",
    "        'scale': 'linear',\n",
    "        'color_scheme': 'politcal',\n",
    "        'legend_name': 'flipped_2020_2024'\n",
    "    },\n",
    "    # {\n",
    "    #     'name': 'religion_catholic_church_percent_adherents_of_total_adherents',\n",
    "    #     'scale': 'linear',\n",
    "    #     'color_scheme': 'sequential',\n",
    "    #     'legend_name': 'CATH Church Adherents %'\n",
    "    # },\n",
    "    # {\n",
    "    #     'name': 'religion_church_of_jesus_christ_of_latter_day_saints_percent_adherents_of_total_adherents',\n",
    "    #     'scale': 'linear',\n",
    "    #     'color_scheme': 'sequential',\n",
    "    #     'legend_name': 'LDS Church Adherents %'\n",
    "    # },\n",
    "    # {\n",
    "    #     'name': 'percent_religious',\n",
    "    #     'scale': 'linear',\n",
    "    #     'color_scheme': 'sequential',\n",
    "    #     'legend_name': 'Percent Population Religious'\n",
    "    # }\n",
    "]\n",
    "\n",
    "results_multi_spatial, interactive_map_multi_spatial = analyze_multi_feature_spatial_correlation(\n",
    "    gdf=census_election_data,\n",
    "    feature_configs=feature_configs,\n",
    "    zoom_start=6\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print_multi_feature_results(results_multi_spatial)\n",
    "\n",
    "# Display map\n",
    "interactive_map_multi_spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using spatial correlation on residuals from a model that predicts a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial model training (only needs to be run once)\n",
    "trainer = ModelTrainer()\n",
    "model_results = trainer.fit_predict(\n",
    "    gdf=census_election_data,\n",
    "    target_column='winner_2024_numeric',\n",
    "    exclude_columns=['winner_2020_numeric', 'votes_dem_2012', 'votes_gop_2012', 'per_point_diff_2012', 'votes_dem_2016', 'votes_gop_2016', 'per_point_diff_2016', \n",
    "                     'votes_dem_2024', 'votes_gop_2024', 'per_point_diff_2024', 'per_dem_2012', 'per_gop_2012', 'diff_2012', 'diff_2016', 'diff_2020', 'per_dem_2016',\n",
    "                       'per_gop_2016', 'per_dem_2020', 'per_gop_2020', 'per_dem_2024', 'per_gop_2024', 'winner_2012_numeric', 'winner_2016_numeric', 'state_winner_2012',\n",
    "                         'state_winner_2016', 'state_winner_2020', 'state_winner_2024', 'per_point_diff_2020'],\n",
    "    exclude_patterns=['index', 'per_dem', 'per_gop', 'date'],  # patterns to exclude\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Spatial analysis (run once after model training)\n",
    "analyzer = SpatialAnalyzer()\n",
    "spatial_results = analyzer.analyze_residuals(\n",
    "    gdf=census_election_data,\n",
    "    residuals=model_results.residuals\n",
    ")\n",
    "\n",
    "# Create map (can be run multiple times with different options)\n",
    "visualizer = MapVisualizer()\n",
    "m = visualizer.create_map(\n",
    "    gdf=census_election_data,\n",
    "    target_column='winner_2024_numeric',\n",
    "    model_results=model_results,\n",
    "    spatial_results=spatial_results,\n",
    "    zoom_start=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting all spatial correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations for all numeric features\n",
    "results_all_spatial = calculate_multi_feature_correlation(\n",
    "    census_election_data,\n",
    "    weight_type='queen',  # or 'knn'\n",
    "    k_neighbors=5  # only needed if using 'knn'\n",
    ")\n",
    "\n",
    "# Get top n features by global Moran's I\n",
    "top_global = get_top_correlations(\n",
    "    results_all_spatial,\n",
    "    n=1000,\n",
    "    p_threshold=0.05,\n",
    "    sort_by='global'\n",
    ")\n",
    "\n",
    "# Get top n features by local Moran's I\n",
    "top_local = get_top_correlations(\n",
    "    results_all_spatial,\n",
    "    n=1000,\n",
    "    p_threshold=0.05,\n",
    "    sort_by='local'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi feature Choropleth (folium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import numpy as np\n",
    "from branca.colormap import LinearColormap\n",
    "import pandas as pd\n",
    "\n",
    "# Define color schemes\n",
    "COLOR_SCHEMES = {\n",
    "    'population': ['#fee5d9', '#fcae91', '#fb6a4a', '#de2d26', '#a50f15'],  # Reds\n",
    "    'political': ['#0571b0', '#92c5de', '#f7f7f7', '#f4a582', '#ca0020'],   # Blue-Red diverging\n",
    "    'sequential': ['#ffffcc', '#a1dab4', '#41b6c4', '#2c7fb8', '#253494'],  # Blue-Green\n",
    "    'viridis': ['#440154', '#414487', '#2a788e', '#22a884', '#7ad151', '#fde725']  # Viridis\n",
    "}\n",
    "\n",
    "def create_multi_feature_choropleth(\n",
    "    gdf,\n",
    "    feature_configs,\n",
    "    center=None,\n",
    "    zoom_start=6,\n",
    "    width='100%',\n",
    "    height='100%'\n",
    "):\n",
    "    \"\"\"\n",
    "    Create an interactive choropleth map with multiple togglable feature layers using Folium.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        The geodataframe containing geographic and feature data\n",
    "    feature_configs : list of dict\n",
    "        List of feature configurations, each containing:\n",
    "        {\n",
    "            'name': str (column name in gdf),\n",
    "            'scale': str ('linear' or 'log'),\n",
    "            'color_scheme': str (optional, one of 'population', 'political', 'sequential'),\n",
    "            'legend_name': str (optional, display name for the legend)\n",
    "        }\n",
    "    center : tuple, optional\n",
    "        (lat, lon) center coordinates. If None, will use centroid of the data\n",
    "    zoom_start : int, default 6\n",
    "        Initial zoom level\n",
    "    width : str, default '100%'\n",
    "        Width of the map in percentage\n",
    "    height : str, default '100%'\n",
    "        Height of the map in percentage\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    folium.Map\n",
    "        The interactive map object\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    for config in feature_configs:\n",
    "        if config['name'] not in gdf.columns:\n",
    "            raise ValueError(f\"Feature '{config['name']}' not found in the GeoDataFrame\")\n",
    "        if config.get('scale') not in ['linear', 'log']:\n",
    "            raise ValueError(f\"Scale for feature '{config['name']}' must be 'linear' or 'log'\")\n",
    "    \n",
    "    # Calculate center if not provided\n",
    "    if center is None:\n",
    "        center = [\n",
    "            gdf.geometry.centroid.y.mean(),\n",
    "            gdf.geometry.centroid.x.mean()\n",
    "        ]\n",
    "    \n",
    "    # Create base map\n",
    "    m = folium.Map(\n",
    "        location=center,\n",
    "        zoom_start=zoom_start,\n",
    "        width=width,\n",
    "        height=height\n",
    "    )\n",
    "    \n",
    "    # Create feature groups dictionary\n",
    "    feature_groups = {}\n",
    "    \n",
    "    for config in feature_configs:\n",
    "        feature_name = config['name']\n",
    "        scale_type = config['scale']\n",
    "        # Use viridis for log scale, otherwise use specified color scheme\n",
    "        color_scheme = 'viridis' if scale_type == 'log' else config.get('color_scheme', 'sequential')\n",
    "        legend_name = config.get('legend_name', feature_name)\n",
    "        \n",
    "        # Get appropriate color scheme\n",
    "        colors = COLOR_SCHEMES.get(color_scheme, COLOR_SCHEMES['sequential'])\n",
    "        \n",
    "        # Create feature group\n",
    "        fg = folium.FeatureGroup(name=legend_name, show=False)\n",
    "        \n",
    "        # Handle data scaling and preparation\n",
    "        data = gdf[feature_name].copy()\n",
    "        if scale_type == 'log':\n",
    "            min_val = data.min()\n",
    "            if min_val <= 0:\n",
    "                print(f\"Warning: {feature_name} contains values â‰¤ 0. Adding offset for log scale.\")\n",
    "                data = data - min_val + 1\n",
    "            # Apply log transformation\n",
    "            data = np.log(data)\n",
    "        \n",
    "        # Create colormap\n",
    "        colormap = LinearColormap(\n",
    "            colors=colors,\n",
    "            vmin=data.min(),\n",
    "            vmax=data.max(),\n",
    "            caption=legend_name + (' (log scale)' if scale_type == 'log' else '')\n",
    "        )\n",
    "        \n",
    "        # Add choropleth layer\n",
    "        for idx, row in gdf.iterrows():\n",
    "            value = row[feature_name]\n",
    "            if scale_type == 'log':\n",
    "                if value <= 0:\n",
    "                    value = value - min_val + 1\n",
    "                value = np.log(value)\n",
    "                \n",
    "            color = colormap(value)\n",
    "            \n",
    "            # Format display value\n",
    "            display_value = row[feature_name]\n",
    "            if isinstance(display_value, (int, float)):\n",
    "                if abs(display_value) >= 1000000:\n",
    "                    display_value = f\"{display_value/1000000:.2f}M\"\n",
    "                elif abs(display_value) >= 1000:\n",
    "                    display_value = f\"{display_value/1000:.2f}K\"\n",
    "                elif feature_name.startswith('per_'):  # Percentage values\n",
    "                    display_value = f\"{display_value:.2f}%\"\n",
    "                else:\n",
    "                    display_value = f\"{display_value:.2f}\"\n",
    "            \n",
    "            # Get state and county names\n",
    "            state_name = row.get('state_name', row.get('STATE_NAME', ''))\n",
    "            county_name = row.get('county_name', row.get('COUNTY_NAME', ''))\n",
    "            \n",
    "            # Create GeoJSON-style feature\n",
    "            feature = {\n",
    "                'type': 'Feature',\n",
    "                'geometry': row.geometry.__geo_interface__,\n",
    "                'properties': {\n",
    "                    'value': display_value,\n",
    "                    'state': state_name,\n",
    "                    'county': county_name\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Add polygon to feature group\n",
    "            folium.GeoJson(\n",
    "                feature,\n",
    "                style_function=lambda x, color=color: {\n",
    "                    'fillColor': color,\n",
    "                    'color': 'black',\n",
    "                    'weight': 1,\n",
    "                    'fillOpacity': 0.7\n",
    "                },\n",
    "                tooltip=folium.GeoJsonTooltip(\n",
    "                    fields=['county', 'state', 'value'],\n",
    "                    aliases=['County', 'State', legend_name],\n",
    "                    localize=True,\n",
    "                    sticky=False,\n",
    "                    labels=True,\n",
    "                    style=\"\"\"\n",
    "                        background-color: white;\n",
    "                        border: 2px solid black;\n",
    "                        border-radius: 3px;\n",
    "                        box-shadow: 3px 3px 3px rgba(0,0,0,0.2);\n",
    "                        padding: 5px;\n",
    "                        font-size: 12px;\n",
    "                    \"\"\"\n",
    "                )\n",
    "            ).add_to(fg)\n",
    "        \n",
    "        # Add colormap to map\n",
    "        colormap.add_to(m)\n",
    "        \n",
    "        # Add feature group to map\n",
    "        fg.add_to(m)\n",
    "        \n",
    "        feature_groups[legend_name] = fg\n",
    "    \n",
    "    # Add custom JavaScript for radio button behavior\n",
    "    layer_control_html = \"\"\"\n",
    "    <script type=\"text/javascript\">\n",
    "    function setupLayerControl() {\n",
    "        // Get layer control container\n",
    "        var layerControlContainer = document.querySelector('.leaflet-control-layers-overlays');\n",
    "        if (!layerControlContainer) {\n",
    "            setTimeout(setupLayerControl, 100);\n",
    "            return;\n",
    "        }\n",
    "\n",
    "        // Replace checkboxes with radio buttons\n",
    "        var inputs = layerControlContainer.querySelectorAll('input[type=\"checkbox\"]');\n",
    "        inputs.forEach(function(input) {\n",
    "            input.type = 'radio';\n",
    "            input.name = 'layer-control';\n",
    "            \n",
    "            // Update the input's checked state based on layer visibility\n",
    "            var layer = input._layer;\n",
    "            if (layer && layer._map) {\n",
    "                input.checked = layer._map.hasLayer(layer);\n",
    "            }\n",
    "            \n",
    "            // Add change listener to handle layer toggling\n",
    "            input.addEventListener('change', function(e) {\n",
    "                if (this.checked) {\n",
    "                    // Uncheck and hide all other layers\n",
    "                    inputs.forEach(function(otherInput) {\n",
    "                        if (otherInput !== input) {\n",
    "                            otherInput.checked = false;\n",
    "                            if (otherInput._layer) {\n",
    "                                otherInput._layer.remove();\n",
    "                            }\n",
    "                        }\n",
    "                    });\n",
    "                    \n",
    "                    // Show the selected layer\n",
    "                    if (this._layer) {\n",
    "                        this._layer.addTo(this._layer._map);\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "        });\n",
    "\n",
    "        // Monitor layer visibility changes\n",
    "        var map = document.querySelector('#map');  // Assuming map has id=\"map\"\n",
    "        if (map && map._leaflet_map) {\n",
    "            map._leaflet_map.on('layeradd layerremove', function(e) {\n",
    "                inputs.forEach(function(input) {\n",
    "                    if (input._layer === e.layer) {\n",
    "                        input.checked = e.type === 'layeradd';\n",
    "                    }\n",
    "                });\n",
    "            });\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Initialize when DOM is ready\n",
    "    if (document.readyState === 'loading') {\n",
    "        document.addEventListener('DOMContentLoaded', setupLayerControl);\n",
    "    } else {\n",
    "        setupLayerControl();\n",
    "    }\n",
    "\n",
    "    // Also set up observer to handle dynamic updates\n",
    "    var observer = new MutationObserver(function(mutations) {\n",
    "        mutations.forEach(function(mutation) {\n",
    "            if (mutation.addedNodes.length) {\n",
    "                setupLayerControl();\n",
    "            }\n",
    "        });\n",
    "    });\n",
    "\n",
    "    observer.observe(document.body, {\n",
    "        childList: true,\n",
    "        subtree: true\n",
    "    });\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add layer control to map\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    # Add custom JavaScript to handle radio button behavior\n",
    "    m.get_root().html.add_child(folium.Element(layer_control_html))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spatial Correlation mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from libpysal.weights import Queen, KNN\n",
    "from esda.moran import Moran, Moran_Local\n",
    "import warnings\n",
    "from typing import Union, Tuple, Dict, List\n",
    "from branca.colormap import LinearColormap\n",
    "\n",
    "def analyze_multi_feature_spatial_correlation(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    feature_configs: List[Dict],\n",
    "    weight_type: str = 'queen',\n",
    "    k_neighbors: int = 5,\n",
    "    center: Tuple[float, float] = None,\n",
    "    zoom_start: int = 4\n",
    ") -> Tuple[Dict, folium.Map]:\n",
    "    \"\"\"\n",
    "    Creates an interactive Folium map showing spatial correlation analysis for multiple features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : gpd.GeoDataFrame\n",
    "        GeoDataFrame containing geometry and data\n",
    "    feature_configs : list of dict\n",
    "        List of feature configurations, each containing:\n",
    "        {\n",
    "            'name': str (column name in gdf),\n",
    "            'scale': str ('linear' or 'log', optional, default='linear'),\n",
    "            'color_scheme': str (optional, one of 'population', 'political', 'sequential', 'viridis'),\n",
    "            'legend_name': str (optional, display name for the legend)\n",
    "        }\n",
    "    weight_type : str, optional (default='queen')\n",
    "        Type of spatial weights to use ('queen' or 'knn')\n",
    "    k_neighbors : int, optional (default=5)\n",
    "        Number of neighbors for KNN weights\n",
    "    center : tuple, optional\n",
    "        (lat, lon) center coordinates for the map\n",
    "    zoom_start : int, optional (default=4)\n",
    "        Initial zoom level for the map\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(gdf, gpd.GeoDataFrame):\n",
    "        raise TypeError(\"Input must be a GeoDataFrame\")\n",
    "    \n",
    "    for config in feature_configs:\n",
    "        if config['name'] not in gdf.columns:\n",
    "            raise ValueError(f\"Feature '{config['name']}' not found in GeoDataFrame\")\n",
    "    \n",
    "    # Create copy to avoid modifying original\n",
    "    gdf_analysis = gdf.copy()\n",
    "    \n",
    "    # Create spatial weights matrix\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        if weight_type.lower() == 'queen':\n",
    "            weights = Queen.from_dataframe(gdf_analysis, use_index=True)\n",
    "        elif weight_type.lower() == 'knn':\n",
    "            weights = KNN.from_dataframe(gdf_analysis, k=k_neighbors)\n",
    "        else:\n",
    "            raise ValueError(\"weight_type must be either 'queen' or 'knn'\")\n",
    "    \n",
    "    # Handle islands if using queen weights\n",
    "    if weight_type.lower() == 'queen':\n",
    "        islands = weights.islands\n",
    "        if len(islands) > 0:\n",
    "            print(f\"Removing {len(islands)} isolated areas from analysis\")\n",
    "            gdf_analysis = gdf_analysis[~gdf_analysis.index.isin(islands)].copy()\n",
    "            weights = Queen.from_dataframe(gdf_analysis, use_index=True)\n",
    "    \n",
    "    weights.transform = 'r'  # Row-standardize weights\n",
    "    \n",
    "    # Calculate map center if not provided\n",
    "    if center is None:\n",
    "        center = [\n",
    "            gdf_analysis.geometry.centroid.y.mean(),\n",
    "            gdf_analysis.geometry.centroid.x.mean()\n",
    "        ]\n",
    "    \n",
    "    # Create base map\n",
    "    m = folium.Map(location=center, zoom_start=zoom_start)\n",
    "    \n",
    "    # Color schemes\n",
    "    COLOR_SCHEMES = {\n",
    "        'population': ['#fee5d9', '#fcae91', '#fb6a4a', '#de2d26', '#a50f15'],\n",
    "        'political': ['#0571b0', '#92c5de', '#f7f7f7', '#f4a582', '#ca0020'],\n",
    "        'sequential': ['#ffffcc', '#a1dab4', '#41b6c4', '#2c7fb8', '#253494'],\n",
    "        'viridis': ['#440154', '#414487', '#2a788e', '#22a884', '#7ad151', '#fde725']\n",
    "    }\n",
    "    \n",
    "    # Store results for all features\n",
    "    all_results = {}\n",
    "    \n",
    "    for config in feature_configs:\n",
    "        feature_name = config['name']\n",
    "        scale_type = config.get('scale', 'linear')\n",
    "        color_scheme = config.get('color_scheme', 'sequential')\n",
    "        legend_name = config.get('legend_name', feature_name)\n",
    "        \n",
    "        # Handle missing values for this feature\n",
    "        if gdf_analysis[feature_name].isnull().any():\n",
    "            print(f\"Warning: {gdf_analysis[feature_name].isnull().sum()} missing values found in {feature_name}\")\n",
    "            feature_data = gdf_analysis.dropna(subset=[feature_name]).copy()\n",
    "        else:\n",
    "            feature_data = gdf_analysis.copy()\n",
    "        \n",
    "        # Standardize the variable\n",
    "        if scale_type == 'log':\n",
    "            # Handle log transformation for non-negative values\n",
    "            min_val = feature_data[feature_name].min()\n",
    "            if min_val <= 0:\n",
    "                offset = abs(min_val) + 1\n",
    "                feature_data[f'{feature_name}_standardized'] = np.log(feature_data[feature_name] + offset)\n",
    "            else:\n",
    "                feature_data[f'{feature_name}_standardized'] = np.log(feature_data[feature_name])\n",
    "        else:\n",
    "            feature_data[f'{feature_name}_standardized'] = feature_data[feature_name]\n",
    "        \n",
    "        # Z-score standardization\n",
    "        feature_data[f'{feature_name}_standardized'] = (\n",
    "            feature_data[f'{feature_name}_standardized'] - \n",
    "            feature_data[f'{feature_name}_standardized'].mean()\n",
    "        ) / feature_data[f'{feature_name}_standardized'].std()\n",
    "        \n",
    "        # Calculate Global Moran's I using standardized values\n",
    "        moran = Moran(feature_data[f'{feature_name}_standardized'], weights)\n",
    "        \n",
    "        # Calculate Local Moran's I using standardized values\n",
    "        local_moran = Moran_Local(feature_data[f'{feature_name}_standardized'], weights)\n",
    "        \n",
    "        # Add local indicators to dataframe\n",
    "        feature_data[f'{feature_name}_local_i'] = local_moran.Is\n",
    "        feature_data[f'{feature_name}_p_value'] = local_moran.p_sim\n",
    "        \n",
    "        # Classify clusters\n",
    "        feature_data[f'{feature_name}_cluster'] = 'Not Significant'\n",
    "        sig_mask = local_moran.p_sim < 0.05\n",
    "        \n",
    "        # Use standardized values for clustering\n",
    "        std_val = feature_data[f'{feature_name}_standardized']\n",
    "        lag_val = weights.sparse.dot(std_val)\n",
    "        \n",
    "        # Assign cluster types\n",
    "        feature_data.loc[sig_mask & (std_val > 0) & (lag_val > 0), f'{feature_name}_cluster'] = 'High-High'\n",
    "        feature_data.loc[sig_mask & (std_val < 0) & (lag_val < 0), f'{feature_name}_cluster'] = 'Low-Low'\n",
    "        feature_data.loc[sig_mask & (std_val > 0) & (lag_val < 0), f'{feature_name}_cluster'] = 'High-Low'\n",
    "        feature_data.loc[sig_mask & (std_val < 0) & (lag_val > 0), f'{feature_name}_cluster'] = 'Low-High'\n",
    "        \n",
    "        # Create feature groups for each layer type\n",
    "        fg_original = folium.FeatureGroup(name=f\"{legend_name} - Values\")\n",
    "        fg_moran = folium.FeatureGroup(name=f\"{legend_name} - Local Moran's I\")\n",
    "        fg_clusters = folium.FeatureGroup(name=f\"{legend_name} - Clusters\")\n",
    "        \n",
    "        # Get colors for the schemes\n",
    "        colors = COLOR_SCHEMES.get(color_scheme, COLOR_SCHEMES['sequential'])\n",
    "        \n",
    "        # Create colormaps\n",
    "        colormap_original = LinearColormap(\n",
    "            colors=colors,\n",
    "            vmin=feature_data[feature_name].min(),\n",
    "            vmax=feature_data[feature_name].max(),\n",
    "            caption=f\"{legend_name} Values\"\n",
    "        )\n",
    "        \n",
    "        colormap_moran = LinearColormap(\n",
    "            colors=['#ca0020', '#f4a582', '#f7f7f7', '#92c5de', '#0571b0'],\n",
    "            vmin=feature_data[f'{feature_name}_local_i'].min(),\n",
    "            vmax=feature_data[f'{feature_name}_local_i'].max(),\n",
    "            caption=f\"{legend_name} Local Moran's I\"\n",
    "        )\n",
    "        \n",
    "        cluster_colors = {\n",
    "            'High-High': '#d7191c',\n",
    "            'Low-Low': '#2c7bb6',\n",
    "            'High-Low': '#fdae61',\n",
    "            'Low-High': '#abd9e9',\n",
    "            'Not Significant': '#ffffbf'\n",
    "        }\n",
    "        \n",
    "        # Add layers\n",
    "        for idx, row in feature_data.iterrows():\n",
    "            # Value distribution layer\n",
    "            color = colormap_original(row[feature_name])\n",
    "            folium.GeoJson(\n",
    "                row.geometry.__geo_interface__,\n",
    "                style_function=lambda x, color=color: {\n",
    "                    'fillColor': color,\n",
    "                    'color': 'black',\n",
    "                    'weight': 1,\n",
    "                    'fillOpacity': 0.7\n",
    "                },\n",
    "                tooltip=f\"{legend_name}: {row[feature_name]:.2f}\"\n",
    "            ).add_to(fg_original)\n",
    "            \n",
    "            # Local Moran's I layer\n",
    "            color = colormap_moran(row[f'{feature_name}_local_i'])\n",
    "            folium.GeoJson(\n",
    "                row.geometry.__geo_interface__,\n",
    "                style_function=lambda x, color=color: {\n",
    "                    'fillColor': color,\n",
    "                    'color': 'black',\n",
    "                    'weight': 1,\n",
    "                    'fillOpacity': 0.7\n",
    "                },\n",
    "                tooltip=f\"Local Moran's I: {row[f'{feature_name}_local_i']:.3f}<br>P-value: {row[f'{feature_name}_p_value']:.3f}\"\n",
    "            ).add_to(fg_moran)\n",
    "            \n",
    "            # Cluster type layer\n",
    "            color = cluster_colors[row[f'{feature_name}_cluster']]\n",
    "            folium.GeoJson(\n",
    "                row.geometry.__geo_interface__,\n",
    "                style_function=lambda x, color=color: {\n",
    "                    'fillColor': color,\n",
    "                    'color': 'black',\n",
    "                    'weight': 1,\n",
    "                    'fillOpacity': 0.7\n",
    "                },\n",
    "                tooltip=f\"Cluster Type: {row[f'{feature_name}_cluster']}\"\n",
    "            ).add_to(fg_clusters)\n",
    "        \n",
    "        # Add feature groups to map\n",
    "        fg_original.add_to(m)\n",
    "        fg_moran.add_to(m)\n",
    "        fg_clusters.add_to(m)\n",
    "        \n",
    "        # Add colormaps to map\n",
    "        colormap_original.add_to(m)\n",
    "        colormap_moran.add_to(m)\n",
    "        \n",
    "        # Store results for this feature\n",
    "        all_results[feature_name] = {\n",
    "            'global_statistics': {\n",
    "                'morans_i': moran.I,\n",
    "                'p_value': moran.p_sim,\n",
    "                'z_score': moran.z_sim\n",
    "            },\n",
    "            'cluster_summary': feature_data[f'{feature_name}_cluster'].value_counts().to_dict(),\n",
    "            'local_statistics': {\n",
    "                'mean_local_i': feature_data[f'{feature_name}_local_i'].mean(),\n",
    "                'significant_clusters': (feature_data[f'{feature_name}_p_value'] < 0.05).sum(),\n",
    "                'percent_significant': (feature_data[f'{feature_name}_p_value'] < 0.05).mean() * 100\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Add cluster type legend\n",
    "    legend_html = \"\"\"\n",
    "    <div style=\"position: fixed; bottom: 50px; right: 50px; z-index: 1000; background-color: white; \n",
    "                padding: 10px; border: 2px solid grey; border-radius: 5px\">\n",
    "    <p><strong>Cluster Types</strong></p>\n",
    "    \"\"\"\n",
    "    for cluster_type, color in cluster_colors.items():\n",
    "        legend_html += f\"\"\"\n",
    "        <p><i class=\"fa fa-square fa-1x\" style=\"color:{color}\"></i> {cluster_type}</p>\n",
    "        \"\"\"\n",
    "    legend_html += \"</div>\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    # Add layer control\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    return all_results, m\n",
    "\n",
    "def print_multi_feature_results(results: Dict):\n",
    "    \"\"\"\n",
    "    Prints formatted results for multiple features.\n",
    "    \"\"\"\n",
    "    for feature_name, feature_results in results.items():\n",
    "        print(f\"\\nSpatial Correlation Analysis Results for {feature_name}\\n\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        print(\"\\nGlobal Moran's I Statistics:\")\n",
    "        print(f\"Moran's I: {feature_results['global_statistics']['morans_i']:.3f}\")\n",
    "        print(f\"P-value: {feature_results['global_statistics']['p_value']:.3f}\")\n",
    "        print(f\"Z-score: {feature_results['global_statistics']['z_score']:.3f}\")\n",
    "        \n",
    "        print(\"\\nLocal Statistics:\")\n",
    "        print(f\"Mean Local Moran's I: {feature_results['local_statistics']['mean_local_i']:.3f}\")\n",
    "        print(f\"Number of Significant Clusters: {feature_results['local_statistics']['significant_clusters']}\")\n",
    "        print(f\"Percent Significant: {feature_results['local_statistics']['percent_significant']:.1f}%\")\n",
    "        \n",
    "        print(\"\\nCluster Type Distribution:\")\n",
    "        for cluster_type, count in feature_results['cluster_summary'].items():\n",
    "            print(f\"{cluster_type}: {count} areas\")\n",
    "\n",
    "def scale_morans_i(morans_i_values):\n",
    "    \"\"\"\n",
    "    Scale Moran's I values to ensure they fall within [-1, 1] range.\n",
    "    \"\"\"\n",
    "    abs_max = max(abs(np.min(morans_i_values)), abs(np.max(morans_i_values)))\n",
    "    if abs_max == 0:\n",
    "        return morans_i_values\n",
    "    return morans_i_values / abs_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spatial correlation on residuals from predicting target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from libpysal.weights import Queen\n",
    "from esda.moran import Moran, Moran_Local\n",
    "from branca.colormap import LinearColormap\n",
    "from typing import Tuple, Dict, List, Union, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelResults:\n",
    "    \"\"\"Container for model results to pass between components\"\"\"\n",
    "    residuals: np.ndarray\n",
    "    feature_importances: pd.DataFrame\n",
    "    predictions: np.ndarray\n",
    "    metrics: Dict\n",
    "    \n",
    "@dataclass\n",
    "class SpatialResults:\n",
    "    \"\"\"Container for spatial analysis results\"\"\"\n",
    "    moran_stats: Dict\n",
    "    spatial_weights: Queen\n",
    "    cluster_types: pd.Series = None\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_columns = None\n",
    "        \n",
    "    def _get_numeric_columns(\n",
    "        self,\n",
    "        gdf: gpd.GeoDataFrame,\n",
    "        target_column: str,\n",
    "        exclude_columns: Optional[List[str]] = None,\n",
    "        exclude_patterns: Optional[List[str]] = None\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get all numeric columns except the target and excluded columns.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        gdf : GeoDataFrame\n",
    "            Input geodataframe\n",
    "        target_column : str\n",
    "            Name of the target column to exclude\n",
    "        exclude_columns : list, optional\n",
    "            List of specific column names to exclude\n",
    "        exclude_patterns : list, optional\n",
    "            List of patterns to match for excluding columns\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list : List of column names to use as features\n",
    "        \"\"\"\n",
    "        # Get all numeric columns\n",
    "        numeric_cols = gdf.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        \n",
    "        # Remove target column if it's in numeric columns\n",
    "        if target_column in numeric_cols:\n",
    "            numeric_cols.remove(target_column)\n",
    "            \n",
    "        # Remove explicitly excluded columns\n",
    "        if exclude_columns:\n",
    "            numeric_cols = [col for col in numeric_cols if col not in exclude_columns]\n",
    "            \n",
    "        # Remove columns matching patterns\n",
    "        if exclude_patterns:\n",
    "            for pattern in exclude_patterns:\n",
    "                numeric_cols = [\n",
    "                    col for col in numeric_cols \n",
    "                    if not any(pattern.lower() in col.lower() for pattern in exclude_patterns)\n",
    "                ]\n",
    "        \n",
    "        return numeric_cols\n",
    "        \n",
    "    def fit_predict(\n",
    "        self,\n",
    "        gdf: gpd.GeoDataFrame,\n",
    "        target_column: str,\n",
    "        exclude_columns: Optional[List[str]] = None,\n",
    "        exclude_patterns: Optional[List[str]] = None,\n",
    "        test_size: float = 0.2,\n",
    "        verbose: bool = True\n",
    "    ) -> ModelResults:\n",
    "        # [Previous fit_predict implementation until predictions]\n",
    "        \"\"\"\n",
    "        Fit the model and calculate residuals using all numeric columns as features.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        gdf : GeoDataFrame\n",
    "            Input geodataframe containing features and target\n",
    "        target_column : str\n",
    "            Name of the column to predict\n",
    "        exclude_columns : list, optional\n",
    "            List of specific column names to exclude from features\n",
    "        exclude_patterns : list, optional\n",
    "            List of patterns to match for excluding columns\n",
    "        test_size : float\n",
    "            Proportion of data to use for testing\n",
    "        verbose : bool\n",
    "            Whether to print information about selected features\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Dictionary containing model performance metrics\n",
    "        \"\"\"\n",
    "        # Validate inputs\n",
    "        if not isinstance(gdf, gpd.GeoDataFrame):\n",
    "            raise TypeError(\"Input must be a GeoDataFrame\")\n",
    "        if target_column not in gdf.columns:\n",
    "            raise ValueError(f\"Target column '{target_column}' not found\")\n",
    "            \n",
    "        # Get numeric feature columns\n",
    "        self.feature_columns = self._get_numeric_columns(\n",
    "            gdf, target_column, exclude_columns, exclude_patterns\n",
    "        )\n",
    "        \n",
    "        if not self.feature_columns:\n",
    "            raise ValueError(\"No numeric feature columns found after exclusions\")\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"Using {len(self.feature_columns)} features:\")\n",
    "            print(\"\\n\".join(f\"- {col}\" for col in self.feature_columns))\n",
    "            \n",
    "        # Prepare data\n",
    "        X = gdf[self.feature_columns].copy()\n",
    "        y = gdf[target_column].copy()\n",
    "        \n",
    "        # Check for and handle missing values\n",
    "        missing_counts = X.isnull().sum()\n",
    "        if missing_counts.any():\n",
    "            if verbose:\n",
    "                print(\"\\nHandling missing values:\")\n",
    "                for col in missing_counts[missing_counts > 0].index:\n",
    "                    print(f\"- {col}: {missing_counts[col]} missing values\")\n",
    "            X = X.fillna(X.mean())\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Fit model\n",
    "        if verbose:\n",
    "            print(\"\\nFitting Random Forest model...\")\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Adjust residuals calculation for GOP=1, Dem=0 coding\n",
    "        y_pred = self.model.predict(X_scaled)\n",
    "        residuals = y - y_pred  # Positive means model under-predicted GOP\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        train_pred = self.model.predict(X_train)\n",
    "        test_pred = self.model.predict(X_test)\n",
    "\n",
    "        # Store feature importances\n",
    "        self.feature_importances = pd.DataFrame({\n",
    "            'feature': self.feature_columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        metrics = {\n",
    "            'train_r2': r2_score(y_train, train_pred),\n",
    "            'test_r2': r2_score(y_test, test_pred),\n",
    "            'train_rmse': np.sqrt(mean_squared_error(y_train, train_pred)),\n",
    "            'test_rmse': np.sqrt(mean_squared_error(y_test, test_pred)),\n",
    "        }\n",
    "        \n",
    "        return ModelResults(\n",
    "            residuals=residuals,\n",
    "            feature_importances=self.feature_importances,\n",
    "            predictions=y_pred,\n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "class SpatialAnalyzer:\n",
    "    def analyze_residuals(\n",
    "        self,\n",
    "        gdf: gpd.GeoDataFrame,\n",
    "        residuals: np.ndarray,\n",
    "        weights_type: str = 'queen',\n",
    "        verbose: bool = True\n",
    "    ) -> SpatialResults:\n",
    "        # Create spatial weights matrix\n",
    "        spatial_weights = Queen.from_dataframe(gdf)\n",
    "        spatial_weights.transform = 'r'\n",
    "        \n",
    "        # Calculate Global Moran's I\n",
    "        moran = Moran(residuals, spatial_weights)\n",
    "        local_moran = Moran_Local(residuals, spatial_weights)\n",
    "        \n",
    "        moran_stats = {\n",
    "            'global_moran_i': moran.I,\n",
    "            'p_value': moran.p_sim,\n",
    "            'z_score': moran.z_sim,\n",
    "            'local_moran_i': local_moran.Is,\n",
    "            'local_p_values': local_moran.p_sim\n",
    "        }\n",
    "        \n",
    "        return SpatialResults(moran_stats=moran_stats, spatial_weights=spatial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapVisualizer:\n",
    "    def create_map(\n",
    "        self,\n",
    "        gdf: gpd.GeoDataFrame,\n",
    "        target_column: str,\n",
    "        model_results: ModelResults,\n",
    "        spatial_results: SpatialResults,\n",
    "        center: Tuple[float, float] = None,\n",
    "        zoom_start: int = 4\n",
    "    ) -> folium.Map:\n",
    "        \"\"\"\n",
    "        Create interactive map with election results and analysis layers.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        gdf : GeoDataFrame\n",
    "            Input geodataframe\n",
    "        target_column : str\n",
    "            Name of the column containing actual results (0=Dem, 1=GOP)\n",
    "        model_results : ModelResults\n",
    "            Container with model predictions and residuals\n",
    "        spatial_results : SpatialResults\n",
    "            Container with spatial analysis results\n",
    "        center : tuple, optional\n",
    "            (lat, lon) center coordinates for the map\n",
    "        zoom_start : int, default=4\n",
    "            Initial zoom level for the map\n",
    "        \"\"\"\n",
    "        if center is None:\n",
    "            center = [gdf.geometry.centroid.y.mean(), gdf.geometry.centroid.x.mean()]\n",
    "        \n",
    "        # Create base map\n",
    "        m = folium.Map(location=center, zoom_start=zoom_start)\n",
    "        \n",
    "        # Create feature groups\n",
    "        fg_results = folium.FeatureGroup(name=\"2024 Election Results\")\n",
    "        fg_residuals = folium.FeatureGroup(name=\"Model Residuals\")\n",
    "        fg_clusters = folium.FeatureGroup(name=\"Spatial Correlation Patterns\")\n",
    "        \n",
    "        # Create colormaps\n",
    "        colormap_results = LinearColormap(\n",
    "            colors=['#2b83ba', '#ffffff', '#de2d26'],  # Blue (Dem/0) to Red (GOP/1)\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            caption=\"2024 Election Results (Blue = Democratic, Red = GOP)\"\n",
    "        )\n",
    "        \n",
    "        # Residual colormap interpretation: positive means under-predicted GOP\n",
    "        colormap_residuals = LinearColormap(\n",
    "            colors=['#2c7bb6', '#abd9e9', '#ffffbf', '#fdae61', '#d7191c'],\n",
    "            vmin=model_results.residuals.min(),\n",
    "            vmax=model_results.residuals.max(),\n",
    "            caption=\"Residuals (Blue = Under-predicted GOP, Red = Over-predicted GOP)\"\n",
    "        )\n",
    "        \n",
    "        # Calculate standardized residuals and spatial lag\n",
    "        std_residuals = (model_results.residuals - model_results.residuals.mean()) / model_results.residuals.std()\n",
    "        lag_residuals = spatial_results.spatial_weights.sparse.dot(std_residuals)\n",
    "        \n",
    "        # Determine cluster types\n",
    "        significance_level = 0.05\n",
    "        sig_mask = spatial_results.moran_stats['local_p_values'] < significance_level\n",
    "        \n",
    "        cluster_types = pd.Series(index=gdf.index, data='Not Significant')\n",
    "        \n",
    "        # High-High: both residual and lag are positive (clusters of GOP under-prediction)\n",
    "        cluster_types[sig_mask & (std_residuals > 0) & (lag_residuals > 0)] = 'High-High'\n",
    "        \n",
    "        # Low-Low: both residual and lag are negative (clusters of GOP over-prediction)\n",
    "        cluster_types[sig_mask & (std_residuals < 0) & (lag_residuals < 0)] = 'Low-Low'\n",
    "        \n",
    "        # High-Low: residual is positive, lag is negative (GOP under-prediction outliers)\n",
    "        cluster_types[sig_mask & (std_residuals > 0) & (lag_residuals < 0)] = 'High-Low'\n",
    "        \n",
    "        # Low-High: residual is negative, lag is positive (GOP over-prediction outliers)\n",
    "        cluster_types[sig_mask & (std_residuals < 0) & (lag_residuals > 0)] = 'Low-High'\n",
    "        \n",
    "        # Define colors for cluster types\n",
    "        cluster_colors = {\n",
    "            'High-High': '#d7191c',     # Red: Under-predicted GOP clusters\n",
    "            'Low-Low': '#2c7bb6',       # Blue: Over-predicted GOP clusters\n",
    "            'High-Low': '#fdae61',      # Orange: Under-predicted GOP outliers\n",
    "            'Low-High': '#abd9e9',      # Light Blue: Over-predicted GOP outliers\n",
    "            'Not Significant': '#ffffbf' # Beige: No significant pattern\n",
    "        }\n",
    "        \n",
    "        # Add election results layer\n",
    "        for idx, row in gdf.iterrows():\n",
    "            result = row[target_column]\n",
    "            winner = 'Democratic' if result == 0 else 'GOP'\n",
    "            winner_color = '#2b83ba' if result == 0 else '#de2d26'\n",
    "            \n",
    "            folium.GeoJson(\n",
    "                row.geometry.__geo_interface__,\n",
    "                style_function=lambda x, color=winner_color: {\n",
    "                    'fillColor': color,\n",
    "                    'color': 'black',\n",
    "                    'weight': 1,\n",
    "                    'fillOpacity': 0.7\n",
    "                },\n",
    "                tooltip=f\"\"\"\n",
    "                    Winner: {winner}<br>\n",
    "                    County: {row.get('county_name', 'N/A')}<br>\n",
    "                    State: {row.get('state_name', 'N/A')}\n",
    "                \"\"\"\n",
    "            ).add_to(fg_results)\n",
    "        \n",
    "        # Add residuals layer\n",
    "        for idx, row in gdf.iterrows():\n",
    "            residual = model_results.residuals[idx]\n",
    "            color = colormap_residuals(residual)\n",
    "            \n",
    "            prediction = model_results.predictions[idx]\n",
    "            predicted_winner = 'GOP' if prediction > 0.5 else 'Democratic'\n",
    "            actual_winner = 'GOP' if row[target_column] == 1 else 'Democratic'\n",
    "            \n",
    "            folium.GeoJson(\n",
    "                row.geometry.__geo_interface__,\n",
    "                style_function=lambda x, color=color: {\n",
    "                    'fillColor': color,\n",
    "                    'color': 'black',\n",
    "                    'weight': 1,\n",
    "                    'fillOpacity': 0.7\n",
    "                },\n",
    "                tooltip=f\"\"\"\n",
    "                    County: {row.get('county_name', 'N/A')}<br>\n",
    "                    State: {row.get('state_name', 'N/A')}<br>\n",
    "                    Residual: {residual:.3f}<br>\n",
    "                    Actual Winner: {actual_winner}<br>\n",
    "                    Predicted Winner: {predicted_winner}<br>\n",
    "                    Model Prediction: {prediction:.3f}\n",
    "                \"\"\"\n",
    "            ).add_to(fg_residuals)\n",
    "        \n",
    "        # Add cluster type layer\n",
    "        for idx, row in gdf.iterrows():\n",
    "            cluster_type = cluster_types[idx]\n",
    "            color = cluster_colors[cluster_type]\n",
    "            \n",
    "            interpretation = {\n",
    "                'High-High': 'Cluster of GOP under-prediction',\n",
    "                'Low-Low': 'Cluster of GOP over-prediction',\n",
    "                'High-Low': 'GOP under-prediction outlier',\n",
    "                'Low-High': 'GOP over-prediction outlier',\n",
    "                'Not Significant': 'No significant spatial pattern'\n",
    "            }\n",
    "            \n",
    "            folium.GeoJson(\n",
    "                row.geometry.__geo_interface__,\n",
    "                style_function=lambda x, color=color: {\n",
    "                    'fillColor': color,\n",
    "                    'color': 'black',\n",
    "                    'weight': 1,\n",
    "                    'fillOpacity': 0.7\n",
    "                },\n",
    "                tooltip=f\"\"\"\n",
    "                    County: {row.get('county_name', 'N/A')}<br>\n",
    "                    State: {row.get('state_name', 'N/A')}<br>\n",
    "                    Pattern: {cluster_type}<br>\n",
    "                    Interpretation: {interpretation[cluster_type]}<br>\n",
    "                    Residual: {model_results.residuals[idx]:.3f}\n",
    "                \"\"\"\n",
    "            ).add_to(fg_clusters)\n",
    "        \n",
    "        # Add layers to map\n",
    "        fg_results.add_to(m)\n",
    "        fg_residuals.add_to(m)\n",
    "        fg_clusters.add_to(m)\n",
    "        colormap_results.add_to(m)\n",
    "        colormap_residuals.add_to(m)\n",
    "        \n",
    "        # Add cluster type legend\n",
    "        legend_html = \"\"\"\n",
    "        <div style=\"position: fixed; bottom: 50px; right: 50px; z-index: 1000; background-color: white; \n",
    "                    padding: 10px; border: 2px solid grey; border-radius: 5px\">\n",
    "        <p><strong>Spatial Correlation Patterns</strong></p>\n",
    "        \"\"\"\n",
    "        for cluster_type, color in cluster_colors.items():\n",
    "            interpretation = {\n",
    "                'High-High': 'Cluster of GOP under-prediction',\n",
    "                'Low-Low': 'Cluster of GOP over-prediction',\n",
    "                'High-Low': 'GOP under-prediction outlier',\n",
    "                'Low-High': 'GOP over-prediction outlier',\n",
    "                'Not Significant': 'No significant spatial pattern'\n",
    "            }\n",
    "            legend_html += f\"\"\"\n",
    "            <p><i class=\"fa fa-square fa-1x\" style=\"color:{color}\"></i> \n",
    "            {cluster_type}: {interpretation[cluster_type]}</p>\n",
    "            \"\"\"\n",
    "        legend_html += \"</div>\"\n",
    "        m.get_root().html.add_child(folium.Element(legend_html))\n",
    "        \n",
    "        # Add layer control\n",
    "        folium.LayerControl().add_to(m)\n",
    "        \n",
    "        return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All spatial correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from libpysal.weights import Queen, KNN\n",
    "from esda.moran import Moran, Moran_Local\n",
    "import warnings\n",
    "from typing import Union, Tuple, Dict, List\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "@dataclass\n",
    "class SpatialCorrelationResult:\n",
    "    \"\"\"Data class to store correlation results for a single feature\"\"\"\n",
    "    feature: str\n",
    "    global_morans_i: float\n",
    "    global_p_value: float\n",
    "    global_z_score: float\n",
    "    mean_local_i: float\n",
    "    significant_clusters: int\n",
    "    percent_significant: float\n",
    "    cluster_counts: Dict[str, int]\n",
    "\n",
    "def calculate_multi_feature_correlation(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    features: List[str] = None,\n",
    "    weight_type: str = 'queen',\n",
    "    k_neighbors: int = 5,\n",
    "    exclude_columns: List[str] = None\n",
    ") -> List[SpatialCorrelationResult]:\n",
    "    \"\"\"\n",
    "    Calculates spatial correlation metrics for multiple features in a GeoDataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : gpd.GeoDataFrame\n",
    "        GeoDataFrame containing geometry and data\n",
    "    features : List[str], optional\n",
    "        List of column names to analyze. If None, will analyze all numeric columns\n",
    "    weight_type : str, optional (default='queen')\n",
    "        Type of spatial weights to use ('queen' or 'knn')\n",
    "    k_neighbors : int, optional (default=5)\n",
    "        Number of neighbors for KNN weights\n",
    "    exclude_columns : List[str], optional\n",
    "        List of column names to exclude from analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List[SpatialCorrelationResult]\n",
    "        List of correlation results for each feature\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(gdf, gpd.GeoDataFrame):\n",
    "        raise TypeError(\"Input must be a GeoDataFrame\")\n",
    "        \n",
    "    # If no features specified, use all numeric columns\n",
    "    if features is None:\n",
    "        features = gdf.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remove excluded columns\n",
    "    if exclude_columns:\n",
    "        features = [f for f in features if f not in exclude_columns]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Create spatial weights matrix once\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        if weight_type.lower() == 'queen':\n",
    "            weights = Queen.from_dataframe(gdf, use_index=True)\n",
    "            # Handle islands\n",
    "            islands = weights.islands\n",
    "            if len(islands) > 0:\n",
    "                gdf = gdf[~gdf.index.isin(islands)].copy()\n",
    "                weights = Queen.from_dataframe(gdf, use_index=True)\n",
    "        elif weight_type.lower() == 'knn':\n",
    "            weights = KNN.from_dataframe(gdf, k=k_neighbors)\n",
    "        else:\n",
    "            raise ValueError(\"weight_type must be either 'queen' or 'knn'\")\n",
    "    \n",
    "    weights.transform = 'r'  # Row-standardize weights\n",
    "    \n",
    "    # Analyze each feature\n",
    "    for feature in features:\n",
    "        # Skip if feature has all missing values\n",
    "        if gdf[feature].isnull().all():\n",
    "            continue\n",
    "            \n",
    "        # Create copy of data without missing values for this feature\n",
    "        gdf_clean = gdf.dropna(subset=[feature]).copy()\n",
    "        \n",
    "        if len(gdf_clean) < 2:  # Skip if not enough data\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Calculate Global Moran's I\n",
    "            moran = Moran(gdf_clean[feature], weights)\n",
    "            \n",
    "            # Calculate Local Moran's I\n",
    "            local_moran = Moran_Local(gdf_clean[feature], weights)\n",
    "            \n",
    "            # Calculate cluster types\n",
    "            sig_mask = local_moran.p_sim < 0.05\n",
    "            std_val = (gdf_clean[feature] - gdf_clean[feature].mean()) / gdf_clean[feature].std()\n",
    "            lag_val = weights.sparse.dot(std_val)\n",
    "            \n",
    "            cluster_types = np.full(len(gdf_clean), 'Not Significant', dtype=object)\n",
    "            cluster_types[sig_mask & (std_val > 0) & (lag_val > 0)] = 'High-High'\n",
    "            cluster_types[sig_mask & (std_val < 0) & (lag_val < 0)] = 'Low-Low'\n",
    "            cluster_types[sig_mask & (std_val > 0) & (lag_val < 0)] = 'High-Low'\n",
    "            cluster_types[sig_mask & (std_val < 0) & (lag_val > 0)] = 'Low-High'\n",
    "            \n",
    "            cluster_counts = dict(pd.Series(cluster_types).value_counts())\n",
    "            \n",
    "            result = SpatialCorrelationResult(\n",
    "                feature=feature,\n",
    "                global_morans_i=moran.I,\n",
    "                global_p_value=moran.p_sim,\n",
    "                global_z_score=moran.z_sim,\n",
    "                mean_local_i=np.mean(local_moran.Is),\n",
    "                significant_clusters=np.sum(sig_mask),\n",
    "                percent_significant=np.mean(sig_mask) * 100,\n",
    "                cluster_counts=cluster_counts\n",
    "            )\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing feature {feature}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    return results\n",
    "\n",
    "def get_top_correlations(\n",
    "    results: List[SpatialCorrelationResult],\n",
    "    n: int = 5,\n",
    "    p_threshold: float = 0.05,\n",
    "    sort_by: str = 'global'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns the top n features by spatial correlation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : List[SpatialCorrelationResult]\n",
    "        List of correlation results\n",
    "    n : int, optional (default=5)\n",
    "        Number of top features to return\n",
    "    p_threshold : float, optional (default=0.05)\n",
    "        Only include results with p-value below this threshold\n",
    "    sort_by : str, optional (default='global')\n",
    "        Sort by 'global' or 'local' Moran's I\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Sorted DataFrame of top correlations\n",
    "    \"\"\"\n",
    "    # Convert results to DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            'feature': r.feature,\n",
    "            'global_morans_i': r.global_morans_i,\n",
    "            'global_p_value': r.global_p_value,\n",
    "            'global_z_score': r.global_z_score,\n",
    "            'mean_local_i': r.mean_local_i,\n",
    "            'significant_clusters': r.significant_clusters,\n",
    "            'percent_significant': r.percent_significant\n",
    "        }\n",
    "        for r in results\n",
    "    ])\n",
    "    \n",
    "    # Filter by p-value\n",
    "    df = df[df['global_p_value'] < p_threshold]\n",
    "    \n",
    "    # Sort by specified metric\n",
    "    sort_col = 'global_morans_i' if sort_by == 'global' else 'mean_local_i'\n",
    "    df = df.sort_values(by=sort_col, ascending=False)\n",
    "    \n",
    "    return df.head(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aispace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
