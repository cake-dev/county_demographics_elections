{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counties_senate_districts = gpd.read_file('data/election/cb_2018_us_county_within_senate_districts/cb_2018_us_county_within_cd116_500k.shp')\n",
    "counties = gpd.read_file('data/election/cb_2018_us_county_5m/cb_2018_us_county_5m.shp')\n",
    "election_senate_2022_county = pd.read_csv('data/election/senate_2022.csv')\n",
    "education_counties = pd.read_csv('data/election/us_counties_education_1970_2022.csv')\n",
    "unemployment_counties = pd.read_csv('data/election/us_counties_unemployment_2000_2022.csv')\n",
    "poverity_counties = pd.read_csv('data/election/us_counties_poverty_2021.csv')\n",
    "population_counties = pd.read_csv('data/election/us_counties_population_2020_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all STATEFP in counties, remove the leading 0\n",
    "counties['STATEFP'] = counties['STATEFP'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties['FIPS Code'] = counties['STATEFP'] + counties['COUNTYFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_counties['FIPS Code'] = education_counties['FIPS Code'].astype(str)\n",
    "unemployment_counties['FIPS Code'] = unemployment_counties['FIPS_Code'].astype(str)\n",
    "poverity_counties['FIPS Code'] = poverity_counties['FIPS_Code'].astype(str)\n",
    "population_counties['FIPS Code'] = population_counties['FIPStxt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the education data with the counties data on the FIPS Code column\n",
    "education_counties_merged = education_counties.merge(counties, on='FIPS Code')\n",
    "# merge the unemployment data with the counties data on the FIPS Code column\n",
    "unemployment_counties_merged = unemployment_counties.merge(counties, on='FIPS Code')\n",
    "# merge the poverity data with the counties data on the FIPS Code column\n",
    "poverity_counties_merged = poverity_counties.merge(counties, on='FIPS Code')\n",
    "# merge the population data with the counties data on the FIPS Code column\n",
    "population_counties_merged = population_counties.merge(counties, on='FIPS Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverity_counties_merged.drop(columns=['STATEFP', 'COUNTYFP',\n",
    "       'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD', 'ALAND', 'AWATER',\n",
    "       'geometry'], inplace=True)\n",
    "unemployment_counties_merged.drop(columns=['STATEFP', 'COUNTYFP',\n",
    "       'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD', 'ALAND', 'AWATER',\n",
    "       'geometry'], inplace=True)\n",
    "population_counties_merged.drop(columns=['STATEFP', 'COUNTYFP',\n",
    "       'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD', 'ALAND', 'AWATER',\n",
    "       'geometry'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the dataframes\n",
    "merged = education_counties_merged.merge(unemployment_counties_merged, on='FIPS Code')\n",
    "merged = merged.merge(poverity_counties_merged, on='FIPS Code')\n",
    "merged = merged.merge(population_counties_merged, on='FIPS Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_geo = gpd.GeoDataFrame(merged, geometry=merged['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns from merged_geo containing any of the following strings in the col name: 'Urban', 'Rural', '1970', '1980', '1990'\n",
    "cols_to_drop = [col for col in merged_geo.columns if 'Urban' in col or 'Rural' in col or '1970' in col or '1980' in col or '1990' in col]\n",
    "merged_geo.drop(columns=cols_to_drop, inplace=True)\n",
    "merged_geo.drop(columns=['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD'], inplace=True)\n",
    "merged_geo.drop(columns=['FIPS_Code_x', 'State_y', 'Area_Name_x', 'FIPS_Code_y', 'Stabr', 'Area_name', 'State', 'Area_Name_y'], inplace=True)\n",
    "merged_geo.rename(columns={'State_x': 'State'}, inplace=True)\n",
    "merged_geo = merged_geo[~merged_geo['State'].isin(['AK', 'HI', 'DC'])]\n",
    "merged_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in counties, show entries where NAME is 'Orleans'\n",
    "counties[counties['NAME'] == 'Orleans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the merged data to a geojson file\n",
    "merged_geo.to_file('data/election/final_data/counties_data.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the geojson file\n",
    "county_level_data = gpd.read_file('data/election/final_data/counties_data.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_level_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to county level data that is the full name of the state, call it State_name\n",
    "state_names = {\n",
    "    'AL': 'Alabama',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "county_level_data['State_name'] = county_level_data['State'].map(state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_level_data.to_file('data/election/final_data/counties_data.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column called state_county that is the concatenation of the state and county name, underscore separated\n",
    "county_level_data['state_county'] = county_level_data['State_name'] + '_' + county_level_data['Area name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change state_county to lower case\n",
    "county_level_data['state_county'] = county_level_data['state_county'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_level_data[~county_level_data['state_county'].str.contains('county')]\n",
    "# show the uniqe ending words in the state_county column (after the last space)\n",
    "county_level_data['state_county'].str.split('_').str[-1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all rows where state_county starts with maine\n",
    "county_level_data[county_level_data['state_county'].str.startswith('maine')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all rows where state_county starts with maine\n",
    "county_level_data[county_level_data['state_county'].str.startswith('maine')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot of PCTPOVALL_2021 vs Unemployment_rate_2021, include a best fit line\n",
    "fig, ax = plt.subplots()\n",
    "merged_geo.plot.scatter(x='PCTPOVALL_2021', y='Unemployment_rate_2021', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the 2016 and 2020 election data\n",
    "election_2016 = pd.read_csv('data/election/2016_US_County_Level_Presidential_Results.csv')\n",
    "election_2020 = pd.read_csv('data/election/2020_US_County_Level_Presidential_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the 2012 election data\n",
    "election_2012 = pd.read_csv('data/election/US_County_Level_Presidential_Results_12-16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns from election_2012 containing any of the following strings in the col name: '2016'\n",
    "cols_to_drop = [col for col in election_2012.columns if '2016' in col]\n",
    "election_2012.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2016 = election_2016[~election_2016.state_abbr.isin(['AK', 'HI', 'DC'])]\n",
    "election_2020 = election_2020[~election_2020.state_name.isin(['Alaska', 'Hawaii', 'District of Columbia'])]\n",
    "election_2012 = election_2012[~election_2012.state_abbr.isin(['AK', 'HI', 'DC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in both election_2016 and election_2020, append _2016 or _2020 to the end of the column names where the name is in votes_gop\tvotes_dem\ttotal_votes\tdiff\tper_gop\tper_dem\n",
    "election_2016.columns = election_2016.columns.str.replace('votes_gop', 'votes_gop_2016')\n",
    "election_2016.columns = election_2016.columns.str.replace('votes_dem', 'votes_dem_2016')\n",
    "election_2016.columns = election_2016.columns.str.replace('total_votes', 'total_votes_2016')\n",
    "election_2016.columns = election_2016.columns.str.replace('diff', 'diff_2016')\n",
    "election_2016.columns = election_2016.columns.str.replace('per_gop', 'per_gop_2016')\n",
    "election_2016.columns = election_2016.columns.str.replace('per_dem', 'per_dem_2016')\n",
    "\n",
    "election_2020.columns = election_2020.columns.str.replace('votes_gop', 'votes_gop_2020')\n",
    "election_2020.columns = election_2020.columns.str.replace('votes_dem', 'votes_dem_2020')\n",
    "election_2020.columns = election_2020.columns.str.replace('total_votes', 'total_votes_2020')\n",
    "election_2020.columns = election_2020.columns.str.replace('diff', 'diff_2020')\n",
    "election_2020.columns = election_2020.columns.str.replace('per_gop', 'per_gop_2020')\n",
    "election_2020.columns = election_2020.columns.str.replace('per_dem', 'per_dem_2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename county_fips in election_2020 to combined_fips\n",
    "election_2020.rename(columns={'county_fips': 'combined_fips'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the combined_fips column in both election_2016 and election_2020 to string\n",
    "election_2016['combined_fips'] = election_2016['combined_fips'].astype(str)\n",
    "election_2020['combined_fips'] = election_2020['combined_fips'].astype(str)\n",
    "election_2012['combined_fips'] = election_2012['combined_fips'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge election_2020 with merged_geo on the FIPS Code column\n",
    "election_2012_merged = election_2012.merge(merged_geo, left_on='combined_fips', right_on='FIPS Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2012_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 2016 into the 2020_merged data on the combined_fips column\n",
    "election_2012_2016_merged = election_2012_merged.merge(election_2016, on='combined_fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2012_2016_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 2012 into the 2016_2020_merged data on the combined_fips column\n",
    "election_2012_2016_2020_merged = election_2012_2016_merged.merge(election_2020, on='combined_fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2012_2016_2020_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all commas from values in all columns with object type\n",
    "election_2012_2016_2020_merged = election_2012_2016_2020_merged.apply(lambda x: x.str.replace(',', '') if x.dtype == 'object' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2012_2016_2020_merged.drop(columns=['POV04_2021', 'CI90LB04_2021', 'CI90UB04_2021', 'PCTPOV04_2021', 'CI90LB04P_2021', 'CI90UB04P_2021'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2012_2016_2020_merged.drop(columns=['county_name_x', 'combined_fips', 'FIPStxt', 'county_name_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2012_2016_2020_merged.drop(columns=['Unnamed: 0_x', 'FIPS', 'county_fips', 'state_fips', 'state_abbr_y', 'Unnamed: 0_y', 'Area name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_2012_2016_2020_merged.drop(columns=['State'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# election_2012_2016_2020_merged, show columns that contain 2012\n",
    "election_2012_2016_2020_merged.columns[election_2012_2016_2020_merged.columns.str.contains('2012')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in election_2012_2016_2020_merged, create a columns called winner_2012, winner_2016 and winner_2020 that is the name of the winner of the election in that year\n",
    "election_2012_2016_2020_merged['winner_2012'] = np.where(election_2012_2016_2020_merged['per_gop_2012'] > election_2012_2016_2020_merged['per_dem_2012'], 'GOP', 'DEM')\n",
    "election_2012_2016_2020_merged['winner_2016'] = np.where(election_2012_2016_2020_merged['per_gop_2016'] > election_2012_2016_2020_merged['per_dem_2016'], 'GOP', 'DEM')\n",
    "election_2012_2016_2020_merged['winner_2020'] = np.where(election_2012_2016_2020_merged['per_gop_2020'] > election_2012_2016_2020_merged['per_dem_2020'], 'GOP', 'DEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename state_abbr_x to state_abbr\n",
    "election_2012_2016_2020_merged.rename(columns={'state_abbr_x': 'state_abbr'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# president counties 2020\n",
    "president_counties_2020 = pd.read_csv('data/election/president_county_candidate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_counties_2020 = president_counties_2020[~president_counties_2020.state.isin(['Alaska', 'Hawaii', 'District of Columbia'])]\n",
    "# drop rows where party is not 'DEM' or 'REP'\n",
    "president_counties_2020 = president_counties_2020[president_counties_2020.party.isin(['DEM', 'REP'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(president_counties_2020.state.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_counties_2020['state_county'] = president_counties_2020['state'] + '_' + president_counties_2020['county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now reduce the number of rows by having each county appear only once.  the columns candidate, party, total_votes, won are translated into columns as such: candidate_dem, candidate_rep, party_dem, party_rep, total_votes_dem, total_votes_rep, won_dem, won_rep\n",
    "president_counties_2020_fixed = president_counties_2020.pivot(index='state_county', columns='party', values=['candidate', 'total_votes', 'won'])\n",
    "president_counties_2020_fixed.columns = ['_'.join(col).strip() for col in president_counties_2020_fixed.columns.values]\n",
    "president_counties_2020_fixed.reset_index(inplace=True)\n",
    "president_counties_2020_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to president_counties_2020_fixed that is called winner_2020, which is 'DEM' if won_dem == True, 'REP' if won_rep == True\n",
    "president_counties_2020_fixed['winner_2020'] = np.where(president_counties_2020_fixed['won_DEM'] == True, 'DEM', 'REP')\n",
    "president_counties_2020_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show rows in state_county that do not have the word 'County' in them\n",
    "president_counties_2020_fixed[president_counties_2020_fixed.state_county.str.contains('city')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for values in predident_counties_2020_fixed where state_county does not contain 'Parish' or 'city', append ' County' to the end of the value\n",
    "president_counties_2020_fixed['state_county'] = np.where(president_counties_2020_fixed['state_county'].str.contains('Parish') | president_counties_2020_fixed['state_county'].str.contains('city') | president_counties_2020_fixed['state_county'].str.contains('County'), president_counties_2020_fixed['state_county'], president_counties_2020_fixed['state_county'] + ' County')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_counties_2020_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_merge_issues(df1, df2, key_column, df1_name='Left DataFrame', df2_name='Right DataFrame'):\n",
    "    \"\"\"\n",
    "    Diagnose why certain rows are being dropped in a merge operation.\n",
    "    \n",
    "    Args:\n",
    "        df1 (pandas.DataFrame): First DataFrame\n",
    "        df2 (pandas.DataFrame): Second DataFrame\n",
    "        key_column (str): Column name used for merging\n",
    "        df1_name (str): Name for first DataFrame for reporting\n",
    "        df2_name (str): Name for second DataFrame for reporting\n",
    "    \"\"\"\n",
    "    # Check for duplicates in merge column\n",
    "    print(f\"\\nChecking for duplicates in merge column '{key_column}':\")\n",
    "    print(f\"{df1_name} duplicates: {df1[key_column].duplicated().sum()}\")\n",
    "    print(f\"{df2_name} duplicates: {df2[key_column].duplicated().sum()}\")\n",
    "    \n",
    "    if df1[key_column].duplicated().sum() > 0:\n",
    "        print(f\"\\nDuplicate values in {df1_name}:\")\n",
    "        print(df1[df1[key_column].duplicated(keep=False)][key_column].sort_values())\n",
    "    \n",
    "    if df2[key_column].duplicated().sum() > 0:\n",
    "        print(f\"\\nDuplicate values in {df2_name}:\")\n",
    "        print(df2[df2[key_column].duplicated(keep=False)][key_column].sort_values())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\nChecking for missing values in '{key_column}':\")\n",
    "    print(f\"{df1_name} missing values: {df1[key_column].isna().sum()}\")\n",
    "    print(f\"{df2_name} missing values: {df2[key_column].isna().sum()}\")\n",
    "    \n",
    "    # Compare value distributions\n",
    "    print(f\"\\nComparing unique values in '{key_column}':\")\n",
    "    df1_values = set(df1[key_column].dropna())\n",
    "    df2_values = set(df2[key_column].dropna())\n",
    "    \n",
    "    print(f\"\\nTotal unique values:\")\n",
    "    print(f\"{df1_name}: {len(df1_values)}\")\n",
    "    print(f\"{df2_name}: {len(df2_values)}\")\n",
    "    \n",
    "    # Find values in df1 that aren't in df2 and vice versa\n",
    "    only_in_df1 = df1_values - df2_values\n",
    "    only_in_df2 = df2_values - df1_values\n",
    "    \n",
    "    if only_in_df1:\n",
    "        print(f\"\\nValues only in {df1_name} (showing first 10):\")\n",
    "        print(sorted(list(only_in_df1))[:10])\n",
    "    \n",
    "    if only_in_df2:\n",
    "        print(f\"\\nValues only in {df2_name} (showing first 10):\")\n",
    "        print(sorted(list(only_in_df2))[:10])\n",
    "    \n",
    "    # Check for leading/trailing whitespace\n",
    "    print(f\"\\nChecking for leading/trailing whitespace in '{key_column}':\")\n",
    "    df1_space = df1[df1[key_column].astype(str).str.strip() != df1[key_column].astype(str)]\n",
    "    df2_space = df2[df2[key_column].astype(str).str.strip() != df2[key_column].astype(str)]\n",
    "    \n",
    "    if len(df1_space) > 0:\n",
    "        print(f\"\\nValues with whitespace in {df1_name} (showing first 5):\")\n",
    "        print(df1_space[key_column].head())\n",
    "    \n",
    "    if len(df2_space) > 0:\n",
    "        print(f\"\\nValues with whitespace in {df2_name} (showing first 5):\")\n",
    "        print(df2_space[key_column].head())\n",
    "    \n",
    "    # Check for case differences\n",
    "    print(f\"\\nChecking for case differences:\")\n",
    "    df1_lower = set(df1[key_column].astype(str).str.lower())\n",
    "    df2_lower = set(df2[key_column].astype(str).str.lower())\n",
    "    case_diff = len(df1_values.intersection(df2_values)) != len(df1_lower.intersection(df2_lower))\n",
    "    \n",
    "    if case_diff:\n",
    "        print(\"Warning: Found case differences in matching values!\")\n",
    "        \n",
    "    # Sample a few unmatched values for detailed comparison\n",
    "    if only_in_df1 or only_in_df2:\n",
    "        print(\"\\nDetailed comparison of a few unmatched values:\")\n",
    "        for val in list(only_in_df1)[:3]:\n",
    "            close_matches = [x for x in df2_values if str(val).lower() in str(x).lower() or str(x).lower() in str(val).lower()]\n",
    "            if close_matches:\n",
    "                print(f\"\\nValue in {df1_name}: '{val}'\")\n",
    "                print(f\"Similar values in {df2_name}: {close_matches}\")\n",
    "\n",
    "def fix_merge_issues(df1, df2, key_column):\n",
    "    \"\"\"\n",
    "    Try to fix common merge issues in both DataFrames.\n",
    "    \n",
    "    Args:\n",
    "        df1 (pandas.DataFrame): First DataFrame\n",
    "        df2 (pandas.DataFrame): Second DataFrame\n",
    "        key_column (str): Column name used for merging\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (cleaned_df1, cleaned_df2)\n",
    "    \"\"\"\n",
    "    # Create copies to avoid modifying originals\n",
    "    df1_clean = df1.copy()\n",
    "    df2_clean = df2.copy()\n",
    "    \n",
    "    # Strip whitespace\n",
    "    if df1_clean[key_column].dtype == object:\n",
    "        df1_clean[key_column] = df1_clean[key_column].str.strip()\n",
    "    if df2_clean[key_column].dtype == object:\n",
    "        df2_clean[key_column] = df2_clean[key_column].str.strip()\n",
    "    \n",
    "    # Remove any duplicate rows based on the key column\n",
    "    df1_clean = df1_clean.drop_duplicates(subset=[key_column])\n",
    "    df2_clean = df2_clean.drop_duplicates(subset=[key_column])\n",
    "    \n",
    "    return df1_clean, df2_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnose_merge_issues(county_level_data, president_counties_2020_fixed, 'state_county', 'county_level_data', 'president_counties_2020_fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change state_county to lower case for president_counties_2020_fixed\n",
    "president_counties_2020_fixed['state_county'] = president_counties_2020_fixed['state_county'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the president_counties_2020_fixed data with the county_level_data data on the state_county column\n",
    "president_counties_2020_merged = county_level_data.merge(president_counties_2020_fixed, on='state_county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(president_counties_2020_merged.State.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_counties_2020_merged.to_file('data/election/final_data/county_data_with_2020_election.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_counties_2020_merged = gpd.read_file('data/election/final_data/county_data_with_2020_election.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all commas from values in all columns with object type\n",
    "president_counties_2020_merged = president_counties_2020_merged.apply(lambda x: x.str.replace(',', '') if x.dtype == 'object' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_counties_2020_merged.drop(columns=['POV04_2021', 'CI90LB04_2021', 'CI90UB04_2021', 'PCTPOV04_2021', 'CI90LB04P_2021', 'CI90UB04P_2021'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(president_counties_2020_merged.State.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make election_2012_2016_2020_merged as gdf\n",
    "president_counties_merged = gpd.GeoDataFrame(election_2012_2016_2020_merged, geometry=election_2012_2016_2020_merged['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save president_counties_2020_merged as geojson\n",
    "president_counties_2020_merged.to_file('data/election/final_data/county_data_final.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_counties_merged.to_file('data/election/final_data/county_data_with_elections_2012_2016_2020.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_2020_data = gpd.read_file('data/election/final_data/county_data_with_2020_election.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_2020_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_2020_data.set_geometry('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop POV04_2021\tCI90LB04_2021\tCI90UB04_2021\tPCTPOV04_2021\tCI90LB04P_2021\tCI90UB04P_2021 from counties_2020_data\n",
    "counties_2020_data.drop(columns=['POV04_2021', 'CI90LB04_2021', 'CI90UB04_2021', 'PCTPOV04_2021', 'CI90LB04P_2021', 'CI90UB04P_2021'], inplace=True)\n",
    "# save as geojson\n",
    "counties_2020_data.to_file('data/election/final_data/county_data_with_2020_election_results.geojson', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treefire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
