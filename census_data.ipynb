{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in census data for 2012, 2016, and 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race_2012 = pd.read_csv('data/election/census/census_race_2012.csv')\n",
    "df_race_2016 = pd.read_csv('data/election/census/census_race_2016.csv')\n",
    "df_race_2020 = pd.read_csv('data/election/census/census_race_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_sex_2012 = pd.read_csv('data/election/census/census_age_sex_2012.csv')\n",
    "df_age_sex_2016 = pd.read_csv('data/election/census/census_age_sex_2016.csv')\n",
    "df_age_sex_2020 = pd.read_csv('data/election/census/census_age_sex_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_employment_2012 = pd.read_csv('data/election/census/census_employment_2012.csv')\n",
    "df_age_employment_2016 = pd.read_csv('data/election/census/census_employment_2016.csv')\n",
    "df_age_employment_2020 = pd.read_csv('data/election/census/census_employment_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industry_2012 = pd.read_csv('data/election/census/census_industry_2012.csv')\n",
    "df_industry_2016 = pd.read_csv('data/election/census/census_industry_2016.csv')\n",
    "df_industry_2020 = pd.read_csv('data/election/census/census_industry_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_financial_2012 = pd.read_csv('data/election/census/census_housing_finanical_2012.csv')\n",
    "df_housing_financial_2016 = pd.read_csv('data/election/census/census_housing_finanical_2016.csv')\n",
    "df_housing_financial_2020 = pd.read_csv('data/election/census/census_housing_finanical_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veteran_status_2012 = pd.read_csv('data/election/census/census_veteran_status_2012.csv')\n",
    "df_veteran_status_2016 = pd.read_csv('data/election/census/census_veteran_status_2016.csv')\n",
    "df_veteran_status_2020 = pd.read_csv('data/election/census/census_veteran_status_2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape race data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reshape_demographics_race_data(df):\n",
    "    \"\"\"\n",
    "    Reshape demographic data from wide format to long format with separate county and state columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input dataframe with demographic data\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped dataframe with county and state as rows and demographic categories as columns\n",
    "    \"\"\"\n",
    "    # Reset index to get the Label column as a regular column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Melt the dataframe to convert counties from columns to rows\n",
    "    melted = pd.melt(\n",
    "        df,\n",
    "        id_vars=['Label (Grouping)'],\n",
    "        var_name='location',\n",
    "        value_name='value'\n",
    "    )\n",
    "    \n",
    "    # Split the location column into county and state\n",
    "    # Remove the '!!Estimate' suffix and split on the last comma\n",
    "    melted['location'] = melted['location'].str.replace('!!Estimate', '')\n",
    "    melted[['county_name', 'state_name']] = melted['location'].str.rsplit(',', n=1, expand=True)\n",
    "    \n",
    "    # Strip whitespace from county and state names\n",
    "    melted['county_name'] = melted['county_name'].str.strip()\n",
    "    melted['state_name'] = melted['state_name'].str.strip()\n",
    "    \n",
    "    # Pivot the data to get demographic categories as columns\n",
    "    reshaped = melted.pivot(\n",
    "        index=['county_name', 'state_name'],\n",
    "        columns='Label (Grouping)',\n",
    "        values='value'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Clean up column names by removing any extra levels\n",
    "    reshaped.columns.name = None\n",
    "    \n",
    "    # Reorder columns to have county_name and state_name first\n",
    "    demographic_cols = [col for col in reshaped.columns if col not in ['county_name', 'state_name']]\n",
    "    column_order = ['county_name', 'state_name'] + demographic_cols\n",
    "    \n",
    "    return reshaped[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race_2012_reshaped = reshape_demographics_race_data(df_race_2012)\n",
    "df_race_2012_reshaped = df_race_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_race_2016_reshaped = reshape_demographics_race_data(df_race_2016)\n",
    "df_race_2016_reshaped = df_race_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_race_2020_reshaped = reshape_demographics_race_data(df_race_2020)\n",
    "df_race_2020_reshaped = df_race_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_race_2012_reshaped.to_csv('data/election/census/census_race_2012_reshaped.csv', index=False)\n",
    "df_race_2016_reshaped.to_csv('data/election/census/census_race_2016_reshaped.csv', index=False)\n",
    "df_race_2020_reshaped.to_csv('data/election/census/census_race_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_demographics_age_data(df):\n",
    "    # First, let's get the column names and split them into components\n",
    "    columns = df.columns[1:]  # Skip the 'Label (Grouping)' column\n",
    "    \n",
    "    # Create a list to store the transformed data\n",
    "    transformed_data = []\n",
    "    \n",
    "    # Track unique counties and states\n",
    "    processed_locations = set()\n",
    "    \n",
    "    # Iterate through each location column\n",
    "    for col in columns:\n",
    "        # Split the column name\n",
    "        parts = col.split('!!')\n",
    "        \n",
    "        # Extract location and demographic type\n",
    "        location = parts[0]\n",
    "        demo_type = parts[1]  # Male, Female, or Total\n",
    "        estimate = parts[2] if len(parts) > 2 else None\n",
    "        \n",
    "        # Skip if not an Estimate\n",
    "        if estimate != 'Estimate':\n",
    "            continue\n",
    "            \n",
    "        # Split location into county and state\n",
    "        county_state = location.split(', ')\n",
    "        county = county_state[0]\n",
    "        state = county_state[1]\n",
    "        \n",
    "        # Create unique key for this county\n",
    "        location_key = (county, state)\n",
    "        \n",
    "        # If we haven't processed this county yet, create a new row\n",
    "        if location_key not in processed_locations:\n",
    "            row_data = {\n",
    "                'county_name': county,\n",
    "                'state_name': state\n",
    "            }\n",
    "            \n",
    "            # Add data for each demographic label\n",
    "            for idx, label in enumerate(df['Label (Grouping)']):\n",
    "                if pd.notna(df.iloc[idx][col]) and str(df.iloc[idx][col]) != '(X)':\n",
    "                    value = df.iloc[idx][col]\n",
    "                    # Convert percentages to floats\n",
    "                    if isinstance(value, str) and '%' in value:\n",
    "                        value = float(value.strip('%'))/100\n",
    "                    \n",
    "                    # Create column name combining label and demographic type\n",
    "                    column_name = f\"{label}_{demo_type.lower()}\"\n",
    "                    row_data[column_name] = value\n",
    "            \n",
    "            transformed_data.append(row_data)\n",
    "            processed_locations.add(location_key)\n",
    "        else:\n",
    "            # Update existing row with additional demographic type data\n",
    "            row_idx = next(i for i, row in enumerate(transformed_data) \n",
    "                          if row['county_name'] == county and row['state_name'] == state)\n",
    "            \n",
    "            for idx, label in enumerate(df['Label (Grouping)']):\n",
    "                if pd.notna(df.iloc[idx][col]) and str(df.iloc[idx][col]) != '(X)':\n",
    "                    value = df.iloc[idx][col]\n",
    "                    # Convert percentages to floats\n",
    "                    if isinstance(value, str) and '%' in value:\n",
    "                        value = float(value.strip('%'))/100\n",
    "                    \n",
    "                    # Create column name combining label and demographic type\n",
    "                    column_name = f\"{label}_{demo_type.lower()}\"\n",
    "                    transformed_data[row_idx][column_name] = value\n",
    "    \n",
    "    # Create new dataframe\n",
    "    new_df = pd.DataFrame(transformed_data)\n",
    "    \n",
    "    # Sort columns alphabetically after county_name and state_name\n",
    "    cols = ['county_name', 'state_name'] + sorted([col for col in new_df.columns \n",
    "                                                 if col not in ['county_name', 'state_name']])\n",
    "    new_df = new_df[cols]\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "# Example usage:\n",
    "# reshaped_df = reshape_demographics_data(your_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_sex_2012_reshaped = reshape_demographics_age_data(df_age_sex_2012)\n",
    "df_age_sex_2012_reshaped = df_age_sex_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_age_sex_2016_reshaped = reshape_demographics_age_data(df_age_sex_2016)\n",
    "df_age_sex_2016_reshaped = df_age_sex_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_age_sex_2020_reshaped = reshape_demographics_age_data(df_age_sex_2020)\n",
    "df_age_sex_2020_reshaped = df_age_sex_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_age_sex_2012_reshaped.to_csv('data/election/census/census_age_sex_2012_reshaped.csv', index=False)\n",
    "df_age_sex_2016_reshaped.to_csv('data/election/census/census_age_sex_2016_reshaped.csv', index=False)\n",
    "df_age_sex_2020_reshaped.to_csv('data/election/census/census_age_sex_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape Employment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_employment_data(df, year):\n",
    "    \"\"\"\n",
    "    Reshape county-level census data from wide format to long format with counties as rows,\n",
    "    creating separate columns for Total, Labor Force, Employed, and Unemployment rate for each category.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with county data in wide format\n",
    "    year (int): Census year (2012 or 2016/2020) to determine column naming format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped DataFrame with counties as rows\n",
    "    \"\"\"\n",
    "    # Define metric mappings based on year\n",
    "    if year == 2012:\n",
    "        metric_mappings = {\n",
    "            'Total': 'Total',\n",
    "            'In labor force': 'labor_force',\n",
    "            'Employed': 'employed',\n",
    "            'Unemployment rate': 'unemployment_rate'\n",
    "        }\n",
    "    else:  # 2016 or 2020\n",
    "        metric_mappings = {\n",
    "            'Total': 'Total',\n",
    "            'Labor Force Participation Rate': 'labor_force',\n",
    "            'Employment/Population Ratio': 'employed',\n",
    "            'Unemployment rate': 'unemployment_rate'\n",
    "        }\n",
    "    \n",
    "    # Get the Label column values as our new column names, filtering out header rows\n",
    "    row_categories = []\n",
    "    for idx, label in enumerate(df['Label (Grouping)']):\n",
    "        if pd.notna(label):\n",
    "            # Skip if row is all caps and contains no data (header row)\n",
    "            if not (str(label).isupper() and df.iloc[idx, 1:].isna().all()):\n",
    "                row_categories.append((idx, label))\n",
    "    \n",
    "    # Process each unique county\n",
    "    counties_data = []\n",
    "    \n",
    "    # Get unique county-state combinations\n",
    "    county_columns = [col for col in df.columns if '!!' in col]\n",
    "    unique_counties = set()\n",
    "    for col in county_columns:\n",
    "        county_state = col.split('!!')[0]\n",
    "        if ',' in county_state:\n",
    "            unique_counties.add(county_state)\n",
    "            \n",
    "    # Process each county\n",
    "    for county_state in unique_counties:\n",
    "        county_name, state_name = county_state.split(',', 1)\n",
    "        state_name = state_name.strip()\n",
    "        \n",
    "        # Create a dictionary for this county's data\n",
    "        county_data = {\n",
    "            'county_name': county_name,\n",
    "            'state_name': state_name\n",
    "        }\n",
    "        print('processing', county_name, state_name)\n",
    "        \n",
    "        # For each demographic category\n",
    "        for idx, category in row_categories:\n",
    "            category_clean = (category.replace(' ', '_')\n",
    "                            .replace('(', '')\n",
    "                            .replace(')', '')\n",
    "                            .replace(',', '')\n",
    "                            .replace('/', '_')\n",
    "                            .replace('-', '_')\n",
    "                            .replace('...', ''))\n",
    "            \n",
    "            # Get the four metrics for this category using the appropriate mapping\n",
    "            for original_metric, clean_metric in metric_mappings.items():\n",
    "                col_name = f\"{county_state}!!{original_metric}!!Estimate\"\n",
    "                if col_name in df.columns:\n",
    "                    value = df.iloc[idx][col_name]\n",
    "                    \n",
    "                    # Convert percentage strings to floats if possible\n",
    "                    if isinstance(value, str):\n",
    "                        if value in ['-', '(X)']:\n",
    "                            value = None\n",
    "                        elif '%' in value:\n",
    "                            try:\n",
    "                                value = float(value.strip('%')) / 100\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                    \n",
    "                    # Create clean column name\n",
    "                    final_col_name = f\"{category_clean}_{clean_metric}\"\n",
    "                    county_data[final_col_name] = value\n",
    "        \n",
    "        counties_data.append(county_data)\n",
    "    \n",
    "    # Create the final DataFrame\n",
    "    result_df = pd.DataFrame(counties_data)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_employment_2012_reshaped = reshape_employment_data(df_age_employment_2012, 2012)\n",
    "df_age_employment_2012_reshaped = df_age_employment_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_employment_2016_reshaped = reshape_employment_data(df_age_employment_2016, 2016)\n",
    "df_age_employment_2016_reshaped = df_age_employment_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_employment_2020_reshaped = reshape_employment_data(df_age_employment_2020, 2020)\n",
    "df_age_employment_2020_reshaped = df_age_employment_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_age_employment_2012_reshaped.to_csv('data/election/census/census_age_employment_2012_reshaped.csv', index=False)\n",
    "df_age_employment_2016_reshaped.to_csv('data/election/census/census_age_employment_2016_reshaped.csv', index=False)\n",
    "df_age_employment_2020_reshaped.to_csv('data/election/census/census_age_employment_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape Industry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_industry_data(df):\n",
    "    \"\"\"\n",
    "    Reshape county-level occupation data from wide format to long format with counties as rows,\n",
    "    creating separate columns for total workers and percentage in each occupation category.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with county occupation data in wide format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped DataFrame with counties as rows\n",
    "    \"\"\"\n",
    "    # Get the Label column values as our new column names, filtering out header rows\n",
    "    row_categories = []\n",
    "    for idx, label in enumerate(df['Label (Grouping)']):\n",
    "        if pd.notna(label):\n",
    "            # Skip if row is all caps or percent imputed rows\n",
    "            if not (str(label).isupper() or 'PERCENT' in str(label)):\n",
    "                row_categories.append((idx, label))\n",
    "    \n",
    "    # Define occupation categories in order\n",
    "    occupation_categories = [\n",
    "        'Total',\n",
    "        'Management, business, science, and arts occupations',\n",
    "        'Service occupations',\n",
    "        'Sales and office occupations',\n",
    "        'Natural resources, construction, and maintenance occupations',\n",
    "        'Production, transportation, and material moving occupations'\n",
    "    ]\n",
    "    \n",
    "    # Process each unique county\n",
    "    counties_data = []\n",
    "    \n",
    "    # Get unique county-state combinations\n",
    "    county_columns = [col for col in df.columns if '!!' in col]\n",
    "    unique_counties = set()\n",
    "    for col in county_columns:\n",
    "        county_state = col.split('!!')[0]\n",
    "        if ',' in county_state:\n",
    "            unique_counties.add(county_state)\n",
    "    \n",
    "    # Process each county\n",
    "    for county_state in unique_counties:\n",
    "        county_name, state_name = county_state.split(',', 1)\n",
    "        state_name = state_name.strip()\n",
    "        \n",
    "        # Create a dictionary for this county's data\n",
    "        county_data = {\n",
    "            'county_name': county_name,\n",
    "            'state_name': state_name\n",
    "        }\n",
    "        \n",
    "        # For each industry category\n",
    "        for idx, category in row_categories:\n",
    "            category_clean = (category.replace(' ', '_')\n",
    "                            .replace('(', '')\n",
    "                            .replace(')', '')\n",
    "                            .replace(',', '')\n",
    "                            .replace('/', '_')\n",
    "                            .replace('-', '_')\n",
    "                            .replace('.', '')\n",
    "                            .replace('...', ''))\n",
    "            \n",
    "            # Get values for total and each occupation percentage\n",
    "            for occupation in occupation_categories:\n",
    "                col_name = f\"{county_state}!!{occupation}!!Estimate\"\n",
    "                if col_name in df.columns:\n",
    "                    value = df.iloc[idx][col_name]\n",
    "                    \n",
    "                    # Convert percentage strings to floats if possible\n",
    "                    if isinstance(value, str):\n",
    "                        if value == '-' or value == '(X)':\n",
    "                            value = None\n",
    "                        elif '%' in value:\n",
    "                            try:\n",
    "                                value = float(value.strip('%')) / 100\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                    \n",
    "                    # Create clean column name\n",
    "                    if occupation == 'Total':\n",
    "                        suffix = 'total_workers'\n",
    "                    else:\n",
    "                        occupation_clean = (occupation.replace(' ', '_')\n",
    "                                         .replace(',', '')\n",
    "                                         .replace('_and_', '_')\n",
    "                                         .lower())\n",
    "                        suffix = f'pct_{occupation_clean}'\n",
    "                    \n",
    "                    final_col_name = f\"{category_clean}_{suffix}\"\n",
    "                    county_data[final_col_name] = value\n",
    "        \n",
    "        counties_data.append(county_data)\n",
    "    \n",
    "    # Create the final DataFrame\n",
    "    result_df = pd.DataFrame(counties_data)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industry_2012_reshaped = reshape_industry_data(df_industry_2012)\n",
    "df_industry_2012_reshaped = df_industry_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_industry_2016_reshaped = reshape_industry_data(df_industry_2016)\n",
    "df_industry_2016_reshaped = df_industry_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_industry_2020_reshaped = reshape_industry_data(df_industry_2020)\n",
    "df_industry_2020_reshaped = df_industry_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_industry_2012_reshaped.to_csv('data/election/census/census_industry_2012_reshaped.csv', index=False)\n",
    "df_industry_2016_reshaped.to_csv('data/election/census/census_industry_2016_reshaped.csv', index=False)\n",
    "df_industry_2020_reshaped.to_csv('data/election/census/census_industry_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape housing financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_housing_financial_data(df):\n",
    "    \"\"\"\n",
    "    Reshape county-level housing financial data from wide format to long format with counties as rows,\n",
    "    creating separate columns for total, owner-occupied, and renter-occupied housing metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with county housing data in wide format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped DataFrame with counties as rows\n",
    "    \"\"\"\n",
    "    # Get the Label column values as our new column names, filtering out header rows\n",
    "    row_categories = []\n",
    "    for idx, label in enumerate(df['Label (Grouping)']):\n",
    "        if pd.notna(label):\n",
    "            # Skip if row is all caps, header rows, or percent imputed\n",
    "            if not (str(label).isupper() or 'PERCENT' in str(label)):\n",
    "                row_categories.append((idx, label))\n",
    "    \n",
    "    # Define housing categories\n",
    "    housing_categories = [\n",
    "        'Occupied housing units',\n",
    "        'Owner-occupied housing units',\n",
    "        'Renter-occupied housing units'\n",
    "    ]\n",
    "    \n",
    "    # Process each unique county\n",
    "    counties_data = []\n",
    "    \n",
    "    # Get unique county-state combinations\n",
    "    county_columns = [col for col in df.columns if '!!' in col]\n",
    "    unique_counties = set()\n",
    "    for col in county_columns:\n",
    "        county_state = col.split('!!')[0]\n",
    "        if ',' in county_state:\n",
    "            unique_counties.add(county_state)\n",
    "    \n",
    "    # Process each county\n",
    "    for county_state in unique_counties:\n",
    "        county_name, state_name = county_state.split(',', 1)\n",
    "        state_name = state_name.strip()\n",
    "        \n",
    "        # Create a dictionary for this county's data\n",
    "        county_data = {\n",
    "            'county_name': county_name,\n",
    "            'state_name': state_name\n",
    "        }\n",
    "        \n",
    "        # For each financial metric\n",
    "        for idx, category in row_categories:\n",
    "            category_clean = (category.replace(' ', '_')\n",
    "                            .replace('(', '')\n",
    "                            .replace(')', '')\n",
    "                            .replace(',', '')\n",
    "                            .replace('/', '_')\n",
    "                            .replace('-', '_')\n",
    "                            .replace('.', '')\n",
    "                            .replace('...', '')\n",
    "                            .replace('$', '')\n",
    "                            .replace('__', '_')\n",
    "                            .lower())\n",
    "            \n",
    "            # Get values for each housing category\n",
    "            for housing_type in housing_categories:\n",
    "                col_name = f\"{county_state}!!{housing_type}!!Estimate\"\n",
    "                if col_name in df.columns:\n",
    "                    value = df.iloc[idx][col_name]\n",
    "                    \n",
    "                    # Convert percentage strings to floats if possible\n",
    "                    if isinstance(value, str):\n",
    "                        if value == '-' or value == '(X)':\n",
    "                            value = None\n",
    "                        elif '%' in value:\n",
    "                            try:\n",
    "                                value = float(value.strip('%')) / 100\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                        # Handle dollar amounts\n",
    "                        elif '$' in value or ',' in value:\n",
    "                            try:\n",
    "                                value = float(value.replace('$', '').replace(',', ''))\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                    \n",
    "                    # Create clean column name\n",
    "                    housing_type_clean = (housing_type.replace(' ', '_')\n",
    "                                        .replace('-', '_')\n",
    "                                        .lower())\n",
    "                    final_col_name = f\"{category_clean}_{housing_type_clean}\"\n",
    "                    county_data[final_col_name] = value\n",
    "        \n",
    "        counties_data.append(county_data)\n",
    "    \n",
    "    # Create the final DataFrame\n",
    "    result_df = pd.DataFrame(counties_data)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_financial_2012_reshaped = reshape_housing_financial_data(df_housing_financial_2012)\n",
    "df_housing_financial_2012_reshaped = df_housing_financial_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_housing_financial_2016_reshaped = reshape_housing_financial_data(df_housing_financial_2016)\n",
    "df_housing_financial_2016_reshaped = df_housing_financial_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_housing_financial_2020_reshaped = reshape_housing_financial_data(df_housing_financial_2020)\n",
    "df_housing_financial_2020_reshaped = df_housing_financial_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_housing_financial_2012_reshaped.to_csv('data/election/census/census_housing_financial_2012_reshaped.csv', index=False)\n",
    "df_housing_financial_2016_reshaped.to_csv('data/election/census/census_housing_financial_2016_reshaped.csv', index=False)\n",
    "df_housing_financial_2020_reshaped.to_csv('data/election/census/census_housing_financial_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape veteran status data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reshape_veteran_data(df):\n",
    "    \"\"\"\n",
    "    Reshape county-level veteran status data from wide format to long format with counties as rows,\n",
    "    creating separate columns for total population, veterans, and nonveterans metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with county veteran data in wide format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Reshaped DataFrame with counties as rows\n",
    "    \"\"\"\n",
    "    # Get the Label column values as our new column names, filtering out header rows\n",
    "    row_categories = []\n",
    "    for idx, label in enumerate(df['Label (Grouping)']):\n",
    "        if pd.notna(label):\n",
    "            # Skip if row is all caps, header rows, or percent imputed\n",
    "            if not (str(label).isupper() or 'PERCENT' in str(label)):\n",
    "                row_categories.append((idx, label))\n",
    "    \n",
    "    # Define status categories\n",
    "    status_categories = [\n",
    "        'Total',\n",
    "        'Veterans',\n",
    "        'Nonveterans'\n",
    "    ]\n",
    "    \n",
    "    # Process each unique county\n",
    "    counties_data = []\n",
    "    \n",
    "    # Get unique county-state combinations\n",
    "    county_columns = [col for col in df.columns if '!!' in col]\n",
    "    unique_counties = set()\n",
    "    for col in county_columns:\n",
    "        county_state = col.split('!!')[0]\n",
    "        if ',' in county_state:\n",
    "            unique_counties.add(county_state)\n",
    "    \n",
    "    # Process each county\n",
    "    for county_state in unique_counties:\n",
    "        county_name, state_name = county_state.split(',', 1)\n",
    "        state_name = state_name.strip()\n",
    "        \n",
    "        # Create a dictionary for this county's data\n",
    "        county_data = {\n",
    "            'county_name': county_name,\n",
    "            'state_name': state_name\n",
    "        }\n",
    "        \n",
    "        # For each demographic/service metric\n",
    "        for idx, category in row_categories:\n",
    "            category_clean = (category.replace(' ', '_')\n",
    "                            .replace('(', '')\n",
    "                            .replace(')', '')\n",
    "                            .replace(',', '')\n",
    "                            .replace('/', '_')\n",
    "                            .replace('-', '_')\n",
    "                            .replace('.', '')\n",
    "                            .replace('...', '')\n",
    "                            .replace('$', '')\n",
    "                            .replace('__', '_')\n",
    "                            .lower())\n",
    "            \n",
    "            # Special handling for period of service categories\n",
    "            is_period_of_service = 'veterans' in category_clean and any(period in category_clean \n",
    "                                                                      for period in ['gulf_war', 'vietnam', 'korean', 'world_war'])\n",
    "            \n",
    "            # Get values for each status category\n",
    "            for status in status_categories:\n",
    "                col_name = f\"{county_state}!!{status}!!Estimate\"\n",
    "                if col_name in df.columns:\n",
    "                    value = df.iloc[idx][col_name]\n",
    "                    \n",
    "                    # Convert percentage strings to floats if possible\n",
    "                    if isinstance(value, str):\n",
    "                        if value == '-' or value == '(X)':\n",
    "                            value = None\n",
    "                        elif '%' in value:\n",
    "                            try:\n",
    "                                value = float(value.strip('%')) / 100\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                        # Handle dollar amounts\n",
    "                        elif '$' in value or ',' in value:\n",
    "                            try:\n",
    "                                value = float(value.replace('$', '').replace(',', ''))\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                    \n",
    "                    # Create clean column name\n",
    "                    if is_period_of_service:\n",
    "                        # For period of service, only store veteran percentage\n",
    "                        if status == 'Veterans':\n",
    "                            final_col_name = f\"pct_{category_clean}\"\n",
    "                            county_data[final_col_name] = value\n",
    "                    else:\n",
    "                        # For other metrics, store all three categories\n",
    "                        status_clean = status.lower()\n",
    "                        final_col_name = f\"{category_clean}_{status_clean}\"\n",
    "                        county_data[final_col_name] = value\n",
    "        \n",
    "        counties_data.append(county_data)\n",
    "    \n",
    "    # Create the final DataFrame\n",
    "    result_df = pd.DataFrame(counties_data)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veteran_status_2012_reshaped = reshape_veteran_data(df_veteran_status_2012)\n",
    "df_veteran_status_2012_reshaped = df_veteran_status_2012_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_veteran_status_2016_reshaped = reshape_veteran_data(df_veteran_status_2016)\n",
    "df_veteran_status_2016_reshaped = df_veteran_status_2016_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)\n",
    "df_veteran_status_2020_reshaped = reshape_veteran_data(df_veteran_status_2020)\n",
    "df_veteran_status_2020_reshaped = df_veteran_status_2020_reshaped.sort_values(by=['state_name', 'county_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_veteran_status_2012_reshaped.to_csv('data/election/census/census_veteran_status_2012_reshaped.csv', index=False)\n",
    "df_veteran_status_2016_reshaped.to_csv('data/election/census/census_veteran_status_2016_reshaped.csv', index=False)\n",
    "df_veteran_status_2020_reshaped.to_csv('data/election/census/census_veteran_status_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stack dataframes in list for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race dataframes\n",
    "df_race_list = [df_race_2012_reshaped, df_race_2016_reshaped, df_race_2020_reshaped]\n",
    "# age_sex dataframes\n",
    "df_age_sex_list = [df_age_sex_2012_reshaped, df_age_sex_2016_reshaped, df_age_sex_2020_reshaped]\n",
    "# age_employment dataframes\n",
    "df_age_employment_list = [df_age_employment_2012_reshaped, df_age_employment_2016_reshaped, df_age_employment_2020_reshaped]\n",
    "# industry dataframes\n",
    "df_industry_list = [df_industry_2012_reshaped, df_industry_2016_reshaped, df_industry_2020_reshaped]\n",
    "# housing_financial dataframes\n",
    "df_housing_financial_list = [df_housing_financial_2012_reshaped, df_housing_financial_2016_reshaped, df_housing_financial_2020_reshaped]\n",
    "# veteran_status dataframes\n",
    "df_veteran_status_list = [df_veteran_status_2012_reshaped, df_veteran_status_2016_reshaped, df_veteran_status_2020_reshaped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the row with county_name 'index' in the df_race_list dataframes\n",
    "for df in df_race_list:\n",
    "    df.drop(df[df['county_name'] == 'index'].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where state_name is 'Puerto Rico' or 'Alaska' or 'Hawaii' or 'District of Columbia' in all dataframe lists\n",
    "for df in df_race_list:\n",
    "    df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for df in df_age_sex_list:\n",
    "    df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for df in df_age_employment_list:\n",
    "    df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for df in df_industry_list:\n",
    "    df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for df in df_housing_financial_list:\n",
    "    df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for df in df_veteran_status_list:\n",
    "    df.drop(df[df['state_name'] == 'Puerto Rico'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Alaska'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'Hawaii'].index, inplace=True)\n",
    "    df.drop(df[df['state_name'] == 'District of Columbia'].index, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show rows where county_name does not contain 'County' or 'Parish' or 'city' or 'Borough\n",
    "df2[~df2['county_name'].str.contains('County|Parish|city|Borough')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_abbr_to_name = {\n",
    "    'AL': 'Alabama',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "state_name_to_abbr = {v: k for k, v in state_abbr_to_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['state_abbr'] = df2['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "# for all dataframes lists, add a column for state_abbr\n",
    "for df in df_race_list:\n",
    "    df['state_abbr'] = df['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "for df in df_age_sex_list:\n",
    "    df['state_abbr'] = df['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "for df in df_age_employment_list:\n",
    "    df['state_abbr'] = df['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "for df in df_industry_list:\n",
    "    df['state_abbr'] = df['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "for df in df_housing_financial_list:\n",
    "    df['state_abbr'] = df['state_name'].map(state_name_to_abbr)\n",
    "\n",
    "for df in df_veteran_status_list:\n",
    "    df['state_abbr'] = df['state_name'].map(state_name_to_abbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add FIPS codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "\n",
    "def clean_place_name(name):\n",
    "    \"\"\"Clean place names for consistent matching\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    \n",
    "    # Convert to string and clean accented characters\n",
    "    name = str(name)\n",
    "    name = unidecode.unidecode(name)\n",
    "    \n",
    "    # Standardize spaces and case\n",
    "    name = name.strip()\n",
    "    \n",
    "    # Standardize specific terms\n",
    "    replacements = {\n",
    "        'Municipality': 'Municipio',\n",
    "        'City and Borough': 'Borough',\n",
    "        'Census Area': 'Census Area',\n",
    "        ' city': ' City',\n",
    "        'LaSalle': 'La Salle',\n",
    "        'LaPorte': 'La Porte',\n",
    "        'DeSoto': 'De Soto',\n",
    "        'DeKalb': 'De Kalb',\n",
    "        'St.': 'St',\n",
    "        'Ste.': 'Ste'\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        name = name.replace(old, new)\n",
    "    \n",
    "    return name\n",
    "\n",
    "def add_fips_codes(census_df, fips_csv_path):\n",
    "    \"\"\"\n",
    "    Add FIPS codes to census data by matching county and state.\n",
    "    Handles special cases for Alaska, Puerto Rico, and Virginia.\n",
    "    \n",
    "    Parameters:\n",
    "    census_df (pandas.DataFrame): Census dataframe with county_name and state_abbr columns\n",
    "    fips_csv_path (str): Path to the FIPS CSV file\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Census dataframe with FIPS codes added\n",
    "    \"\"\"\n",
    "    # Read FIPS data\n",
    "    fips_df = pd.read_csv(fips_csv_path)\n",
    "    \n",
    "    # Filter out non-place rows (like \"UNITED STATES\" and state-level entries)\n",
    "    fips_df = fips_df[~fips_df['name'].isna()]\n",
    "    fips_df = fips_df[fips_df['name'].str.contains('County|Borough|Parish|Census Area|city|Municipio', \n",
    "                                                  case=False, na=False)]\n",
    "    \n",
    "    # Clean up names in both dataframes\n",
    "    census_df = census_df.copy()\n",
    "    census_df['clean_name'] = census_df['county_name'].apply(clean_place_name)\n",
    "    fips_df['clean_name'] = fips_df['name'].apply(clean_place_name)\n",
    "    \n",
    "    # # Special handling for DC\n",
    "    # dc_mask = census_df['county_name'] == 'District of Columbia'\n",
    "    # census_df.loc[dc_mask, 'state_abbr'] = 'DC'\n",
    "    \n",
    "    # # Handle cases where state_abbr might be NaN\n",
    "    # state_map = {\n",
    "    #     'Borough': 'AK',\n",
    "    #     'Census Area': 'AK',\n",
    "    #     'Municipio': 'PR'\n",
    "    # }\n",
    "    \n",
    "    # for identifier, state_code in state_map.items():\n",
    "    #     mask = census_df['county_name'].str.contains(identifier, na=False)\n",
    "    #     census_df.loc[mask, 'state_abbr'] = state_code\n",
    "    \n",
    "    # Merge the dataframes\n",
    "    result = pd.merge(\n",
    "        census_df,\n",
    "        fips_df[['fips', 'clean_name', 'state']],\n",
    "        how='left',\n",
    "        left_on=['clean_name', 'state_abbr'],\n",
    "        right_on=['clean_name', 'state']\n",
    "    )\n",
    "    \n",
    "    # Drop the working columns\n",
    "    result = result.drop(['clean_name', 'state'], axis=1)\n",
    "    \n",
    "    # Convert FIPS codes to strings with leading zeros\n",
    "    result['fips'] = result['fips'].astype(str).str.zfill(5)\n",
    "    \n",
    "    # Rename the FIPS column\n",
    "    result = result.rename(columns={'fips': 'fips_code'})\n",
    "    \n",
    "    # Check for unmatched counties\n",
    "    unmatched = result[result['fips_code'].isna()]\n",
    "    if len(unmatched) > 0:\n",
    "        print(f\"\\nWarning: {len(unmatched)} places could not be matched with FIPS codes:\")\n",
    "        for _, row in unmatched.iterrows():\n",
    "            print(f\"- {row['county_name']}, {row['state_abbr']}\")\n",
    "    \n",
    "    # Reorder columns to put fips_code after state_name\n",
    "    cols = list(result.columns)\n",
    "    state_name_idx = cols.index('state_name')\n",
    "    cols.remove('fips_code')\n",
    "    cols.insert(state_name_idx + 1, 'fips_code')\n",
    "    result = result[cols]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add fips codes to all dataframes\n",
    "# for df in df_race_list:\n",
    "#     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# for df in df_age_sex_list:\n",
    "#     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# for df in df_age_employment_list:\n",
    "#     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# for df in df_industry_list:\n",
    "#     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# for df in df_housing_financial_list:\n",
    "#     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "# for df in df_veteran_status_list:\n",
    "#     df = add_fips_codes(df, 'data/election/fips_state_and_county.csv')\n",
    "\n",
    "df_race_2012_reshaped = add_fips_codes(df_race_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_race_2016_reshaped = add_fips_codes(df_race_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_race_2020_reshaped = add_fips_codes(df_race_2020_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_age_sex_2012_reshaped = add_fips_codes(df_age_sex_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_age_sex_2016_reshaped = add_fips_codes(df_age_sex_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_age_sex_2020_reshaped = add_fips_codes(df_age_sex_2020_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_age_employment_2012_reshaped = add_fips_codes(df_age_employment_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_age_employment_2016_reshaped = add_fips_codes(df_age_employment_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_age_employment_2020_reshaped = add_fips_codes(df_age_employment_2020_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_industry_2012_reshaped = add_fips_codes(df_industry_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_industry_2016_reshaped = add_fips_codes(df_industry_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_industry_2020_reshaped = add_fips_codes(df_industry_2020_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_housing_financial_2012_reshaped = add_fips_codes(df_housing_financial_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_housing_financial_2016_reshaped = add_fips_codes(df_housing_financial_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_housing_financial_2020_reshaped = add_fips_codes(df_housing_financial_2020_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_veteran_status_2012_reshaped = add_fips_codes(df_veteran_status_2012_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_veteran_status_2016_reshaped = add_fips_codes(df_veteran_status_2016_reshaped, 'data/election/fips_state_and_county.csv')\n",
    "df_veteran_status_2020_reshaped = add_fips_codes(df_veteran_status_2020_reshaped, 'data/election/fips_state_and_county.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns with more than 0 missing values\n",
    "df_age_employment_2012_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_age_employment_2016_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_age_employment_2020_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_industry_2012_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_industry_2016_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_industry_2020_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_housing_financial_2012_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_housing_financial_2016_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_housing_financial_2020_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_veteran_status_2012_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_veteran_status_2016_reshaped.dropna(axis=1, how='any', inplace=True)\n",
    "df_veteran_status_2020_reshaped.dropna(axis=1, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add _2012 to all columns except for county_name, state_name, fips_code, state_abbr\n",
    "df_race_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_race_2012_reshaped.columns]\n",
    "df_age_sex_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_sex_2012_reshaped.columns]\n",
    "df_age_employment_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_employment_2012_reshaped.columns]\n",
    "df_industry_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_industry_2012_reshaped.columns]\n",
    "df_housing_financial_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_housing_financial_2012_reshaped.columns]\n",
    "df_veteran_status_2012_reshaped.columns = [col + '_2012' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_veteran_status_2012_reshaped.columns]\n",
    "\n",
    "# add _2016 to all columns except for county_name, state_name, fips_code, state_abbr\n",
    "df_race_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_race_2016_reshaped.columns]\n",
    "df_age_sex_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_sex_2016_reshaped.columns]\n",
    "df_age_employment_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_employment_2016_reshaped.columns]\n",
    "df_industry_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_industry_2016_reshaped.columns]\n",
    "df_housing_financial_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_housing_financial_2016_reshaped.columns]\n",
    "df_veteran_status_2016_reshaped.columns = [col + '_2016' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_veteran_status_2016_reshaped.columns]\n",
    "\n",
    "# add _2020 to all columns except for county_name, state_name, fips_code, state_abbr\n",
    "df_race_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_race_2020_reshaped.columns]\n",
    "df_age_sex_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_sex_2020_reshaped.columns]\n",
    "df_age_employment_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_age_employment_2020_reshaped.columns]\n",
    "df_industry_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_industry_2020_reshaped.columns]\n",
    "df_housing_financial_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_housing_financial_2020_reshaped.columns]\n",
    "df_veteran_status_2020_reshaped.columns = [col + '_2020' if col not in ['county_name', 'state_name', 'fips_code', 'state_abbr'] else col for col in df_veteran_status_2020_reshaped.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>fips_code</th>\n",
       "      <th>Total:_2020</th>\n",
       "      <th>American Indian and Alaska Native alone_2020</th>\n",
       "      <th>...</th>\n",
       "      <th>Two or more races:_2020</th>\n",
       "      <th>White alone_2020</th>\n",
       "      <th>Two races excluding Some other race, and three or more races_2020</th>\n",
       "      <th>Two races including Some other race_2020</th>\n",
       "      <th>state_abbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>55,639</td>\n",
       "      <td>155</td>\n",
       "      <td>...</td>\n",
       "      <td>1,421</td>\n",
       "      <td>42,150</td>\n",
       "      <td>1,075</td>\n",
       "      <td>346</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>218,289</td>\n",
       "      <td>1,514</td>\n",
       "      <td>...</td>\n",
       "      <td>5,677</td>\n",
       "      <td>186,504</td>\n",
       "      <td>4,158</td>\n",
       "      <td>1,519</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>25,026</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>522</td>\n",
       "      <td>11,587</td>\n",
       "      <td>290</td>\n",
       "      <td>232</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>22,374</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>17,138</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>57,755</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>1,293</td>\n",
       "      <td>54,271</td>\n",
       "      <td>1,029</td>\n",
       "      <td>264</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>Sweetwater County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>43,352</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>1,844</td>\n",
       "      <td>39,470</td>\n",
       "      <td>957</td>\n",
       "      <td>887</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>Teton County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56039.0</td>\n",
       "      <td>23,356</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>20,815</td>\n",
       "      <td>237</td>\n",
       "      <td>195</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>Uinta County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56041.0</td>\n",
       "      <td>20,374</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>867</td>\n",
       "      <td>18,929</td>\n",
       "      <td>760</td>\n",
       "      <td>107</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>Washakie County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>7,933</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>376</td>\n",
       "      <td>6,898</td>\n",
       "      <td>308</td>\n",
       "      <td>68</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>Weston County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56045.0</td>\n",
       "      <td>6,942</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>201</td>\n",
       "      <td>6,418</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3107 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            county_name state_name fips_code Total:_2020  \\\n",
       "0        Autauga County    Alabama    1001.0      55,639   \n",
       "1        Baldwin County    Alabama    1003.0     218,289   \n",
       "2        Barbour County    Alabama    1005.0      25,026   \n",
       "3           Bibb County    Alabama    1007.0      22,374   \n",
       "4         Blount County    Alabama    1009.0      57,755   \n",
       "...                 ...        ...       ...         ...   \n",
       "3102  Sweetwater County    Wyoming   56037.0      43,352   \n",
       "3103       Teton County    Wyoming   56039.0      23,356   \n",
       "3104       Uinta County    Wyoming   56041.0      20,374   \n",
       "3105    Washakie County    Wyoming   56043.0       7,933   \n",
       "3106      Weston County    Wyoming   56045.0       6,942   \n",
       "\n",
       "         American Indian and Alaska Native alone_2020  ...  \\\n",
       "0                                                 155  ...   \n",
       "1                                               1,514  ...   \n",
       "2                                                  88  ...   \n",
       "3                                                  12  ...   \n",
       "4                                                  55  ...   \n",
       "...                                               ...  ...   \n",
       "3102                                              477  ...   \n",
       "3103                                               38  ...   \n",
       "3104                                              122  ...   \n",
       "3105                                               69  ...   \n",
       "3106                                               40  ...   \n",
       "\n",
       "         Two or more races:_2020     White alone_2020  \\\n",
       "0                          1,421               42,150   \n",
       "1                          5,677              186,504   \n",
       "2                            522               11,587   \n",
       "3                            114               17,138   \n",
       "4                          1,293               54,271   \n",
       "...                          ...                  ...   \n",
       "3102                       1,844               39,470   \n",
       "3103                         432               20,815   \n",
       "3104                         867               18,929   \n",
       "3105                         376                6,898   \n",
       "3106                         201                6,418   \n",
       "\n",
       "             Two races excluding Some other race, and three or more races_2020  \\\n",
       "0                                                 1,075                          \n",
       "1                                                 4,158                          \n",
       "2                                                   290                          \n",
       "3                                                   114                          \n",
       "4                                                 1,029                          \n",
       "...                                                 ...                          \n",
       "3102                                                957                          \n",
       "3103                                                237                          \n",
       "3104                                                760                          \n",
       "3105                                                308                          \n",
       "3106                                                201                          \n",
       "\n",
       "             Two races including Some other race_2020 state_abbr  \n",
       "0                                                 346         AL  \n",
       "1                                               1,519         AL  \n",
       "2                                                 232         AL  \n",
       "3                                                   0         AL  \n",
       "4                                                 264         AL  \n",
       "...                                               ...        ...  \n",
       "3102                                              887         WY  \n",
       "3103                                              195         WY  \n",
       "3104                                              107         WY  \n",
       "3105                                               68         WY  \n",
       "3106                                                0         WY  \n",
       "\n",
       "[3107 rows x 14 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_race_2020_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all dataframes on fips_code\n",
    "df_race_merged = df_race_2012_reshaped.merge(df_race_2016_reshaped, on='fips_code')\n",
    "df_race_merged = df_race_merged.merge(df_race_2020_reshaped, on='fips_code')\n",
    "df_age_sex_merged = df_age_sex_2012_reshaped.merge(df_age_sex_2016_reshaped, on='fips_code')\n",
    "df_age_sex_merged = df_age_sex_merged.merge(df_age_sex_2020_reshaped, on='fips_code')\n",
    "df_age_employment_merged = df_age_employment_2012_reshaped.merge(df_age_employment_2016_reshaped, on='fips_code')\n",
    "df_age_employment_merged = df_age_employment_merged.merge(df_age_employment_2020_reshaped, on='fips_code')\n",
    "df_industry_merged = df_industry_2012_reshaped.merge(df_industry_2016_reshaped, on='fips_code')\n",
    "df_industry_merged = df_industry_merged.merge(df_industry_2020_reshaped, on='fips_code')\n",
    "df_housing_financial_merged = df_housing_financial_2012_reshaped.merge(df_housing_financial_2016_reshaped, on='fips_code')\n",
    "df_housing_financial_merged = df_housing_financial_merged.merge(df_housing_financial_2020_reshaped, on='fips_code')\n",
    "df_veteran_status_merged = df_veteran_status_2012_reshaped.merge(df_veteran_status_2016_reshaped, on='fips_code')\n",
    "df_veteran_status_merged = df_veteran_status_merged.merge(df_veteran_status_2020_reshaped, on='fips_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# load the existing counties data county_data_with_elections_2012_2016_2020.geojson\n",
    "counties = gpd.read_file('data/election/final_data/county_data_with_elections_2012_2016_2020.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1001.0\n",
       "1        1003.0\n",
       "2        1005.0\n",
       "3        1007.0\n",
       "4        1009.0\n",
       "         ...   \n",
       "3102    56037.0\n",
       "3103    56039.0\n",
       "3104    56041.0\n",
       "3105    56043.0\n",
       "3106    56045.0\n",
       "Name: fips_code, Length: 3107, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_veteran_status_merged['fips_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1001\n",
       "1        1003\n",
       "2        1005\n",
       "3        1007\n",
       "4        1009\n",
       "        ...  \n",
       "3101    56037\n",
       "3102    56039\n",
       "3103    56041\n",
       "3104    56043\n",
       "3105    56045\n",
       "Name: FIPS Code, Length: 3106, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counties['FIPS Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a .0 to each fips code in the counties dataframe\n",
    "counties['FIPS Code'] = counties['FIPS Code'].astype(str) + '.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bovam\\AppData\\Local\\Temp\\ipykernel_21892\\3259534277.py:5: FutureWarning: Passing 'suffixes' which cause duplicate columns {'state_name_x_x', 'fips_code_x', 'state_name_y_x', 'county_name_x_x', 'county_name_y_x', 'state_abbr_y_x', 'state_abbr_x_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  counties_merged = counties_merged.merge(df_industry_merged, left_on='FIPS Code', right_on='fips_code')\n",
      "C:\\Users\\bovam\\AppData\\Local\\Temp\\ipykernel_21892\\3259534277.py:7: FutureWarning: Passing 'suffixes' which cause duplicate columns {'state_name_x_x', 'fips_code_x', 'state_name_y_x', 'county_name_x_x', 'county_name_y_x', 'state_abbr_y_x', 'state_abbr_x_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  counties_merged = counties_merged.merge(df_veteran_status_merged, left_on='FIPS Code', right_on='fips_code')\n"
     ]
    }
   ],
   "source": [
    "# merging all data to the counties dataframe\n",
    "counties_merged = counties.merge(df_race_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_age_sex_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_age_employment_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_industry_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_housing_financial_merged, left_on='FIPS Code', right_on='fips_code')\n",
    "counties_merged = counties_merged.merge(df_veteran_status_merged, left_on='FIPS Code', right_on='fips_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_abbr</th>\n",
       "      <th>total_votes_2012</th>\n",
       "      <th>votes_dem_2012</th>\n",
       "      <th>votes_gop_2012</th>\n",
       "      <th>per_dem_2012</th>\n",
       "      <th>...</th>\n",
       "      <th>with_any_disability_nonveterans_2016</th>\n",
       "      <th>without_a_disability_total_2016</th>\n",
       "      <th>without_a_disability_veterans_2016</th>\n",
       "      <th>without_a_disability_nonveterans_2016</th>\n",
       "      <th>state_abbr_y_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>23909.0</td>\n",
       "      <td>6354.0</td>\n",
       "      <td>17366.0</td>\n",
       "      <td>0.265758</td>\n",
       "      <td>...</td>\n",
       "      <td>7316.0</td>\n",
       "      <td>31732.0</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>28212.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>84988.0</td>\n",
       "      <td>18329.0</td>\n",
       "      <td>65772.0</td>\n",
       "      <td>0.215666</td>\n",
       "      <td>...</td>\n",
       "      <td>20021.0</td>\n",
       "      <td>126655.0</td>\n",
       "      <td>13079.0</td>\n",
       "      <td>113576.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>11459.0</td>\n",
       "      <td>5873.0</td>\n",
       "      <td>5539.0</td>\n",
       "      <td>0.512523</td>\n",
       "      <td>...</td>\n",
       "      <td>3982.0</td>\n",
       "      <td>13296.0</td>\n",
       "      <td>869</td>\n",
       "      <td>12427.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>8391.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>6131.0</td>\n",
       "      <td>0.262186</td>\n",
       "      <td>...</td>\n",
       "      <td>2486.0</td>\n",
       "      <td>13023.0</td>\n",
       "      <td>821</td>\n",
       "      <td>12202.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>23980.0</td>\n",
       "      <td>2961.0</td>\n",
       "      <td>20741.0</td>\n",
       "      <td>0.123478</td>\n",
       "      <td>...</td>\n",
       "      <td>6603.0</td>\n",
       "      <td>35452.0</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>32605.0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>WY</td>\n",
       "      <td>16750.0</td>\n",
       "      <td>4773.0</td>\n",
       "      <td>11427.0</td>\n",
       "      <td>0.284955</td>\n",
       "      <td>...</td>\n",
       "      <td>4002.0</td>\n",
       "      <td>27120.0</td>\n",
       "      <td>2039.0</td>\n",
       "      <td>25081.0</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>WY</td>\n",
       "      <td>11356.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>4858.0</td>\n",
       "      <td>0.546936</td>\n",
       "      <td>...</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>16886.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>15797.0</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>WY</td>\n",
       "      <td>8453.0</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>6613.0</td>\n",
       "      <td>0.192594</td>\n",
       "      <td>...</td>\n",
       "      <td>2259.0</td>\n",
       "      <td>11879.0</td>\n",
       "      <td>793</td>\n",
       "      <td>11086.0</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>WY</td>\n",
       "      <td>3911.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>3013.0</td>\n",
       "      <td>0.203017</td>\n",
       "      <td>...</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>4767.0</td>\n",
       "      <td>542</td>\n",
       "      <td>4225.0</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>WY</td>\n",
       "      <td>3323.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>0.126994</td>\n",
       "      <td>...</td>\n",
       "      <td>721</td>\n",
       "      <td>4387.0</td>\n",
       "      <td>567</td>\n",
       "      <td>3820.0</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3105 rows × 1095 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state_abbr  total_votes_2012  votes_dem_2012  votes_gop_2012  \\\n",
       "0            AL           23909.0          6354.0         17366.0   \n",
       "1            AL           84988.0         18329.0         65772.0   \n",
       "2            AL           11459.0          5873.0          5539.0   \n",
       "3            AL            8391.0          2200.0          6131.0   \n",
       "4            AL           23980.0          2961.0         20741.0   \n",
       "...         ...               ...             ...             ...   \n",
       "3100         WY           16750.0          4773.0         11427.0   \n",
       "3101         WY           11356.0          6211.0          4858.0   \n",
       "3102         WY            8453.0          1628.0          6613.0   \n",
       "3103         WY            3911.0           794.0          3013.0   \n",
       "3104         WY            3323.0           422.0          2821.0   \n",
       "\n",
       "      per_dem_2012  ...          with_any_disability_nonveterans_2016  \\\n",
       "0         0.265758  ...                                        7316.0   \n",
       "1         0.215666  ...                                       20021.0   \n",
       "2         0.512523  ...                                        3982.0   \n",
       "3         0.262186  ...                                        2486.0   \n",
       "4         0.123478  ...                                        6603.0   \n",
       "...            ...  ...                                           ...   \n",
       "3100      0.284955  ...                                        4002.0   \n",
       "3101      0.546936  ...                                        1047.0   \n",
       "3102      0.192594  ...                                        2259.0   \n",
       "3103      0.203017  ...                                        1136.0   \n",
       "3104      0.126994  ...                                           721   \n",
       "\n",
       "              without_a_disability_total_2016  \\\n",
       "0                                     31732.0   \n",
       "1                                    126655.0   \n",
       "2                                     13296.0   \n",
       "3                                     13023.0   \n",
       "4                                     35452.0   \n",
       "...                                       ...   \n",
       "3100                                  27120.0   \n",
       "3101                                  16886.0   \n",
       "3102                                  11879.0   \n",
       "3103                                   4767.0   \n",
       "3104                                   4387.0   \n",
       "\n",
       "              without_a_disability_veterans_2016  \\\n",
       "0                                         3520.0   \n",
       "1                                        13079.0   \n",
       "2                                            869   \n",
       "3                                            821   \n",
       "4                                         2847.0   \n",
       "...                                          ...   \n",
       "3100                                      2039.0   \n",
       "3101                                      1089.0   \n",
       "3102                                         793   \n",
       "3103                                         542   \n",
       "3104                                         567   \n",
       "\n",
       "             without_a_disability_nonveterans_2016 state_abbr_y_y  \n",
       "0                                          28212.0             AL  \n",
       "1                                         113576.0             AL  \n",
       "2                                          12427.0             AL  \n",
       "3                                          12202.0             AL  \n",
       "4                                          32605.0             AL  \n",
       "...                                            ...            ...  \n",
       "3100                                       25081.0             WY  \n",
       "3101                                       15797.0             WY  \n",
       "3102                                       11086.0             WY  \n",
       "3103                                        4225.0             WY  \n",
       "3104                                        3820.0             WY  \n",
       "\n",
       "[3105 rows x 1095 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counties_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1001.0\n",
       "1        1003.0\n",
       "2        1005.0\n",
       "3        1007.0\n",
       "4        1009.0\n",
       "         ...   \n",
       "3100    56037.0\n",
       "3101    56039.0\n",
       "3102    56041.0\n",
       "3103    56043.0\n",
       "3104    56045.0\n",
       "Name: FIPS Code, Length: 3105, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15 to 19 years_male_2012_y\n",
    "counties_merged['FIPS Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show duplicated columns\n",
    "duplicated_cols = counties_merged.columns[counties_merged.columns.duplicated()]\n",
    "duplicated_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated columns\n",
    "counties_merged.drop(columns=duplicated_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save counties_merged to a geojson file\n",
    "counties_merged.to_file('data/election/final_data/county_data_with_elections_2012_2016_2020_census_MAIN.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out the dataframes into separate dataframes for each year (2012, 2016, 2020), also take the state_abbr, county_name, state_name, and fips_code columns\n",
    "counties_merged_2012 = counties_merged[[col for col in counties_merged.columns if '2012' in col] + ['state_abbr', 'county_name', 'state_name', 'FIPS Code', 'geometry']]\n",
    "counties_merged_2016 = counties_merged[[col for col in counties_merged.columns if '2016' in col] + ['state_abbr', 'county_name', 'state_name', 'FIPS Code', 'geometry']]\n",
    "# for 2020, include values that contain 2021 as well\n",
    "counties_merged_2020 = counties_merged[[col for col in counties_merged.columns if '2020' in col or '2021' in col] + ['state_abbr', 'county_name', 'state_name', 'FIPS Code', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Civilian_labor_force_2016',\n",
       " 'Employed_2016',\n",
       " 'Unemployed_2016',\n",
       " 'Unemployment_rate_2016',\n",
       " 'votes_dem_2016',\n",
       " 'votes_gop_2016',\n",
       " 'total_votes_2016',\n",
       " 'per_dem_2016',\n",
       " 'per_gop_2016',\n",
       " 'diff_2016',\n",
       " 'per_point_diff_2016',\n",
       " 'winner_2016',\n",
       " 'Total:_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0American Indian and Alaska Native alone_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Asian alone_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Black or African American alone_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Native Hawaiian and Other Pacific Islander alone_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Some other race alone_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Two or more races:_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0White alone_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Two races excluding Some other race, and three or more races_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Two races including Some other race_2016',\n",
       " 'Population_16_years_and_over_Total_2016',\n",
       " 'Population_16_years_and_over_labor_force_2016',\n",
       " 'Population_16_years_and_over_employed_2016',\n",
       " 'Population_16_years_and_over_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa016_to_19_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa020_to_24_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa020_to_24_years_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa020_to_24_years_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa025_to_29_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa030_to_34_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035_to_44_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035_to_44_years_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035_to_44_years_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035_to_44_years_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa045_to_54_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa045_to_54_years_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa045_to_54_years_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa045_to_54_years_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa055_to_59_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa055_to_59_years_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa055_to_59_years_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa055_to_59_years_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa060_to_64_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa060_to_64_years_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa060_to_64_years_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa060_to_64_years_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa065_to_74_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa065_to_74_years_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa065_to_74_years_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075_years_and_over_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0White_alone_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0White_alone_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0White_alone_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0White_alone_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Black_or_African_American_alone_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0American_Indian_and_Alaska_Native_alone_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Asian_alone_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Native_Hawaiian_and_Other_Pacific_Islander_alone_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Some_other_race_alone_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Two_or_more_races_Total_2016',\n",
       " 'Hispanic_or_Latino_origin_of_any_race_Total_2016',\n",
       " 'White_alone_not_Hispanic_or_Latino_Total_2016',\n",
       " 'White_alone_not_Hispanic_or_Latino_labor_force_2016',\n",
       " 'White_alone_not_Hispanic_or_Latino_employed_2016',\n",
       " 'White_alone_not_Hispanic_or_Latino_unemployment_rate_2016',\n",
       " 'Population_20_to_64_years_Total_2016',\n",
       " 'Population_20_to_64_years_labor_force_2016',\n",
       " 'Population_20_to_64_years_employed_2016',\n",
       " 'Population_20_to_64_years_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Male_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Male_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Male_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Male_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Female_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Female_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Female_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Female_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_18_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_18_years_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_18_years_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_18_years_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_6_years_only_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_6_years_and_6_to_17_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_6_to_17_years_only_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_6_to_17_years_only_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_6_to_17_years_only_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0With_own_children_under_6_to_17_years_only_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Below_poverty_level_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0At_or_above_the_poverty_level_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0At_or_above_the_poverty_level_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0At_or_above_the_poverty_level_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0At_or_above_the_poverty_level_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0With_any_disability_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0With_any_disability_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0With_any_disability_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0With_any_disability_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Population_25_to_64_years_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Population_25_to_64_years_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Population_25_to_64_years_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Population_25_to_64_years_unemployment_rate_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Less_than_high_school_graduate_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0High_school_graduate_includes_equivalency_Total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0High_school_graduate_includes_equivalency_labor_force_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0High_school_graduate_includes_equivalency_employed_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0High_school_graduate_includes_equivalency_unemployment_rate_2016',\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Some_college_or_associate's_degree_Total_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Some_college_or_associate's_degree_labor_force_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Some_college_or_associate's_degree_employed_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Some_college_or_associate's_degree_unemployment_rate_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Bachelor's_degree_or_higher_Total_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Bachelor's_degree_or_higher_labor_force_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Bachelor's_degree_or_higher_employed_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Bachelor's_degree_or_higher_unemployment_rate_2016\",\n",
       " 'Civilian_employed_population_16_years_and_over_total_workers_2016',\n",
       " 'Civilian_employed_population_16_years_and_over_pct_management_business_science_arts_occupations_2016',\n",
       " 'Civilian_employed_population_16_years_and_over_pct_service_occupations_2016',\n",
       " 'Civilian_employed_population_16_years_and_over_pct_sales_office_occupations_2016',\n",
       " 'Civilian_employed_population_16_years_and_over_pct_natural_resources_construction_maintenance_occupations_2016',\n",
       " 'Civilian_employed_population_16_years_and_over_pct_production_transportation_material_moving_occupations_2016',\n",
       " 'Agriculture_forestry_fishing_and_hunting_and_mining_total_workers_2016',\n",
       " 'Construction_total_workers_2016',\n",
       " 'Manufacturing_total_workers_2016',\n",
       " 'Wholesale_trade_total_workers_2016',\n",
       " 'Retail_trade_total_workers_2016',\n",
       " 'Retail_trade_pct_management_business_science_arts_occupations_2016',\n",
       " 'Retail_trade_pct_service_occupations_2016',\n",
       " 'Retail_trade_pct_sales_office_occupations_2016',\n",
       " 'Retail_trade_pct_natural_resources_construction_maintenance_occupations_2016',\n",
       " 'Retail_trade_pct_production_transportation_material_moving_occupations_2016',\n",
       " 'Transportation_and_warehousing_and_utilities_total_workers_2016',\n",
       " 'Information_total_workers_2016',\n",
       " 'Finance_and_insurance_and_real_estate_and_rental_and_leasing_total_workers_2016',\n",
       " 'Professional_scientific_and_management_and_administrative_and_waste_management_services_total_workers_2016',\n",
       " 'Educational_services_and_health_care_and_social_assistance_total_workers_2016',\n",
       " 'Educational_services_and_health_care_and_social_assistance_pct_management_business_science_arts_occupations_2016',\n",
       " 'Educational_services_and_health_care_and_social_assistance_pct_service_occupations_2016',\n",
       " 'Educational_services_and_health_care_and_social_assistance_pct_sales_office_occupations_2016',\n",
       " 'Educational_services_and_health_care_and_social_assistance_pct_natural_resources_construction_maintenance_occupations_2016',\n",
       " 'Educational_services_and_health_care_and_social_assistance_pct_production_transportation_material_moving_occupations_2016',\n",
       " 'Arts_entertainment_and_recreation_and_accommodation_and_food_services_total_workers_2016',\n",
       " 'Other_services_except_public_administration_total_workers_2016',\n",
       " 'Public_administration_total_workers_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0Industry_total_workers_2016',\n",
       " 'occupied_housing_units_occupied_housing_units_2016',\n",
       " 'occupied_housing_units_owner_occupied_housing_units_2016',\n",
       " 'occupied_housing_units_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0less_than_5000_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0less_than_5000_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0less_than_5000_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa05000_to_9999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa05000_to_9999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa05000_to_9999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa010000_to_14999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa010000_to_14999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa010000_to_14999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa015000_to_19999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa015000_to_19999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa015000_to_19999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa020000_to_24999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa020000_to_24999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa020000_to_24999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa025000_to_34999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa025000_to_34999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa025000_to_34999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035000_to_49999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035000_to_49999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035000_to_49999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa050000_to_74999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa050000_to_74999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa050000_to_74999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075000_to_99999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075000_to_99999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075000_to_99999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0100000_to_149999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0100000_to_149999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0100000_to_149999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0150000_or_more_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0150000_or_more_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0150000_or_more_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0median_household_income_dollars_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0less_than_300_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0less_than_300_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0less_than_300_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0300_to_499_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0300_to_499_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0300_to_499_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0500_to_799_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0500_to_799_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0500_to_799_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0800_to_999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0800_to_999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0800_to_999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa01000_to_1499_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa01000_to_1499_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa01000_to_1499_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa01500_to_1999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa01500_to_1999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa01500_to_1999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa02000_to_2499_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa02000_to_2499_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa02000_to_2499_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa02500_to_2999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa02500_to_2999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa02500_to_2999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa03000_or_more_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa03000_or_more_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa03000_or_more_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0no_cash_rent_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0no_cash_rent_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0median_dollars_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0less_than_20000_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0less_than_20000_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0less_than_20000_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0less_than_20_percent_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0less_than_20_percent_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0less_than_20_percent_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa020_to_29_percent_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa020_to_29_percent_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa020_to_29_percent_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa030_percent_or_more_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa030_percent_or_more_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa030_percent_or_more_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa020000_to_34999_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa020000_to_34999_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa020000_to_34999_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075000_or_more_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075000_or_more_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075000_or_more_renter_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0zero_or_negative_income_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0zero_or_negative_income_owner_occupied_housing_units_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0zero_or_negative_income_renter_occupied_housing_units_2016',\n",
       " 'civilian_population_18_years_and_over_total_2016',\n",
       " 'civilian_population_18_years_and_over_veterans_2016',\n",
       " 'civilian_population_18_years_and_over_nonveterans_2016',\n",
       " 'pct_\\xa0\\xa0\\xa0\\xa0gulf_war_9_2001_or_later_veterans_2016',\n",
       " 'pct_\\xa0\\xa0\\xa0\\xa0gulf_war_8_1990_to_8_2001_veterans_2016',\n",
       " 'pct_\\xa0\\xa0\\xa0\\xa0vietnam_era_veterans_2016',\n",
       " 'pct_\\xa0\\xa0\\xa0\\xa0korean_war_veterans_2016',\n",
       " 'pct_\\xa0\\xa0\\xa0\\xa0world_war_ii_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0male_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0male_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0male_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0female_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0female_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0female_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa018_to_34_years_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa018_to_34_years_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa018_to_34_years_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035_to_54_years_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035_to_54_years_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa035_to_54_years_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa055_to_64_years_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa055_to_64_years_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa055_to_64_years_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa065_to_74_years_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa065_to_74_years_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa065_to_74_years_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075_years_and_over_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075_years_and_over_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa075_years_and_over_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0white_alone_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0white_alone_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0white_alone_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0black_or_african_american_alone_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0black_or_african_american_alone_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0black_or_african_american_alone_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0american_indian_and_alaska_native_alone_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0american_indian_and_alaska_native_alone_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0american_indian_and_alaska_native_alone_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0asian_alone_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0asian_alone_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0asian_alone_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0native_hawaiian_and_other_pacific_islander_alone_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0native_hawaiian_and_other_pacific_islander_alone_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0native_hawaiian_and_other_pacific_islander_alone_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0some_other_race_alone_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0some_other_race_alone_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0some_other_race_alone_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0two_or_more_races_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0two_or_more_races_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0two_or_more_races_nonveterans_2016',\n",
       " 'hispanic_or_latino_of_any_race_total_2016',\n",
       " 'hispanic_or_latino_of_any_race_veterans_2016',\n",
       " 'hispanic_or_latino_of_any_race_nonveterans_2016',\n",
       " 'white_alone_not_hispanic_or_latino_total_2016',\n",
       " 'white_alone_not_hispanic_or_latino_veterans_2016',\n",
       " 'white_alone_not_hispanic_or_latino_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_18_years_and_over_with_income_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_18_years_and_over_with_income_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_25_years_and_over_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_25_years_and_over_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_25_years_and_over_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0less_than_high_school_graduate_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0less_than_high_school_graduate_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0less_than_high_school_graduate_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0high_school_graduate_includes_equivalency_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0high_school_graduate_includes_equivalency_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0high_school_graduate_includes_equivalency_nonveterans_2016',\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0some_college_or_associate's_degree_total_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0some_college_or_associate's_degree_veterans_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0some_college_or_associate's_degree_nonveterans_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0bachelor's_degree_or_higher_total_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0bachelor's_degree_or_higher_veterans_2016\",\n",
       " \"\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0bachelor's_degree_or_higher_nonveterans_2016\",\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_18_to_64_years_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_18_to_64_years_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_18_to_64_years_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_labor_force_18_to_64_years_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_labor_force_18_to_64_years_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_labor_force_18_to_64_years_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_18_years_and_over_for_whom_poverty_status_is_determined_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_18_years_and_over_for_whom_poverty_status_is_determined_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0civilian_population_18_years_and_over_for_whom_poverty_status_is_determined_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0income_in_the_past_12_months_below_poverty_level_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0income_in_the_past_12_months_below_poverty_level_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0income_in_the_past_12_months_below_poverty_level_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0income_in_the_past_12_months_at_or_above_poverty_level_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0income_in_the_past_12_months_at_or_above_poverty_level_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0income_in_the_past_12_months_at_or_above_poverty_level_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0with_any_disability_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0with_any_disability_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0with_any_disability_nonveterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0without_a_disability_total_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0without_a_disability_veterans_2016',\n",
       " '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0without_a_disability_nonveterans_2016']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all cols in counties_merged that have 2020 in them\n",
    "[col for col in counties_merged.columns if '2016' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Civilian_labor_force_2020</th>\n",
       "      <th>Employed_2020</th>\n",
       "      <th>Unemployed_2020</th>\n",
       "      <th>Unemployment_rate_2020</th>\n",
       "      <th>CENSUS_2020_POP</th>\n",
       "      <th>...</th>\n",
       "      <th>state_abbr</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>FIPS Code</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26425</td>\n",
       "      <td>25023</td>\n",
       "      <td>1402</td>\n",
       "      <td>5.3</td>\n",
       "      <td>58805</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>POLYGON ((-86.9176 32.66417, -86.81657 32.6601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98979</td>\n",
       "      <td>92893</td>\n",
       "      <td>6086</td>\n",
       "      <td>6.1</td>\n",
       "      <td>231767</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>POLYGON ((-88.02927 30.22271, -88.02399 30.230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8684</td>\n",
       "      <td>8017</td>\n",
       "      <td>667</td>\n",
       "      <td>7.7</td>\n",
       "      <td>25223</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>POLYGON ((-85.74142 31.61961, -85.72983 31.632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8717</td>\n",
       "      <td>8085</td>\n",
       "      <td>632</td>\n",
       "      <td>7.3</td>\n",
       "      <td>22293</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>POLYGON ((-87.42194 33.00338, -87.31854 33.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25136</td>\n",
       "      <td>24010</td>\n",
       "      <td>1126</td>\n",
       "      <td>4.5</td>\n",
       "      <td>59134</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>POLYGON ((-86.96336 33.85822, -86.9202 33.8734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>20510</td>\n",
       "      <td>18981</td>\n",
       "      <td>1529</td>\n",
       "      <td>7.5</td>\n",
       "      <td>42272</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Sweetwater County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>POLYGON ((-110.05371 42.27074, -109.543 42.264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>15138</td>\n",
       "      <td>14237</td>\n",
       "      <td>901</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23331</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Teton County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56039.0</td>\n",
       "      <td>POLYGON ((-111.05533 44.66626, -111.00076 44.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>9105</td>\n",
       "      <td>8525</td>\n",
       "      <td>580</td>\n",
       "      <td>6.4</td>\n",
       "      <td>20450</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Uinta County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56041.0</td>\n",
       "      <td>POLYGON ((-111.04655 41.25163, -111.04655 41.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>3944</td>\n",
       "      <td>3736</td>\n",
       "      <td>208</td>\n",
       "      <td>5.3</td>\n",
       "      <td>7685</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Washakie County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>POLYGON ((-108.55056 44.16846, -108.09077 44.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>3788</td>\n",
       "      <td>3642</td>\n",
       "      <td>146</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6838</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56045.0</td>\n",
       "      <td>POLYGON ((-105.08078 43.96622, -105.07928 44.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3105 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Civilian_labor_force_2020 Employed_2020 Unemployed_2020  \\\n",
       "0                        26425         25023            1402   \n",
       "1                        98979         92893            6086   \n",
       "2                         8684          8017             667   \n",
       "3                         8717          8085             632   \n",
       "4                        25136         24010            1126   \n",
       "...                        ...           ...             ...   \n",
       "3100                     20510         18981            1529   \n",
       "3101                     15138         14237             901   \n",
       "3102                      9105          8525             580   \n",
       "3103                      3944          3736             208   \n",
       "3104                      3788          3642             146   \n",
       "\n",
       "      Unemployment_rate_2020 CENSUS_2020_POP  ... state_abbr  \\\n",
       "0                        5.3           58805  ...         AL   \n",
       "1                        6.1          231767  ...         AL   \n",
       "2                        7.7           25223  ...         AL   \n",
       "3                        7.3           22293  ...         AL   \n",
       "4                        4.5           59134  ...         AL   \n",
       "...                      ...             ...  ...        ...   \n",
       "3100                     7.5           42272  ...         WY   \n",
       "3101                     6.0           23331  ...         WY   \n",
       "3102                     6.4           20450  ...         WY   \n",
       "3103                     5.3            7685  ...         WY   \n",
       "3104                     3.9            6838  ...         WY   \n",
       "\n",
       "            county_name state_name FIPS Code  \\\n",
       "0        Autauga County    Alabama    1001.0   \n",
       "1        Baldwin County    Alabama    1003.0   \n",
       "2        Barbour County    Alabama    1005.0   \n",
       "3           Bibb County    Alabama    1007.0   \n",
       "4         Blount County    Alabama    1009.0   \n",
       "...                 ...        ...       ...   \n",
       "3100  Sweetwater County    Wyoming   56037.0   \n",
       "3101       Teton County    Wyoming   56039.0   \n",
       "3102       Uinta County    Wyoming   56041.0   \n",
       "3103    Washakie County    Wyoming   56043.0   \n",
       "3104      Weston County    Wyoming   56045.0   \n",
       "\n",
       "                                               geometry  \n",
       "0     POLYGON ((-86.9176 32.66417, -86.81657 32.6601...  \n",
       "1     POLYGON ((-88.02927 30.22271, -88.02399 30.230...  \n",
       "2     POLYGON ((-85.74142 31.61961, -85.72983 31.632...  \n",
       "3     POLYGON ((-87.42194 33.00338, -87.31854 33.006...  \n",
       "4     POLYGON ((-86.96336 33.85822, -86.9202 33.8734...  \n",
       "...                                                 ...  \n",
       "3100  POLYGON ((-110.05371 42.27074, -109.543 42.264...  \n",
       "3101  POLYGON ((-111.05533 44.66626, -111.00076 44.6...  \n",
       "3102  POLYGON ((-111.04655 41.25163, -111.04655 41.2...  \n",
       "3103  POLYGON ((-108.55056 44.16846, -108.09077 44.1...  \n",
       "3104  POLYGON ((-105.08078 43.96622, -105.07928 44.1...  \n",
       "\n",
       "[3105 rows x 30 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counties_merged[[col for col in counties_merged.columns if '2020' in col] + ['state_abbr', 'county_name', 'state_name', 'FIPS Code', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bovam\\AppData\\Local\\Temp\\ipykernel_21892\\689539826.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if '%' in counties_merged_2012[col].values:\n",
      "C:\\Users\\bovam\\AppData\\Local\\Temp\\ipykernel_21892\\689539826.py:8: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if '%' in counties_merged_2016[col].values:\n",
      "C:\\Users\\bovam\\AppData\\Local\\Temp\\ipykernel_21892\\689539826.py:13: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if '%' in counties_merged_2020[col].values:\n"
     ]
    }
   ],
   "source": [
    "# in counties_merged_2012, fix values in all columns that contain a percentage sign in the value (i.e. some columns have values with percentage signs in them, need to be float)\n",
    "for col in counties_merged_2012.columns:\n",
    "    if '%' in counties_merged_2012[col].values:\n",
    "        counties_merged_2012[col] = counties_merged_2012[col].str.replace('%', '').astype(float)\n",
    "\n",
    "# in counties_merged_2016, fix values in all columns that contain a percentage sign in the value (i.e. some columns have values with percentage signs in them, need to be float)\n",
    "for col in counties_merged_2016.columns:\n",
    "    if '%' in counties_merged_2016[col].values:\n",
    "        counties_merged_2016[col] = counties_merged_2016[col].str.replace('%', '').astype(float)\n",
    "\n",
    "# in counties_merged_2020, fix values in all columns that contain a percentage sign in the value (i.e. some columns have values with percentage signs in them, need to be float)\n",
    "for col in counties_merged_2020.columns:\n",
    "    if '%' in counties_merged_2020[col].values:\n",
    "        counties_merged_2020[col] = counties_merged_2020[col].str.replace('%', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.444184\n",
       "1       0.537623\n",
       "2       0.076631\n",
       "3       0.577280\n",
       "4       0.800022\n",
       "          ...   \n",
       "3100    0.506294\n",
       "3101   -0.375213\n",
       "3102    0.628058\n",
       "3103    0.646560\n",
       "3104    0.775551\n",
       "Name: per_point_diff_2020, Length: 3105, dtype: float64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counties_merged_2020.per_point_diff_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save merged dataframes to geojson files\n",
    "counties_merged_2012.to_file('data/election/final_data/county_data_with_elections_2012_census_MAIN.geojson', driver='GeoJSON')\n",
    "counties_merged_2016.to_file('data/election/final_data/county_data_with_elections_2016_census_MAIN.geojson', driver='GeoJSON')\n",
    "counties_merged_2020.to_file('data/election/final_data/county_data_with_elections_2020_census_MAIN.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Civilian_labor_force_2020</th>\n",
       "      <th>Employed_2020</th>\n",
       "      <th>Unemployed_2020</th>\n",
       "      <th>Unemployment_rate_2020</th>\n",
       "      <th>Civilian_labor_force_2021</th>\n",
       "      <th>...</th>\n",
       "      <th>state_abbr</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>FIPS Code</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26425</td>\n",
       "      <td>25023</td>\n",
       "      <td>1402</td>\n",
       "      <td>5.3</td>\n",
       "      <td>26545</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>POLYGON ((-86.9176 32.66417, -86.81657 32.6601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98979</td>\n",
       "      <td>92893</td>\n",
       "      <td>6086</td>\n",
       "      <td>6.1</td>\n",
       "      <td>99953</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>POLYGON ((-88.02927 30.22271, -88.02399 30.230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8684</td>\n",
       "      <td>8017</td>\n",
       "      <td>667</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8280</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>POLYGON ((-85.74142 31.61961, -85.72983 31.632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8717</td>\n",
       "      <td>8085</td>\n",
       "      <td>632</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8641</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>POLYGON ((-87.42194 33.00338, -87.31854 33.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25136</td>\n",
       "      <td>24010</td>\n",
       "      <td>1126</td>\n",
       "      <td>4.5</td>\n",
       "      <td>25377</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>POLYGON ((-86.96336 33.85822, -86.9202 33.8734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>20510</td>\n",
       "      <td>18981</td>\n",
       "      <td>1529</td>\n",
       "      <td>7.5</td>\n",
       "      <td>19354</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Sweetwater County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>POLYGON ((-110.05371 42.27074, -109.543 42.264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>15138</td>\n",
       "      <td>14237</td>\n",
       "      <td>901</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15906</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Teton County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56039.0</td>\n",
       "      <td>POLYGON ((-111.05533 44.66626, -111.00076 44.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>9105</td>\n",
       "      <td>8525</td>\n",
       "      <td>580</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8812</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Uinta County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56041.0</td>\n",
       "      <td>POLYGON ((-111.04655 41.25163, -111.04655 41.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>3944</td>\n",
       "      <td>3736</td>\n",
       "      <td>208</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3939</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Washakie County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>POLYGON ((-108.55056 44.16846, -108.09077 44.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>3788</td>\n",
       "      <td>3642</td>\n",
       "      <td>146</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3718</td>\n",
       "      <td>...</td>\n",
       "      <td>WY</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56045.0</td>\n",
       "      <td>POLYGON ((-105.08078 43.96622, -105.07928 44.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3105 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Civilian_labor_force_2020 Employed_2020 Unemployed_2020  \\\n",
       "0                        26425         25023            1402   \n",
       "1                        98979         92893            6086   \n",
       "2                         8684          8017             667   \n",
       "3                         8717          8085             632   \n",
       "4                        25136         24010            1126   \n",
       "...                        ...           ...             ...   \n",
       "3100                     20510         18981            1529   \n",
       "3101                     15138         14237             901   \n",
       "3102                      9105          8525             580   \n",
       "3103                      3944          3736             208   \n",
       "3104                      3788          3642             146   \n",
       "\n",
       "      Unemployment_rate_2020 Civilian_labor_force_2021  ... state_abbr  \\\n",
       "0                        5.3                     26545  ...         AL   \n",
       "1                        6.1                     99953  ...         AL   \n",
       "2                        7.7                      8280  ...         AL   \n",
       "3                        7.3                      8641  ...         AL   \n",
       "4                        4.5                     25377  ...         AL   \n",
       "...                      ...                       ...  ...        ...   \n",
       "3100                     7.5                     19354  ...         WY   \n",
       "3101                     6.0                     15906  ...         WY   \n",
       "3102                     6.4                      8812  ...         WY   \n",
       "3103                     5.3                      3939  ...         WY   \n",
       "3104                     3.9                      3718  ...         WY   \n",
       "\n",
       "            county_name  state_name FIPS Code  \\\n",
       "0        Autauga County     Alabama    1001.0   \n",
       "1        Baldwin County     Alabama    1003.0   \n",
       "2        Barbour County     Alabama    1005.0   \n",
       "3           Bibb County     Alabama    1007.0   \n",
       "4         Blount County     Alabama    1009.0   \n",
       "...                 ...         ...       ...   \n",
       "3100  Sweetwater County     Wyoming   56037.0   \n",
       "3101       Teton County     Wyoming   56039.0   \n",
       "3102       Uinta County     Wyoming   56041.0   \n",
       "3103    Washakie County     Wyoming   56043.0   \n",
       "3104      Weston County     Wyoming   56045.0   \n",
       "\n",
       "                                               geometry  \n",
       "0     POLYGON ((-86.9176 32.66417, -86.81657 32.6601...  \n",
       "1     POLYGON ((-88.02927 30.22271, -88.02399 30.230...  \n",
       "2     POLYGON ((-85.74142 31.61961, -85.72983 31.632...  \n",
       "3     POLYGON ((-87.42194 33.00338, -87.31854 33.006...  \n",
       "4     POLYGON ((-86.96336 33.85822, -86.9202 33.8734...  \n",
       "...                                                 ...  \n",
       "3100  POLYGON ((-110.05371 42.27074, -109.543 42.264...  \n",
       "3101  POLYGON ((-111.05533 44.66626, -111.00076 44.6...  \n",
       "3102  POLYGON ((-111.04655 41.25163, -111.04655 41.2...  \n",
       "3103  POLYGON ((-108.55056 44.16846, -108.09077 44.1...  \n",
       "3104  POLYGON ((-105.08078 43.96622, -105.07928 44.1...  \n",
       "\n",
       "[3105 rows x 73 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counties_merged_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reshaped data to csvs\n",
    "df_race_2012_reshaped.to_csv('data/election/census/census_race_2012_reshaped.csv', index=False)\n",
    "df_race_2016_reshaped.to_csv('data/election/census/census_race_2016_reshaped.csv', index=False)\n",
    "df_race_2020_reshaped.to_csv('data/election/census/census_race_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_age_sex_2012_reshaped.to_csv('data/election/census/census_age_sex_2012_reshaped.csv', index=False)\n",
    "df_age_sex_2016_reshaped.to_csv('data/election/census/census_age_sex_2016_reshaped.csv', index=False)\n",
    "df_age_sex_2020_reshaped.to_csv('data/election/census/census_age_sex_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_age_employment_2012_reshaped.to_csv('data/election/census/census_age_employment_2012_reshaped.csv', index=False)\n",
    "df_age_employment_2016_reshaped.to_csv('data/election/census/census_age_employment_2016_reshaped.csv', index=False)\n",
    "df_age_employment_2020_reshaped.to_csv('data/election/census/census_age_employment_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_industry_2012_reshaped.to_csv('data/election/census/census_industry_2012_reshaped.csv', index=False)\n",
    "df_industry_2016_reshaped.to_csv('data/election/census/census_industry_2016_reshaped.csv', index=False)\n",
    "df_industry_2020_reshaped.to_csv('data/election/census/census_industry_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_housing_financial_2012_reshaped.to_csv('data/election/census/census_housing_financial_2012_reshaped.csv', index=False)\n",
    "df_housing_financial_2016_reshaped.to_csv('data/election/census/census_housing_financial_2016_reshaped.csv', index=False)\n",
    "df_housing_financial_2020_reshaped.to_csv('data/election/census/census_housing_financial_2020_reshaped.csv', index=False)\n",
    "# save the reshaped data to csvs\n",
    "df_veteran_status_2012_reshaped.to_csv('data/election/census/census_veteran_status_2012_reshaped.csv', index=False)\n",
    "df_veteran_status_2016_reshaped.to_csv('data/election/census/census_veteran_status_2016_reshaped.csv', index=False)\n",
    "df_veteran_status_2020_reshaped.to_csv('data/election/census/census_veteran_status_2020_reshaped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add _2012 to all column names, remove ':' from column names\n",
    "df2_fips.columns = [col + '_2012' if col != 'state_name' and col != 'county_name' else col for col in df2_fips.columns]\n",
    "df2_fips.columns = [col.replace(':', '') for col in df2_fips.columns]\n",
    "df2_fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove commas from all values\n",
    "df2_fips = df2_fips.replace(',', '', regex=True)\n",
    "df2_fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_demographic_percentages(df):\n",
    "    \"\"\"\n",
    "    Add percentage columns for each demographic category.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with demographic counts\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with additional percentage columns\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Define the demographic columns and their new percentage column names\n",
    "    demographic_cols = {\n",
    "        'American Indian and Alaska Native alone_2012': 'pct_aian_2012',\n",
    "        'Asian alone_2012': 'pct_asian_2012',\n",
    "        'Black or African American alone_2012': 'pct_black_2012',\n",
    "        'Native Hawaiian and Other Pacific Islander alone_2012': 'pct_nhpi_2012',\n",
    "        'Some other race alone_2012': 'pct_other_2012',\n",
    "        'Two or more races_2012': 'pct_two_or_more_2012',\n",
    "        'White alone_2012': 'pct_white_2012',\n",
    "        'Two races excluding Some other race, and three or more races_2012': 'pct_two_races_excl_other_2012',\n",
    "        'Two races including Some other race_2012': 'pct_two_races_incl_other_2012'\n",
    "    }\n",
    "    \n",
    "    # Calculate percentages for each demographic category\n",
    "    for col, new_col in demographic_cols.items():\n",
    "        result[new_col] = (result[col] / result['Total_2012'] * 100).round(2)\n",
    "        \n",
    "    # Validate that percentages sum to approximately 100\n",
    "    # Note: We exclude the detailed two races breakdowns as they're subcategories\n",
    "    main_pct_cols = [\n",
    "        'pct_aian_2012',\n",
    "        'pct_asian_2012',\n",
    "        'pct_black_2012',\n",
    "        'pct_nhpi_2012',\n",
    "        'pct_other_2012',\n",
    "        'pct_two_or_more_2012',\n",
    "        'pct_white_2012'\n",
    "    ]\n",
    "    \n",
    "    # Calculate sum of percentages\n",
    "    result['pct_sum'] = result[main_pct_cols].sum(axis=1)\n",
    "    \n",
    "    # Check for any significant deviations from 100%\n",
    "    tolerance = 0.1  # Allow for small rounding differences\n",
    "    deviations = result[abs(result['pct_sum'] - 100) > tolerance]\n",
    "    if len(deviations) > 0:\n",
    "        print(f\"\\nWarning: {len(deviations)} rows have percentages that don't sum to 100% (±{tolerance}%):\")\n",
    "        for _, row in deviations.iterrows():\n",
    "            print(f\"- {row['county_name']}, {row['state_name']}: {row['pct_sum']:.2f}%\")\n",
    "    \n",
    "    # Drop the validation column\n",
    "    result = result.drop('pct_sum', axis=1)\n",
    "    \n",
    "    # Group and order columns\n",
    "    id_cols = ['county_name', 'state_name', 'fips_code_2012', 'state_abbr_2012']\n",
    "    count_cols = ['Total_2012'] + list(demographic_cols.keys())\n",
    "    pct_cols = list(demographic_cols.values())\n",
    "    \n",
    "    # Reorder columns\n",
    "    result = result[id_cols + count_cols + pct_cols]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called df\n",
    "df2_fips = add_demographic_percentages(df2_fips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aispace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
